# Investigative Journalism Platform - Complete Vision & Architecture

## Executive Summary

You're building a comprehensive **AI-Powered Investigative Journalism Platform** that combines:
- âœ… **What you already have**: Multi-database search, agentic research, tag taxonomy
- ğŸš€ **What you want to add**: Social media monitoring, FOIA tracking, Boolean alerts, team UI

**The Good News**: You already have 60% of the core infrastructure built! We're not starting from scratch.

---

## Table of Contents

1. [Current State Assessment](#current-state-assessment)
2. [Complete Platform Vision](#complete-platform-vision)
3. [System Architecture](#system-architecture)
4. [Component Deep Dives](#component-deep-dives)
5. [Data Source Integration Strategy](#data-source-integration-strategy)
6. [Agentic Research System](#agentic-research-system)
7. [Non-Technical UI Design](#non-technical-ui-design)
8. [Phased Implementation Roadmap](#phased-implementation-roadmap)
9. [Cost & Resource Analysis](#cost--resource-analysis)
10. [Recommendations](#recommendations)

---

## PART 1: Current State Assessment

### What You Already Have (Existing Assets)

#### âœ… Core Infrastructure (Highly Sophisticated)

**1. Agentic Research System**
- **`core/agentic_executor.py`** - Self-improving search with LLM-powered query refinement
  - Automatic result quality evaluation
  - Iterative query improvement (up to 3 refinements)
  - Parallel execution across multiple databases
  - **This is GOLD** - most platforms don't have this level of intelligence

**2. Multiple Execution Strategies**
- `core/intelligent_executor.py` - Intelligent query generation
- `core/parallel_executor.py` - Parallel multi-database search
- `core/adaptive_analyzer.py` - Adaptive result analysis
- `core/result_analyzer.py` - Result quality assessment

**3. Database Integration Framework**
- `core/database_integration_base.py` - Abstract base class for integrations
- `core/database_registry.py` - Central registry for all data sources
- `core/api_request_tracker.py` - API usage tracking and rate limiting

#### âœ… Existing Data Source Integrations

**Government/Public Sources:**
1. **SAM.gov** (`experiments/scrapers/sam_search.py`)
   - Federal contract opportunities
   - Grant information
   - Entity registrations

2. **DVIDS** (`experiments/scrapers/dvids_search.py`)
   - Military news and media
   - Department of Defense information
   - Images and videos from military operations

3. **ClearanceJobs** (`experiments/scrapers/clearancejobs_search.py`)
   - Security clearance job postings
   - Indicators of government hiring priorities

4. **Discord** (`experiments/discord/discord_server_manager.py`)
   - Already monitoring Discord servers
   - Source of leaks, extremist activity, insider information

**Partial/Test Integrations:**
5. **USAJobs** (`test_usajobs_live.py`)
   - Federal employment opportunities
   - Government hiring trends

#### âœ… Knowledge Management System

**Tag Taxonomy** (`experiments/tag_management/`)
- **440 curated tags** across 20 categories
- **Interactive HTML browser** (`taxonomy_browse.html`)
- **Auto-tagging system** (`batch_tag_articles.py`)
- **1,101 articles** already tagged and categorized

**Keyword Database** (Just built!)
- **1,216 keywords** for Boolean searches
- **24 investigative themes**
- **40 ready-to-use Boolean queries**
- **697 acronyms** identified

#### âœ… Infrastructure & Utilities

- **LLM Integration** (`llm_utils.py`) - Configured with litellm for multi-model support
- **Config Management** (`config_loader.py`) - Centralized configuration
- **API Tracking** - Request logging, rate limiting, cost tracking

---

### What You Want to Add (Gaps & Expansion)

#### 1. Social Media Monitoring (NEW)
- **Twitter/X** - Real-time monitoring, thread tracking, sentiment analysis
- **Reddit** - Subreddit monitoring, post tracking, comment analysis
- **TikTok** - Video content monitoring, hashtag tracking
- **Telegram** - Channel monitoring, group tracking (investigative gold mine)
- **4chan** - Board monitoring (pol, int, etc.) for extremism research

#### 2. Additional Government/FOIA Sources (NEW)
- **FBI Vault** - FOIA document releases
- **CIA FOIA Reading Room** - Declassified documents
- **NSA FOIA** - NSA document releases
- **MuckRock** - FOIA request tracking platform
- **DocumentCloud** - Investigative document repository
- **Federal Register** - Proposed rules, notices, executive orders
- **Congress.gov** - Bills, hearings, Congressional reports

#### 3. Automated Boolean Search Monitoring (NEW)
- **Scheduled searches** across all sources
- **Keyword alert system** using your 1,216 keywords
- **Email/Slack notifications** for high-priority matches
- **Deduplication** across sources
- **Relevance scoring** and prioritization

#### 4. Natural Language Research Interface (ENHANCE EXISTING)
- **Chat-based UI** for non-technical users
- **Plain English queries** â†’ Agentic research
- **Conversational refinement** (user can ask follow-ups)
- **Result summarization** with citations

#### 5. Analysis Capabilities (NEW)

**Qualitative Analysis:**
- **LLM-powered summarization** of result sets
- **Theme extraction** across documents
- **Entity relationship mapping** (person-organization-event networks)
- **Timeline generation** from events
- **Sentiment analysis** of sources

**Quantitative Analysis:**
- **Trend tracking** (keyword mentions over time)
- **Source diversity metrics** (are you seeing multiple sources?)
- **Network analysis** (who's connected to whom?)
- **Statistical anomaly detection** (unusual spikes in activity)

#### 6. Team Collaboration UI (NEW)
- **Web dashboard** accessible to non-technical users
- **Shared workspaces** for investigations
- **Annotation tools** for documents
- **Task assignment** (research tasks)
- **Export capabilities** (PDF reports, CSV data)

---

## PART 2: Complete Platform Vision

### Platform Name (Working Title)
**"SigInt"** - Signal Intelligence Platform for Investigative Journalism

### Core Value Proposition

> **"Ask a question in plain English, get comprehensive multi-source intelligence analysis, automatically monitored over time, with team collaboration."**

### User Workflows

#### Workflow 1: Ad-Hoc Deep Research (Natural Language)

**Non-technical team member's experience:**

1. **Ask Question**: "What connections exist between tech companies and the Trump administration's AI policy?"

2. **Platform Response**:
   ```
   ğŸ” Researching across 15 sources...

   Government Sources (3):
   âœ“ SAM.gov: 12 relevant contracts found
   âœ“ Federal Register: 8 AI policy notices
   âœ“ Congress.gov: 3 relevant bills

   Media Sources (5):
   âœ“ NewsAPI: 47 news articles
   âœ“ Twitter: 156 relevant tweets
   âœ“ Reddit: 23 discussions

   Documents (2):
   âœ“ MuckRock: 5 FOIA releases
   âœ“ DocumentCloud: 8 documents

   ğŸ¤– Analyzing results...
   âœ“ Extracted 12 key entities
   âœ“ Generated timeline (2023-2025)
   âœ“ Identified 8 thematic clusters

   ğŸ“Š Summary available. Would you like to:
   1. See the executive summary
   2. Explore results by source
   3. Generate a report
   4. Set up monitoring for this topic
   ```

3. **User selects**: "See executive summary"

4. **Platform provides**:
   - 3-paragraph summary with citations
   - Key findings (bullet points)
   - Important entities (people, orgs, events)
   - Recommended next steps

5. **User can**:
   - Click citations to see original documents
   - Ask follow-up questions
   - Export to PDF
   - Share with team
   - **Set up automated monitoring** for future updates

#### Workflow 2: Automated Boolean Monitoring

**Power user's experience:**

1. **Create Monitor**:
   ```
   Monitor Name: "Domestic Extremism - NVE"

   Keywords: "nihilistic violent extremism" OR "NVE" OR "domestic terrorism"
   Boolean Query: (keywords) AND (FBI OR DHS OR "threat assessment")

   Sources to Monitor:
   â˜‘ FBI.gov
   â˜‘ DHS.gov
   â˜‘ Google News
   â˜‘ Twitter (hashtags: #NVE, #domesticterrorism)
   â˜‘ Reddit (subreddits: r/intelligence, r/nationalsecurity)

   Alert Settings:
   â˜‘ Immediate alert for government sources
   â˜‘ Daily digest for news/social
   â˜ Weekly summary report

   Delivery:
   â˜‘ Email (brian@example.com)
   â˜‘ Slack (#investigation-channel)
   ```

2. **Platform Runs** (automatically, daily at 6 AM):
   - Searches all selected sources
   - Deduplicates results
   - Scores by relevance
   - Filters based on rules

3. **User Receives** (at 7 AM):
   - **Immediate alerts** (if government doc released): Slack ping + email
   - **Daily digest email**:
     ```
     ğŸš¨ NVE Monitoring Alert - 3 High-Priority Matches

     Government Sources (1):
     ğŸ”´ NEW: FBI releases NVE threat assessment
        Source: fbi.gov/reports/nve-assessment-2025
        Published: Today, 6:32 AM
        Matched: "nihilistic violent extremism", "threat assessment"

     News (2):
     ğŸŸ¡ NYT: FBI Director discusses NVE threat
        Published: Yesterday

     ğŸŸ¡ WaPo: Extremism experts warn of NVE rise
        Published: 2 days ago

     Social Media (7 matches) - See digest
     ```

4. **User clicks** "FBI releases NVE threat assessment"
   - Opens full document in platform
   - Sees highlighted keywords
   - Can annotate, share with team, add to investigation folder

#### Workflow 3: Team Collaboration on Investigation

**Lead investigator assigns research task:**

1. **Creates Investigation**: "Project: Silicon Valley - Trump Admin Connections"

2. **Adds team members**: Brian (lead), Sarah (researcher), Mike (analyst)

3. **Assigns tasks**:
   ```
   Task 1: Research Elon Musk's government contracts (2023-2025)
   â†’ Assigned to: Sarah
   â†’ Sources: SAM.gov, Federal Register

   Task 2: Analyze Twitter discussions about tech CEOs and Trump
   â†’ Assigned to: Mike
   â†’ Sources: Twitter, Reddit
   ```

4. **Sarah (non-technical) uses natural language search**:
   - Types: "Show me all government contracts awarded to Elon Musk or his companies since 2023"
   - Platform searches SAM.gov, USASpending.gov
   - Results appear with easy export to investigation folder

5. **Mike uses Boolean monitoring**:
   - Sets up Twitter monitor: `(Elon OR Musk OR Tesla OR SpaceX) AND (Trump OR "Trump admin")`
   - Gets daily digest of relevant tweets
   - Can click to see full threads, track influencers

6. **Team collaborates**:
   - Shared workspace shows all findings
   - Can comment on documents
   - Brian reviews and exports final report

---

## PART 3: System Architecture

### High-Level Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INTERFACES                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚  Web UI      â”‚  â”‚ Chat Interfaceâ”‚  â”‚  API         â”‚              â”‚
â”‚  â”‚ (Dashboard)  â”‚  â”‚ (Natural Lang)â”‚  â”‚ (Programmatic)              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    REQUEST ROUTER         â”‚
         â”‚  (Determines intent)      â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                                 â”‚
         â–¼                                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BOOLEAN MONITOR    â”‚                      â”‚  AGENTIC RESEARCH    â”‚
â”‚  (Scheduled)        â”‚                      â”‚  (On-Demand)         â”‚
â”‚                     â”‚                      â”‚                      â”‚
â”‚  â€¢ Keyword DB       â”‚                      â”‚  â€¢ Natural Language  â”‚
â”‚  â€¢ Cron scheduler   â”‚                      â”‚  â€¢ Multi-phase       â”‚
â”‚  â€¢ Alert rules      â”‚                      â”‚  â€¢ Self-refining     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                             â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  QUERY BUILDER   â”‚
                    â”‚  â€¢ Boolean gen   â”‚
                    â”‚  â€¢ Synonym exp   â”‚
                    â”‚  â€¢ Source adapt  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                                     â”‚
           â–¼                                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DATA SOURCE LAYER   â”‚              â”‚  ANALYSIS ENGINE   â”‚
â”‚  (15+ integrations)  â”‚              â”‚                    â”‚
â”‚                      â”‚              â”‚  â€¢ LLM Summaries   â”‚
â”‚  Government:         â”‚              â”‚  â€¢ Entity Extract  â”‚
â”‚  â€¢ SAM.gov          â”‚              â”‚  â€¢ Timeline Gen    â”‚
â”‚  â€¢ DVIDS            â”‚              â”‚  â€¢ Network Graph   â”‚
â”‚  â€¢ FBI FOIA         â”‚              â”‚  â€¢ Sentiment       â”‚
â”‚  â€¢ Congress.gov     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â€¢ Trends          â”‚
â”‚                      â”‚              â”‚                    â”‚
â”‚  Social Media:       â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚  â€¢ Twitter/X         â”‚                       â”‚
â”‚  â€¢ Reddit            â”‚                       â”‚
â”‚  â€¢ Telegram          â”‚                       â–¼
â”‚  â€¢ TikTok            â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      â”‚              â”‚  STORAGE LAYER     â”‚
â”‚  Documents:          â”‚              â”‚                    â”‚
â”‚  â€¢ MuckRock          â”‚              â”‚  â€¢ PostgreSQL      â”‚
â”‚  â€¢ DocumentCloud    â”‚              â”‚  â€¢ Elasticsearch   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  â€¢ S3 (docs)       â”‚
           â”‚                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                                     â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  DEDUPLICATION   â”‚
                    â”‚  â€¢ Content hash  â”‚
                    â”‚  â€¢ Similarity    â”‚
                    â”‚  â€¢ Cross-source  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚ RELEVANCE SCORER â”‚
                    â”‚  â€¢ Keyword match â”‚
                    â”‚  â€¢ Source cred   â”‚
                    â”‚  â€¢ Recency       â”‚
                    â”‚  â€¢ LLM scoring   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  ALERT MANAGER   â”‚
                    â”‚  â€¢ Email         â”‚
                    â”‚  â€¢ Slack         â”‚
                    â”‚  â€¢ Web notif     â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Breakdown

#### Layer 1: User Interfaces (3 interfaces)

**1. Web Dashboard** (Non-technical primary interface)
- **Technology**: React + Tailwind CSS + FastAPI backend
- **Features**:
  - Visual query builder (no code needed)
  - Result browser with filters
  - Investigation workspaces
  - Document annotation
  - Report generation
  - Team collaboration

**2. Chat Interface** (Natural language)
- **Technology**: Streamlit Chat or custom React chat
- **Features**:
  - Conversational research
  - Follow-up questions
  - Clarification prompts
  - Inline result preview
  - Export conversation to investigation

**3. API** (For power users/automation)
- **Technology**: FastAPI with OpenAPI docs
- **Features**:
  - Programmatic access to all features
  - Webhook support for integrations
  - Python client library
  - CLI tool

#### Layer 2: Intelligence Layer

**Agentic Research Engine** (Enhance existing `agentic_executor.py`)
```python
class EnhancedAgenticResearch:
    """
    Extends existing agentic_executor.py with:
    - Natural language understanding
    - Multi-turn conversation
    - Result synthesis
    - Investigation persistence
    """

    async def research(self, question: str, context: Dict) -> ResearchResult:
        """
        1. Parse natural language question
        2. Identify relevant sources
        3. Generate source-specific queries
        4. Execute parallel search (reuse existing parallel_executor)
        5. Evaluate and refine (reuse existing agentic refinement)
        6. Synthesize results with LLM
        7. Return structured result with citations
        """
```

**Boolean Monitor** (New - Build on keyword database)
```python
class BooleanMonitor:
    """
    Automated monitoring using keyword database
    """

    def __init__(self, keyword_db_path: str):
        self.keywords = load_keyword_database(keyword_db_path)
        self.scheduler = CronScheduler()
        self.alert_manager = AlertManager()

    async def create_monitor(self, monitor_config: MonitorConfig):
        """
        Create a new monitoring job:
        1. Load Boolean query from keyword DB
        2. Schedule searches (cron)
        3. Set up alert rules
        4. Save monitor config
        """

    async def execute_monitor(self, monitor_id: str):
        """
        Run a monitoring job:
        1. Execute all queries across sources
        2. Deduplicate results
        3. Score relevance
        4. Apply alert rules
        5. Send notifications
        6. Store results
        """
```

#### Layer 3: Data Source Integration

**Source Adapter Pattern** (Expand existing `database_integration_base.py`)

Each source gets an adapter that implements:
```python
class SourceAdapter(ABC):
    """Base class for all data source integrations"""

    @abstractmethod
    async def search(self, query: Query) -> List[Result]:
        """Execute search, return standardized results"""

    @abstractmethod
    def supports_boolean(self) -> bool:
        """Does this source support Boolean queries?"""

    @abstractmethod
    def rate_limit(self) -> RateLimit:
        """What are the rate limits?"""
```

**New Sources to Add** (Priority order):

**Tier 1: Government/FOIA** (High signal, authoritative)
1. **FBI Vault** (`FBIVaultAdapter`)
   - FOIA document releases
   - API available
   - Rate limit: Generous

2. **CIA FOIA** (`CIAFOIAAdapter`)
   - Reading room search
   - Web scraping (no API)
   - Rate limit: Respectful scraping

3. **Federal Register** (`FederalRegisterAdapter`)
   - API available
   - No authentication needed
   - Rate limit: 1000 req/hour

4. **Congress.gov** (`CongressAdapter`)
   - API available (requires key)
   - Bills, hearings, reports
   - Rate limit: Generous

**Tier 2: Social Media** (Real-time, high volume)
1. **Twitter/X** (`TwitterAdapter`)
   - API v2 (paid tiers)
   - Rate limits: Varies by tier (100-300 req/15min)
   - Features: Search, streaming, user timeline

2. **Reddit** (`RedditAdapter`)
   - PRAW library (Python Reddit API Wrapper)
   - Rate limit: 60 req/min
   - Features: Subreddit search, post tracking

3. **Telegram** (`TelegramAdapter`)
   - Telethon library
   - No official search API (scraping)
   - Features: Channel monitoring, group tracking

4. **TikTok** (`TikTokAdapter`)
   - Unofficial APIs (TikTok-Api library)
   - Fragile (API changes frequently)
   - Features: Hashtag search, user content

5. **4chan** (`FourChanAdapter`)
   - Read-only API (boards.4chan.org/board/catalog.json)
   - No rate limit (respect guidelines)
   - Features: Board monitoring, thread tracking

**Tier 3: Document Repositories**
1. **MuckRock** (`MuckRockAdapter`)
   - FOIA request tracking
   - API available
   - Features: Document search, request tracking

2. **DocumentCloud** (`DocumentCloudAdapter`)
   - Investigative documents
   - API available
   - Features: Full-text search, annotations

**Tier 4: News & Media**
1. **NewsAPI** (Already commonly used)
2. **Google News RSS** (Free, no API key)
3. **ProPublica API** (Investigative journalism)

#### Layer 4: Analysis Engine

**LLM-Powered Analysis** (New capabilities)

```python
class AnalysisEngine:
    """
    Qualitative and quantitative analysis of results
    """

    async def summarize(self, results: List[Result]) -> Summary:
        """
        Generate executive summary of result set
        - 3-paragraph overview
        - Key findings (bullets)
        - Important entities
        """

    async def extract_entities(self, results: List[Result]) -> EntityGraph:
        """
        Extract and link entities:
        - People (with roles/affiliations)
        - Organizations
        - Events
        - Locations
        Return as network graph
        """

    async def generate_timeline(self, results: List[Result]) -> Timeline:
        """
        Create chronological timeline of events
        """

    async def identify_themes(self, results: List[Result]) -> List[Theme]:
        """
        Extract recurring themes using LLM clustering
        """

    async def track_trends(self, keyword: str, timeframe: str) -> TrendData:
        """
        Quantitative: mentions over time, source diversity
        """

    async def analyze_sentiment(self, results: List[Result]) -> SentimentAnalysis:
        """
        Sentiment across sources, topics
        """
```

**Quantitative Analytics** (New)

```python
class QuantitativeAnalytics:
    """
    Statistical analysis of results
    """

    def mention_frequency(self, keyword: str, by: str = "day") -> pd.DataFrame:
        """Mentions over time"""

    def source_diversity(self, results: List[Result]) -> Dict:
        """How many unique sources? Coverage breadth?"""

    def entity_network(self, results: List[Result]) -> nx.Graph:
        """NetworkX graph of entity connections"""

    def detect_anomalies(self, trend_data: pd.DataFrame) -> List[Anomaly]:
        """Statistical anomaly detection (spikes, drops)"""
```

---

## PART 4: Data Source Integration Strategy

### Integration Complexity Matrix

| Source | Difficulty | API Available | Cost | Priority | Notes |
|--------|-----------|---------------|------|----------|-------|
| **FBI Vault** | Easy | Yes | Free | HIGH | Already have framework |
| **Federal Register** | Easy | Yes | Free | HIGH | Well-documented API |
| **Twitter/X** | Medium | Yes | $$$$ | HIGH | Expensive tiers ($5k-$42k/mo) |
| **Reddit** | Easy | Yes | Free | HIGH | PRAW library is excellent |
| **Congress.gov** | Easy | Yes | Free | MEDIUM | Requires API key |
| **CIA FOIA** | Medium | No | Free | MEDIUM | Web scraping needed |
| **Telegram** | Hard | Partial | Free | HIGH | Unofficial, changes often |
| **TikTok** | Hard | No | Free | LOW | Unstable unofficial APIs |
| **4chan** | Easy | Yes | Free | MEDIUM | Simple JSON API |
| **MuckRock** | Easy | Yes | Free | MEDIUM | Good API docs |
| **DocumentCloud** | Easy | Yes | Free | MEDIUM | Full-text search |

### Recommended Integration Order

**Phase 1: Government Sources** (Weeks 1-2)
- FBI Vault
- Federal Register
- Congress.gov

**Rationale**: Easy APIs, high signal, free, similar to SAM.gov/DVIDS you already have.

**Phase 2: Reddit & 4chan** (Week 3)
- Reddit (PRAW)
- 4chan (simple JSON API)

**Rationale**: Easy integrations, high value for extremism/disinformation research, free.

**Phase 3: Document Repositories** (Week 4)
- MuckRock
- DocumentCloud

**Rationale**: Medium difficulty, high value for investigations, free.

**Phase 4: Telegram** (Week 5-6)
- Telegram channels/groups

**Rationale**: High value for leaks/extremism but technically challenging.

**Phase 5: Twitter/X** (Decide based on budget)
- Expensive but high value
- Consider waiting or using free tier limits

**Phase 6: TikTok** (Optional, low priority)
- Unstable APIs, lower journalistic value

### Technical Implementation Pattern

**Reuse Your Existing Pattern**:

You already have a great pattern in `database_integration_base.py`. For each new source:

1. **Create adapter class**:
```python
from core.database_integration_base import DatabaseIntegration, DatabaseMetadata

class FBIVaultAdapter(DatabaseIntegration):
    def __init__(self):
        super().__init__(DatabaseMetadata(
            id="fbi_vault",
            name="FBI Vault",
            description="FBI FOIA document releases",
            category="government_foia"
        ))

    async def execute_search(self, params: Dict, api_key: str, limit: int) -> QueryResult:
        # Implementation
        pass
```

2. **Register in `database_registry.py`**:
```python
registry.register(FBIVaultAdapter())
```

3. **Use with existing agentic executor**:
```python
executor = AgenticExecutor()
results = await executor.execute_all(
    research_question="What FBI documents mention 'domestic terrorism'?",
    databases=[fbi_vault, cia_foia],  # Add new sources seamlessly!
    api_keys={},
    limit=20
)
```

---

## PART 5: Agentic Research System (Enhanced)

### Current Capability (What You Have)

Your `agentic_executor.py` already does:
âœ… Multi-database parallel search
âœ… Automatic result quality evaluation
âœ… LLM-powered query refinement
âœ… Iterative improvement (up to 3 iterations)

This is **already sophisticated**. Most platforms don't have this.

### What to Add (Enhancements)

#### Enhancement 1: Natural Language Understanding

**Current**: Requires structured research question
**Enhanced**: Accepts conversational input

```python
class NaturalLanguageRouter:
    """
    Parse natural language, determine intent, route to appropriate handler
    """

    async def parse_query(self, user_input: str) -> Intent:
        """
        Use LLM to understand intent:

        "Show me Elon Musk's government contracts"
        â†’ Intent: SEARCH
        â†’ Sources: [SAM.gov, USASpending]
        â†’ Entity: Elon Musk (person)
        â†’ Type: Contracts

        "What's the latest on domestic terrorism?"
        â†’ Intent: SEARCH + MONITOR_SETUP
        â†’ Sources: [News, Gov, Social]
        â†’ Topic: Domestic terrorism
        â†’ Suggest: Set up monitoring

        "Summarize my findings on Project X"
        â†’ Intent: ANALYSIS
        â†’ Action: Summarize investigation
        """

        prompt = f"""Parse this user query and determine intent:

        "{user_input}"

        Return JSON:
        {{
          "intent": "search" | "monitor" | "analyze" | "export",
          "entities": [...],
          "keywords": [...],
          "suggested_sources": [...],
          "time_frame": "...",
          "action_needed": "..."
        }}
        """

        response = await acompletion(model="gpt-4o", messages=[...])
        return Intent.from_json(response)
```

#### Enhancement 2: Multi-Turn Conversation

**Current**: One-shot search
**Enhanced**: Conversational refinement

```python
class ConversationalResearch:
    """
    Maintain conversation context, allow follow-ups
    """

    def __init__(self):
        self.conversation_history = []
        self.current_investigation = None

    async def handle_message(self, user_message: str) -> Response:
        """
        Process message in context of conversation

        User: "What government contracts did SpaceX get in 2024?"
        Bot: [searches SAM.gov, returns 15 contracts]

        User: "Show me just the ones over $100 million"
        Bot: [filters results from memory, returns 3 contracts]

        User: "Compare that to 2023"
        Bot: [searches 2023, compares, shows trend]

        User: "Set up monitoring for new SpaceX contracts"
        Bot: [creates boolean monitor, confirms]
        """

        # Add to history
        self.conversation_history.append({
            "role": "user",
            "content": user_message,
            "timestamp": datetime.now()
        })

        # Determine if this is refinement or new query
        intent = await self.analyze_intent_with_context(
            message=user_message,
            history=self.conversation_history
        )

        if intent.is_refinement:
            # Use cached results, apply filters
            response = await self.refine_existing_results(intent)
        else:
            # New search
            response = await self.execute_new_search(intent)

        self.conversation_history.append({
            "role": "assistant",
            "content": response,
            "timestamp": datetime.now()
        })

        return response
```

#### Enhancement 3: Result Synthesis

**Current**: Returns raw results
**Enhanced**: LLM synthesis with citations

```python
class ResultSynthesizer:
    """
    Synthesize multi-source results into coherent narrative
    """

    async def synthesize(self, results: Dict[str, QueryResult]) -> Synthesis:
        """
        Input: Raw results from multiple sources
        Output: Synthesized analysis with citations

        Example:
        - 50 results from 8 sources
        - LLM reads all
        - Generates:
          * Executive summary (3 paragraphs)
          * Key findings (5 bullets)
          * Important entities (people, orgs, places)
          * Recommended actions
          * All with [citations]
        """

        # Prepare context for LLM
        context = self.prepare_synthesis_context(results)

        prompt = f"""You are synthesizing intelligence from multiple sources.

        Research Question: {context['question']}

        Sources ({len(results)}):
        {context['source_summary']}

        Results ({context['total_results']} total):
        {context['results_text']}

        Provide a comprehensive analysis:

        1. EXECUTIVE SUMMARY (3 paragraphs):
           - What did you find?
           - What's the significance?
           - What are the implications?

        2. KEY FINDINGS (5-7 bullet points):
           - Most important discoveries
           - Each with [citation]

        3. IMPORTANT ENTITIES:
           - People (with roles/affiliations)
           - Organizations
           - Events
           - Locations

        4. RECOMMENDED NEXT STEPS:
           - What should be investigated further?
           - What sources should be consulted?
           - Are there gaps in coverage?

        Use [Source: name, URL] format for citations.
        """

        synthesis = await acompletion(
            model="gpt-4o",  # Need most capable model
            messages=[{"role": "user", "content": prompt}]
        )

        return Synthesis.from_text(synthesis)
```

#### Enhancement 4: Investigation Persistence

**Current**: Results are ephemeral
**Enhanced**: Save investigations, track over time

```python
class InvestigationManager:
    """
    Manage long-term investigations
    """

    def create_investigation(self, name: str, description: str) -> Investigation:
        """
        Create a new investigation workspace:
        - Unique ID
        - Name/description
        - Team members
        - Research questions
        - Saved results
        - Timeline
        """

    def add_results(self, investigation_id: str, results: QueryResult):
        """
        Add new results to investigation:
        - Deduplicate against existing
        - Update timeline
        - Notify team
        """

    def get_investigation(self, investigation_id: str) -> Investigation:
        """
        Retrieve full investigation with all history
        """

    def export_report(self, investigation_id: str, format: str) -> bytes:
        """
        Generate report:
        - PDF (formatted, citations)
        - CSV (data export)
        - JSON (full data)
        """
```

---

## PART 6: Non-Technical UI Design

### Design Principles

1. **"No code" required** - Visual query builder, not Boolean syntax
2. **Conversation first** - Natural language primary interface
3. **Progressive disclosure** - Simple by default, advanced when needed
4. **Instant feedback** - Loading states, progress bars, previews
5. **Accessible** - WCAG 2.1 AA compliant, keyboard navigation

### UI Mockup: Main Dashboard

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SigInt - Investigative Intelligence Platform        ğŸ‘¤ Brian  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ’¬ Ask a research question...                          â”‚  â”‚
â”‚  â”‚                                                         â”‚  â”‚
â”‚  â”‚ Examples:                                               â”‚  â”‚
â”‚  â”‚ â€¢ "What FBI documents mention domestic terrorism?"     â”‚  â”‚
â”‚  â”‚ â€¢ "Show me Elon Musk's government contracts in 2024"   â”‚  â”‚
â”‚  â”‚ â€¢ "Track mentions of 'artificial intelligence' policy" â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ“Š Investigations â”‚  â”‚ ğŸ”” Active Alerts â”‚  â”‚ ğŸ¯ Monitors â”‚  â”‚
â”‚  â”‚                   â”‚  â”‚                   â”‚  â”‚             â”‚  â”‚
â”‚  â”‚  Project Phoenix â”‚  â”‚  NVE Monitoring  â”‚  â”‚  12 active  â”‚  â”‚
â”‚  â”‚  5 findings      â”‚  â”‚  3 new matches   â”‚  â”‚  2 alerts   â”‚  â”‚
â”‚  â”‚                   â”‚  â”‚                   â”‚  â”‚             â”‚  â”‚
â”‚  â”‚  [View]          â”‚  â”‚  [View Alert]    â”‚  â”‚  [Manage]   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  Recent Activity:                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ†• 2 minutes ago - Sarah added 5 documents to Project P â”‚  â”‚
â”‚  â”‚ ğŸ” 1 hour ago - New FBI Vault release on extremism     â”‚  â”‚
â”‚  â”‚ ğŸ“Š 3 hours ago - Weekly trend report: AI policy        â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### UI Mockup: Chat Interface (Natural Language Research)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ’¬ Research Chat                               ğŸ—‘ï¸  Export  âš™ï¸  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  YOU:                                                           â”‚
â”‚  What government contracts did SpaceX receive in 2024?         â”‚
â”‚                                                                 â”‚
â”‚  SIGINT:                                                        â”‚
â”‚  ğŸ” Searching across SAM.gov, USASpending...                   â”‚
â”‚                                                                 â”‚
â”‚  Found 15 contracts totaling $2.3B                             â”‚
â”‚                                                                 â”‚
â”‚  Top 5:                                                         â”‚
â”‚  1. [$800M] NASA - Starship lunar lander (Apr 2024) [View]    â”‚
â”‚  2. [$500M] Space Force - Satellite launches (Feb 2024) [View]â”‚
â”‚  3. [$400M] DOD - National security missions (Jan 2024) [View]â”‚
â”‚  4. [$300M] NASA - ISS resupply (Mar 2024) [View]             â”‚
â”‚  5. [$150M] Air Force - GPS launches (May 2024) [View]        â”‚
â”‚                                                                 â”‚
â”‚  [Show all 15] [Export to CSV] [Add to Investigation]         â”‚
â”‚                                                                 â”‚
â”‚  Would you like me to:                                          â”‚
â”‚  â€¢ Compare to 2023 contracts?                                   â”‚
â”‚  â€¢ Set up monitoring for new SpaceX contracts?                  â”‚
â”‚  â€¢ Analyze trends?                                              â”‚
â”‚                                                                 â”‚
â”‚  YOU:                                                           â”‚
â”‚  Show me just the ones over $100 million                       â”‚
â”‚                                                                 â”‚
â”‚  SIGINT:                                                        â”‚
â”‚  Filtered to 8 contracts over $100M:                           â”‚
â”‚  [Results shown...]                                            â”‚
â”‚                                                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Type your message...                                    [Send]â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### UI Mockup: Monitor Creation (No-Code Boolean Builder)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Create New Monitor                                  [Save] [Ã—]â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Monitor Name: *                                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Domestic Extremism - NVE                                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  What are you monitoring? (Natural language or keywords)       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ nihilistic violent extremism OR NVE OR domestic terror  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  âœ¨ Suggested keywords from database:                          â”‚
â”‚  [+domestic terrorism] [+violent extremists] [+FBI] [+DHS]     â”‚
â”‚                                                                 â”‚
â”‚  Select sources to monitor:                                    â”‚
â”‚  â˜‘ Government                                                  â”‚
â”‚    â˜‘ FBI.gov          â˜‘ DHS.gov          â˜‘ Federal Register   â”‚
â”‚                                                                 â”‚
â”‚  â˜‘ Social Media                                                â”‚
â”‚    â˜‘ Twitter (#NVE, #domesticterrorism)                       â”‚
â”‚    â˜‘ Reddit (r/intelligence, r/nationalSecurity)              â”‚
â”‚    â˜ Telegram                                                  â”‚
â”‚                                                                 â”‚
â”‚  â˜‘ News                                                        â”‚
â”‚    â˜‘ Google News      â˜‘ NewsAPI                               â”‚
â”‚                                                                 â”‚
â”‚  How often should we check?                                    â”‚
â”‚  â—‹ Real-time (for supported sources)                           â”‚
â”‚  â— Daily at 6:00 AM                                            â”‚
â”‚  â—‹ Weekly on Monday                                            â”‚
â”‚  â—‹ Custom schedule...                                          â”‚
â”‚                                                                 â”‚
â”‚  Alert me when:                                                â”‚
â”‚  â˜‘ Any government source publishes (immediate)                 â”‚
â”‚  â˜‘ 3+ new results in a day (daily digest)                     â”‚
â”‚  â˜ Mention of specific person: [              ]               â”‚
â”‚                                                                 â”‚
â”‚  Send alerts to:                                               â”‚
â”‚  â˜‘ Email: brian@example.com                                    â”‚
â”‚  â˜‘ Slack: #investigations                                     â”‚
â”‚  â˜ Webhook: [                               ]                 â”‚
â”‚                                                                 â”‚
â”‚  [Preview Results] [Save Monitor]                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### UI Mockup: Investigation Workspace (Team Collaboration)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Investigation: Project Phoenix - Tech & Trump Admin           â”‚
â”‚  Team: Brian (Lead), Sarah (Researcher), Mike (Analyst)        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  [Overview] [Documents] [Timeline] [Network] [Tasks] [Export]  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  ğŸ“‹ TASKS                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ âœ… Research Elon Musk contracts (Sarah) - Complete      â”‚  â”‚
â”‚  â”‚ ğŸ”„ Analyze Twitter discussions (Mike) - In Progress     â”‚  â”‚
â”‚  â”‚ â³ FOIA request for emails (Brian) - Pending            â”‚  â”‚
â”‚  â”‚ [+ Add Task]                                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  ğŸ“ DOCUMENTS (23)                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Source     â”‚ Title                          â”‚ Added By â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ SAM.gov    â”‚ SpaceX Contract $800M          â”‚ Sarah    â”‚  â”‚
â”‚  â”‚ FBI Vault  â”‚ Tech CEO Meetings Memo         â”‚ Brian    â”‚  â”‚
â”‚  â”‚ Twitter    â”‚ Thread: Musk-Trump connections â”‚ Mike     â”‚  â”‚
â”‚  â”‚ ...        â”‚ ...                            â”‚ ...      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  ğŸ—ºï¸ ENTITY NETWORK (Auto-generated)                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚        Elon Musk â”€â”€â”€â”€â”€â”€â”€â”€â”€ Donald Trump                 â”‚  â”‚
â”‚  â”‚           â”‚                     â”‚                        â”‚  â”‚
â”‚  â”‚           â”‚                     â”‚                        â”‚  â”‚
â”‚  â”‚        SpaceX â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DoD                          â”‚  â”‚
â”‚  â”‚           â”‚                     â”‚                        â”‚  â”‚
â”‚  â”‚        Tesla â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                             â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  [Expand Network] [View Details] [Export Graph]         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  ğŸ’¬ TEAM COMMENTS                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Sarah: Found interesting pattern in contracts - all     â”‚  â”‚
â”‚  â”‚        awarded within 2 weeks of Trump policy change    â”‚  â”‚
â”‚  â”‚        5 minutes ago                        [Reply]     â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚ Mike: Twitter analysis shows coordinated messaging      â”‚  â”‚
â”‚  â”‚       between tech accounts and MAGA accounts           â”‚  â”‚
â”‚  â”‚       2 hours ago                           [Reply]     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                 â”‚
â”‚  [+ Add Comment or Document]                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack for UI

**Frontend:**
- **Framework**: React 18 + TypeScript
- **Styling**: Tailwind CSS (rapid development)
- **Charts**: Recharts or Chart.js
- **Network Graphs**: D3.js or Cytoscape.js
- **State Management**: Zustand (lightweight vs Redux)
- **Build**: Vite (fast)

**Backend:**
- **API**: FastAPI (Python) - matches your existing stack
- **WebSockets**: For real-time updates
- **Authentication**: Auth0 or Supabase Auth
- **File Storage**: S3 or Backblaze B2

**Database:**
- **Primary**: PostgreSQL (structured data, teams, investigations)
- **Search**: Elasticsearch (full-text search across results)
- **Cache**: Redis (session state, rate limiting)

**Deployment:**
- **Backend**: Docker containers on AWS ECS or DigitalOcean
- **Frontend**: Vercel or Netlify (easy React deployment)
- **Database**: AWS RDS or managed PostgreSQL

---

## PART 7: Phased Implementation Roadmap

### Phase 0: Foundation (Week 1) - **START HERE**

**Goal**: Get your existing system production-ready

**Tasks**:
1. **Refactor existing code**:
   - Move all scripts to proper module structure
   - Clean up imports
   - Add proper error handling

2. **Set up development environment**:
   - Docker Compose for local development
   - PostgreSQL database
   - Redis for caching

3. **Create basic API**:
   - FastAPI wrapper around your agentic_executor
   - `/api/research` endpoint (POST request â†’ agentic search)
   - `/api/sources` endpoint (list available sources)

4. **Test thoroughly**:
   - Existing SAM.gov, DVIDS, ClearanceJobs work
   - Agentic executor runs end-to-end
   - Results are correct

**Deliverable**: Stable API that non-technical team can call (even if via Postman)

**Time**: 1 week
**Effort**: Refactoring existing code
**Cost**: $0 (just time)

---

### Phase 1: Boolean Monitoring MVP (Weeks 2-3)

**Goal**: Automated monitoring of 1-2 key topics with email alerts

**Tasks**:
1. **Build Boolean Monitor**:
   - Load keyword database
   - Schedule daily searches (cron)
   - Simple email alerts (smtplib)

2. **Add 3 new government sources**:
   - FBI Vault (easy API)
   - Federal Register (easy API)
   - Congress.gov (easy API)

3. **Create monitoring config file**:
   ```yaml
   monitors:
     - name: "Domestic Extremism - NVE"
       keywords: ["nihilistic violent extremism", "NVE"]
       sources: ["fbi_gov", "dhs_gov", "google_news"]
       schedule: "daily_6am"
       alert_email: "brian@example.com"
   ```

4. **Test**:
   - Set up 1-2 monitors
   - Verify emails arrive
   - Check deduplication works

**Deliverable**: Automated daily monitoring with email alerts

**Time**: 2 weeks
**Effort**: Medium (new code but straightforward)
**Cost**: $0 (all free data sources)

---

### Phase 2: Simple Web UI (Weeks 4-5)

**Goal**: Basic web interface for non-technical team

**Tasks**:
1. **Build simple Streamlit app**:
   - Chat interface for natural language queries
   - Results display with filters
   - Export to CSV

2. **Features**:
   - Text box: "Ask a question..."
   - Submit â†’ calls agentic executor
   - Show results in table
   - Download CSV button

3. **Deploy**:
   - Streamlit Cloud (free tier)
   - Share link with team

**Deliverable**: Web UI team can use without coding

**Time**: 1-2 weeks
**Effort**: Low (Streamlit is fast)
**Cost**: $0 (Streamlit Cloud free tier)

---

### Phase 3: Social Media Integration (Weeks 6-7)

**Goal**: Add Reddit and Twitter monitoring

**Tasks**:
1. **Reddit adapter** (PRAW):
   - Subreddit monitoring
   - Post/comment search
   - Add to agentic executor

2. **Twitter adapter** (if budget allows):
   - Basic tier ($100/month gets 10k tweets/month)
   - Keyword search
   - User timeline tracking

3. **4chan adapter** (easy):
   - Board monitoring (JSON API)
   - Thread tracking

4. **Add to monitors**:
   - Update existing NVE monitor to include Reddit, Twitter
   - Test alerts work

**Deliverable**: Social media integrated, monitoring works

**Time**: 2 weeks
**Effort**: Medium (Twitter API is annoying but doable)
**Cost**: $100/month (Twitter Basic tier) - **DECISION POINT**

---

### Phase 4: Analysis Engine (Weeks 8-9)

**Goal**: LLM-powered analysis and synthesis

**Tasks**:
1. **Build AnalysisEngine**:
   - Result summarization
   - Entity extraction
   - Timeline generation
   - Theme identification

2. **Add to UI**:
   - "Summarize results" button
   - "Generate timeline" button
   - "Show entity network" visual

3. **Test**:
   - Run analysis on saved investigations
   - Verify quality of LLM outputs

**Deliverable**: Click button â†’ get AI analysis

**Time**: 2 weeks
**Effort**: Medium (LLM prompting is iterative)
**Cost**: LLM API calls (~$50-200/month depending on usage)

---

### Phase 5: Team Collaboration (Weeks 10-12)

**Goal**: Full investigation workspaces

**Tasks**:
1. **Build InvestigationManager**:
   - Create/save investigations
   - Add documents
   - Team comments
   - Task tracking

2. **Upgrade UI**:
   - From Streamlit â†’ React app
   - Investigation workspace view
   - Document annotation
   - Network graph visualization

3. **Add authentication**:
   - Simple login (email/password)
   - Role-based access (admin, researcher)

**Deliverable**: Full team collaboration platform

**Time**: 3 weeks
**Effort**: HIGH (this is the biggest lift)
**Cost**: $50-100/month (hosting)

---

### Phase 6: Advanced Features (Weeks 13+)

**Goal**: Polish and advanced capabilities

**Tasks**:
1. **Telegram integration** (hard but high value)
2. **Advanced analytics** (trends, anomalies)
3. **Export/reporting** (PDF reports, CSV dumps)
4. **Mobile responsiveness**
5. **Performance optimization**
6. **Documentation**

**Deliverable**: Production-grade platform

**Time**: Ongoing
**Effort**: Variable
**Cost**: Variable

---

## PART 8: Cost & Resource Analysis

### Development Costs (Your Time)

| Phase | Weeks | Complexity | Your Effort |
|-------|-------|------------|-------------|
| Phase 0 | 1 | Low | 20-30 hours |
| Phase 1 | 2 | Medium | 40-60 hours |
| Phase 2 | 1-2 | Low | 20-30 hours |
| Phase 3 | 2 | Medium | 40-50 hours |
| Phase 4 | 2 | Medium | 30-40 hours |
| Phase 5 | 3 | HIGH | 80-120 hours |
| Phase 6 | Ongoing | Variable | Variable |

**Total (Phases 0-5)**: ~11-12 weeks, 230-330 hours

**If you work on this full-time**: 3 months to full platform
**If you work 10-20 hours/week**: 6-8 months

### Operational Costs (Monthly)

| Service | Phase Introduced | Cost | Notes |
|---------|-----------------|------|-------|
| **LLM API** (gpt-4o-mini) | Phase 0 | $50-200 | Depends on query volume |
| **Twitter Basic** | Phase 3 | $100 | 10k tweets/month |
| **Hosting** (DigitalOcean) | Phase 2 | $20-50 | App + DB + Redis |
| **PostgreSQL** | Phase 0 | $0-25 | Start free (Supabase), scale up |
| **Elasticsearch** | Phase 4 | $0-50 | Self-hosted free, managed paid |
| **S3 Storage** | Phase 5 | $5-20 | Document storage |

**Minimum**: $75-100/month (with free tiers)
**Realistic**: $200-300/month (comfortable scaling)
**Full Scale**: $500-1000/month (if Twitter Pro, more compute)

### Cost Optimization Strategies

1. **Start free**:
   - Use all free APIs (FBI, Reddit, 4chan)
   - Skip Twitter initially
   - Use free tiers (Supabase, Streamlit Cloud)

2. **Self-host**:
   - Run on your own server ($5-20/month DigitalOcean droplet)
   - PostgreSQL + Redis + Elasticsearch on one box

3. **Use cheaper LLMs**:
   - gpt-4o-mini ($0.15/1M input tokens) instead of gpt-4o ($5/1M)
   - Claude Haiku for summaries
   - Only use expensive models for synthesis

4. **Cache aggressively**:
   - Don't re-search same query
   - Cache LLM summaries
   - Use Redis for hot data

**Recommendation**: Start with $50-100/month budget, scale as you prove value.

---

## PART 9: Recommendations & Decision Points

### My Recommendation: Phased Approach with Early Team Feedback

**Philosophy**: "Ship early, iterate based on real usage"

### Recommended Path

#### **Week 1-3: Quick Win (Phase 0 + Phase 1 combined)**

**Goal**: Get 1 automated monitor running and emailing you

**Why**:
- Proves value immediately
- Your team sees automated intel in their inbox
- Builds momentum

**What to build**:
1. Clean up existing agentic executor (1 day)
2. Add FBI Vault + Federal Register APIs (2 days)
3. Build simple Boolean monitor with email (2 days)
4. Set up NVE monitoring (your example) (1 day)
5. Test for a week (5 days)

**Outcome**: Daily email digest like:
```
Subject: NVE Monitoring - 3 New Matches

Government Sources (1):
ğŸ”´ FBI Vault: New FOIA release on extremism

News (2):
ğŸŸ¡ NYT article on domestic terrorism trends
ğŸŸ¡ ProPublica investigation into fusion centers
```

**Effort**: ~1-2 weeks full-time OR 3-4 weeks part-time
**Cost**: $0

---

#### **Week 4-6: Simple UI (Phase 2)**

**Goal**: Give your non-technical team a way to ask questions

**What to build**:
- Streamlit chat interface
- Type question â†’ get results
- Export to CSV

**Why**:
- Non-technical team can now do research themselves
- Reduces burden on you
- Validates that natural language works

**Outcome**: Team member can:
1. Go to web page
2. Type: "Show me government contracts for AI companies in 2024"
3. Get results instantly
4. Download CSV

**Effort**: 1-2 weeks
**Cost**: $0 (Streamlit free tier)

---

#### **Week 7-9: Add Social Media (Phase 3)**

**Goal**: Expand to Reddit and (optionally) Twitter

**What to build**:
- Reddit adapter (PRAW)
- Add to monitors
- Optional: Twitter Basic tier

**Why**:
- Reddit is investigative gold (extremism, leaks, insider discussions)
- Free and easy to integrate
- Twitter is nice-to-have but expensive

**Outcome**: Monitors now include social media

**Effort**: 2 weeks
**Cost**: $0-100/month (depending on Twitter decision)

---

#### **Week 10-12: AI Analysis (Phase 4)**

**Goal**: Click button â†’ get AI summary

**What to build**:
- Result synthesizer
- Entity extractor
- Timeline generator

**Why**:
- Makes sense of large result sets
- Saves hours of manual reading
- "Wow factor" for stakeholders

**Outcome**: AI writes executive summary of investigation

**Effort**: 2 weeks
**Cost**: +$50-100/month LLM usage

---

#### **DECISION POINT: Phase 5 or Iterate?**

At this point (week 12, ~3 months), you'll have:
âœ… Automated monitoring with alerts
âœ… Natural language research interface
âœ… Multi-source search (gov + social)
âœ… AI analysis and synthesis

**Option A**: Build full team UI (Phase 5)
- React app, investigation workspaces, collaboration
- **Effort**: 2-3 months
- **Complexity**: HIGH
- **Value**: Enables true team collaboration

**Option B**: Iterate on existing (cheaper, faster)
- Improve Streamlit UI
- Add more sources
- Refine monitoring
- **Effort**: Ongoing, small improvements
- **Complexity**: LOW
- **Value**: Incremental

**My advice**: Pause after Phase 4, use the system for 1-2 months, THEN decide if Phase 5 is worth it.

---

### Critical Success Factors

**1. Start with real use cases**
- Don't build for hypothetical needs
- Use your actual investigations
- Let usage drive features

**2. Get team feedback early**
- Deploy Streamlit UI (week 4-6)
- Have team use it
- See what they actually need vs what you think they need

**3. Don't over-engineer**
- Streamlit is fine for internal tools
- Don't need React if Streamlit works
- YAGNI (You Aren't Gonna Need It)

**4. Budget for LLM costs**
- Can add up quickly if not careful
- Cache aggressively
- Use cheaper models where possible

**5. Document as you go**
- Your future self will thank you
- Team needs docs to onboard
- API docs enable power users

---

### What to Build NEXT (After Reading This)

**Immediate Next Step**: Phase 0+1 Combined (Weeks 1-3)

**Concrete action plan**:

1. **Day 1-2**: Refactor existing code
   - Create proper module structure
   - Fix imports
   - Add error handling

2. **Day 3-5**: Add FBI Vault + Federal Register
   - Create adapters (copy SAM.gov pattern)
   - Test searches work
   - Verify results are correct

3. **Day 6-8**: Build Boolean Monitor
   - Load keyword database
   - Create monitor config system
   - Build scheduler (cron or APScheduler)
   - Implement email alerts

4. **Day 9-10**: Set up NVE monitor
   - Use your "nihilistic violent extremism" example
   - Configure sources (FBI, DHS, News, Reddit)
   - Set alert rules
   - Test end-to-end

5. **Day 11-15**: Run in production
   - Monitor runs daily
   - You receive emails
   - Fix any bugs
   - Tune relevance scoring

**End of Week 3**: You have automated intel flowing to your inbox daily.

**Then**: Show your team, get feedback, decide on Phase 2 (Streamlit UI).

---

## CONCLUSION

### What You Have (Amazing Foundation)

You've already built:
âœ… Sophisticated agentic search system
âœ… Multi-database integration framework
âœ… Tag taxonomy (440 tags)
âœ… Keyword database (1,216 keywords)
âœ… Several working integrations (SAM.gov, DVIDS, Discord)

**This is 60% of the platform already done!**

### What You Need (Fill the Gaps)

ğŸš€ Automated monitoring (Boolean queries + alerts)
ğŸš€ Natural language interface (make it accessible)
ğŸš€ Social media integration (Reddit, Twitter, Telegram)
ğŸš€ AI analysis (synthesis, entities, timelines)
ğŸš€ Team collaboration UI (for non-technical users)

### My Recommended Path

1. **Phase 0+1** (Weeks 1-3): Monitoring MVP â†’ Proves immediate value
2. **Phase 2** (Weeks 4-6): Simple UI â†’ Enables team self-service
3. **Phase 3** (Weeks 7-9): Social media â†’ Expands coverage
4. **Phase 4** (Weeks 10-12): AI analysis â†’ "Wow factor"
5. **DECISION POINT**: Evaluate, then Phase 5 or iterate

### Budget

**Minimum**: $50-100/month (free tiers + basic LLM)
**Realistic**: $200-300/month (comfortable scaling)
**Development time**: 3 months full-time OR 6-8 months part-time

### Final Thought

> **You don't need to build everything at once.**

Start with **Phase 0+1** (automated monitoring). It's the highest value-to-effort ratio:
- Immediate utility (daily intel emails)
- Low complexity (extend what you have)
- Proves the concept
- Builds momentum

Then iterate based on **real usage and team feedback**.

**Ready to start?** I can build Phase 0+1 with you right now. We can have automated NVE monitoring running within a week.

---

## PART 10: Knowledge Graph & Entity Extraction (Separate Repository)

### Overview

A **standalone investigative wiki system** with entity extraction and knowledge graph capabilities is being developed in parallel at:

**Location**: `/home/brian/projects/investigative_wiki/`

**Repository Status**: Separate standalone repository (not integrated with sam_gov)

**Current Phase**: Stage 0 validation (testing GPT-Researcher for investigative journalism use case)

### Why Separated?

The wiki project was originally planned as part of sam_gov but was separated to:

1. **Validate core assumptions independently** - Test if entity-based organization helps investigative work before investing in integration
2. **De-risk LLM extraction quality** - Prove LLM entity extraction works (Stage 1-3) before coupling to multi-source complexity
3. **Avoid circular dependencies** - Build and validate knowledge graph concept without sam_gov's deep_research.py dependencies
4. **Prevent scope creep** - Keep sam_gov focused on multi-source research; keep wiki focused on knowledge organization

### What It Does (Target Architecture)

The investigative wiki transforms **single-run research outputs** into **persistent investigative memory**:

**Core Features**:
- **Entity Extraction**: LLM extracts people, organizations, offices, programs, concepts from research reports
- **Knowledge Graph**: SQLite database storing entities, evidence snippets, claims (subject-predicate-object triples)
- **Entity Pivoting**: Query "show all J-2 mentions across all investigations" - cross-lead entity tracking
- **Lead Organization**: Investigations organized as "Leads" (case files) with persistent graphs
- **Source Traceability**: Every claim anchored to evidence snippet â†’ source URL (epistemic nihilism: "what is claimed where")

**What It Does NOT Do**:
- âŒ Research generation (uses external engines like GPT-Researcher)
- âŒ Truth adjudication (no fact-checking - just claim tracking)
- âŒ Multi-source orchestration (that's sam_gov's job)

### Integration Path (If Standalone Proves Valuable)

**Current Standalone Approach**:
```python
class GPTResearcherClient(ResearchClient):
    async def run_research(self, query, params):
        researcher = GPTResearcher(query=query, **params)
        await researcher.conduct_research()
        report = await researcher.write_report()
        sources = researcher.get_source_urls()
        return ResearchResult(report_md=report, citations=..., sources=...)
```

**Future Integration with sam_gov** (Phase 2+ after standalone validation):
```python
class SamGovDeepResearchClient(ResearchClient):
    """Adapter wrapping sam_gov's research/deep_research.py"""

    async def run_research(self, query, params):
        from research.deep_research import DeepResearchEngine

        engine = DeepResearchEngine(
            research_question=query,
            max_tasks=params.get('max_tasks', 5),
            max_results_per_task=params.get('max_results', 50),
            # ... Phase 3C parameters
        )

        result = await engine.run()

        # Transform Phase 3C output â†’ ResearchResult format
        return ResearchResult(
            report_md=result['report'],
            citations=result['evidence'],
            sources=result['sources']
        )
```

**Integration Effort**: ~10-12 hours
- Create `SamGovDeepResearchClient` adapter (2-3 hours)
- Update wiki ingestion to handle Phase 3C output format (1-2 hours)
- Extend entity extraction for government-specific types: `contract`, `solicitation`, `job_posting`, `military_unit` (2-3 hours)
- Add government-specific predicates: `awarded_to`, `posted_by`, `requires_clearance` (2-3 hours)
- Test integration end-to-end (2-3 hours)

### What You'd Gain from Integration

**Current sam_gov limitation**: Results are ephemeral JSON files, no persistent memory

**With wiki integration**:
- All SAM/DVIDS/USAJobs/Twitter results automatically become `evidence` rows with extracted `entities`
- Cross-investigation queries: "Show all government contractors mentioned in SAM.gov results linked to psychological operations"
- Entity tracking: "Which entities appear in both my J-2 investigation AND my contractor fraud lead?"
- Pattern discovery: "Who are the bridge entities connecting multiple themes?"
- Timeline views: "All J-2 directors mentioned since 2001 with their associated programs"

### Current Status & Timeline

**Phased Validation Approach** (no big-bang):

- **Stage 0** (2 hours, ZERO code): Validate GPT-Researcher works for investigative journalism
  - Status: Ready to execute
  - Decision gate: GO/TRY_DEERFLOW/STOP

- **Stage 1** (2 hours, manual): Manually extract entities, test if entity pivoting is useful
  - Status: Awaiting Stage 0 completion
  - Decision gate: GO/STOP

- **Stage 2** (4-6 hours): 3-table SQLite + CLI (evidence, entities, evidence_entities)
  - Status: Schema designed (poc/schema_stage2.sql)
  - Decision gate: GO/MAINTAIN/STOP

- **Stage 3** (4-6 hours): LLM entity extraction (eliminate manual CSV creation)
  - Decision gate: GO/TUNE/STOP

- **Full PoC** (6-8 hours): Add leads, research_runs, sources tables + GPT-Researcher integration

- **V1** (20-25 hours): Add claims, predicates, entity_aliases + multi-lead support + Web UI

**Total Standalone Effort**: ~40-50 hours across 5 validation stages

**Integration Timeline**: Only after Full PoC/V1 proves standalone value (weeks-months from now)

### Database Schema Compatibility

**Key Design Decision**: Wiki database schema is **research-engine-agnostic**

Tables are identical whether using:
- GPT-Researcher (web-only, Tavily/Brave search)
- sam_gov deep_research.py (SAM/DVIDS/USAJobs/Twitter via MCP)

**Shared Schema**:
- `leads` (investigation case files)
- `research_runs` (each has `engine` field: "gpt-researcher" | "sam-gov-deep-research")
- `sources` (URLs/documents)
- `evidence` (text snippets)
- `entities` (people, orgs, offices, programs, concepts)
- `claims` (subject-predicate-object triples anchored to evidence)
- `predicates` (held_role, part_of, mentioned_with, etc.)

Only difference: `ResearchRun.engine` field changes + evidence extraction logic adapts to output format

### Decision: When to Integrate?

**DO NOT integrate until**:
- âœ… Stage 1 validates entity organization is useful
- âœ… Stage 3 validates LLM extraction quality is good (80%+ accuracy)
- âœ… Full PoC validates end-to-end automation works
- âœ… User has used V1 wiki for 5-10 real investigations successfully

**Premature integration risks**:
- Wasted effort if entity extraction doesn't prove valuable
- Coupling to unvalidated LLM extraction quality
- Scope creep contaminating both repos

**Right time to integrate**: After standalone proves "entity pivoting across investigations" is genuinely useful for investigative journalism workflow (weeks-months from now, not days)

### References

**Standalone Wiki Documentation**:
- `/home/brian/projects/investigative_wiki/README.md` - Project overview
- `/home/brian/projects/investigative_wiki/v3_STANDALONE.md` - Primary design doc (518 lines)
- `/home/brian/projects/investigative_wiki/v3_INTEGRATED_FUTURE.md` - Integration patterns reference (for Phase 2+)
- `/home/brian/projects/investigative_wiki/poc/` - Stage 0-3 validation guides

**sam_gov Deep Research**:
- `research/deep_research.py` - Phase 3C: Hypothesis generation, sequential task execution, coverage assessment
- `core/agentic_executor.py` - Multi-database parallel search with LLM refinement
- `integrations/mcp/` - MCP-based government/social database integrations

---

## CONCLUSION

### What You Have (Amazing Foundation)
