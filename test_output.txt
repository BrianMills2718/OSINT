2025-10-20 19:48:18,060 - asyncio - DEBUG - Using selector: EpollSelector
2025-10-20 19:48:18,100 - AIResearchTest - INFO - Registry loaded: 7 sources available
2025-10-20 19:48:18,100 - AIResearchTest - INFO - Sources: ['sam', 'dvids', 'usajobs', 'clearancejobs', 'fbi_vault', 'discord', 'twitter']
2025-10-20 19:48:18,101 - AIResearchTest - INFO - Calling LLM for source selection...
[92m19:48:18 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:18,101 - LiteLLM - DEBUG - 

[92m19:48:18 - LiteLLM:DEBUG[0m: utils.py:349 - [92mRequest to litellm:[0m
2025-10-20 19:48:18,101 - LiteLLM - DEBUG - [92mRequest to litellm:[0m
[92m19:48:18 - LiteLLM:DEBUG[0m: utils.py:349 - [92mlitellm.responses(model='gpt-5-mini', input='You are a research assistant with access to multiple databases.\n\nAvailable Databases:\n[\n  {\n    "id": "sam",\n    "name": "SAM.gov",\n    "category": "contracts",\n    "description": "U.S. federal government contracting opportunities and solicitations",\n    "requires_api_key": true,\n    "typical_response_time": 2.5\n  },\n  {\n    "id": "dvids",\n    "name": "DVIDS",\n    "category": "media",\n    "description": "U.S. military photos, videos, and news from Department of Defense",\n    "requires_api_key": true,\n    "typical_response_time": 2.0\n  },\n  {\n    "id": "usajobs",\n    "name": "USAJobs",\n    "category": "jobs",\n    "description": "Official U.S. federal government job listings across all agencies",\n    "requires_api_key": true,\n    "typical_response_time": 2.0\n  },\n  {\n    "id": "clearancejobs",\n    "name": "ClearanceJobs",\n    "category": "jobs",\n    "description": "Security clearance job postings requiring TS/SCI, Secret, Top Secret, and other clearances",\n    "requires_api_key": false,\n    "typical_response_time": 5.0\n  },\n  {\n    "id": "fbi_vault",\n    "name": "FBI Vault",\n    "category": "government_fbi",\n    "description": "FBI FOIA document releases and investigation files",\n    "requires_api_key": false,\n    "typical_response_time": 3.0\n  },\n  {\n    "id": "discord",\n    "name": "Discord",\n    "category": "social_general",\n    "description": "Discord community discussions from Bellingcat, Project OWL, and other OSINT servers",\n    "requires_api_key": false,\n    "typical_response_time": 0.5\n  },\n  {\n    "id": "twitter",\n    "name": "Twitter",\n    "category": "social_twitter",\n    "description": "Twitter search for tweets, users, and social media intelligence",\n    "requires_api_key": true,\n    "typical_response_time": 3.0\n  }\n]\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nTask: Select EVERY database that could provide relevant information for this research question.\n\n\nIMPORTANT:\n- Include EVERY database that might have relevant information\n- Only exclude databases that are clearly irrelevant\n- Cast a very wide net - when in doubt, include it\n- Keep keywords simple and focused\n\n\nFor each selected database, provide:\n- source_id: The database ID (must match an id from Available Databases list)\n- keywords: Search keywords (1-3 focused terms, NOT a sentence)\n- reasoning: Why this database is relevant (1 sentence)\n\nReturn JSON array of selected sources.', text={'format': {'type': 'json_schema', 'name': 'source_selection', 'schema': {'type': 'object', 'properties': {'selected_sources': {'type': 'array', 'items': {'type': 'object', 'properties': {'source_id': {'type': 'string'}, 'keywords': {'type': 'string'}, 'reasoning': {'type': 'string'}}, 'required': ['source_id', 'keywords', 'reasoning'], 'additionalProperties': False}, 'minItems': 1, 'maxItems': 10}, 'research_strategy': {'type': 'string'}}, 'required': ['selected_sources', 'research_strategy'], 'additionalProperties': False}, 'strict': True}})[0m
2025-10-20 19:48:18,101 - LiteLLM - DEBUG - [92mlitellm.responses(model='gpt-5-mini', input='You are a research assistant with access to multiple databases.\n\nAvailable Databases:\n[\n  {\n    "id": "sam",\n    "name": "SAM.gov",\n    "category": "contracts",\n    "description": "U.S. federal government contracting opportunities and solicitations",\n    "requires_api_key": true,\n    "typical_response_time": 2.5\n  },\n  {\n    "id": "dvids",\n    "name": "DVIDS",\n    "category": "media",\n    "description": "U.S. military photos, videos, and news from Department of Defense",\n    "requires_api_key": true,\n    "typical_response_time": 2.0\n  },\n  {\n    "id": "usajobs",\n    "name": "USAJobs",\n    "category": "jobs",\n    "description": "Official U.S. federal government job listings across all agencies",\n    "requires_api_key": true,\n    "typical_response_time": 2.0\n  },\n  {\n    "id": "clearancejobs",\n    "name": "ClearanceJobs",\n    "category": "jobs",\n    "description": "Security clearance job postings requiring TS/SCI, Secret, Top Secret, and other clearances",\n    "requires_api_key": false,\n    "typical_response_time": 5.0\n  },\n  {\n    "id": "fbi_vault",\n    "name": "FBI Vault",\n    "category": "government_fbi",\n    "description": "FBI FOIA document releases and investigation files",\n    "requires_api_key": false,\n    "typical_response_time": 3.0\n  },\n  {\n    "id": "discord",\n    "name": "Discord",\n    "category": "social_general",\n    "description": "Discord community discussions from Bellingcat, Project OWL, and other OSINT servers",\n    "requires_api_key": false,\n    "typical_response_time": 0.5\n  },\n  {\n    "id": "twitter",\n    "name": "Twitter",\n    "category": "social_twitter",\n    "description": "Twitter search for tweets, users, and social media intelligence",\n    "requires_api_key": true,\n    "typical_response_time": 3.0\n  }\n]\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nTask: Select EVERY database that could provide relevant information for this research question.\n\n\nIMPORTANT:\n- Include EVERY database that might have relevant information\n- Only exclude databases that are clearly irrelevant\n- Cast a very wide net - when in doubt, include it\n- Keep keywords simple and focused\n\n\nFor each selected database, provide:\n- source_id: The database ID (must match an id from Available Databases list)\n- keywords: Search keywords (1-3 focused terms, NOT a sentence)\n- reasoning: Why this database is relevant (1 sentence)\n\nReturn JSON array of selected sources.', text={'format': {'type': 'json_schema', 'name': 'source_selection', 'schema': {'type': 'object', 'properties': {'selected_sources': {'type': 'array', 'items': {'type': 'object', 'properties': {'source_id': {'type': 'string'}, 'keywords': {'type': 'string'}, 'reasoning': {'type': 'string'}}, 'required': ['source_id', 'keywords', 'reasoning'], 'additionalProperties': False}, 'minItems': 1, 'maxItems': 10}, 'research_strategy': {'type': 'string'}}, 'required': ['selected_sources', 'research_strategy'], 'additionalProperties': False}, 'strict': True}})[0m
[92m19:48:18 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:18,101 - LiteLLM - DEBUG - 

[92m19:48:18 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {}
2025-10-20 19:48:18,101 - LiteLLM - DEBUG - self.optional_params: {}
[92m19:48:18 - LiteLLM:DEBUG[0m: utils.py:349 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-10-20 19:48:18,101 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
[92m19:48:18 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'source_selection', 'schema': {'type': 'object', 'properties': {'selected_sources': {'type': 'array', 'items': {'type': 'object', 'properties': {'source_id': {'type': 'string'}, 'keywords': {'type': 'string'}, 'reasoning': {'type': 'string'}}, 'required': ['source_id', 'keywords', 'reasoning'], 'additionalProperties': False}, 'minItems': 1, 'maxItems': 10}, 'research_strategy': {'type': 'string'}}, 'required': ['selected_sources', 'research_strategy'], 'additionalProperties': False}, 'strict': True}}}
2025-10-20 19:48:18,102 - LiteLLM - DEBUG - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'source_selection', 'schema': {'type': 'object', 'properties': {'selected_sources': {'type': 'array', 'items': {'type': 'object', 'properties': {'source_id': {'type': 'string'}, 'keywords': {'type': 'string'}, 'reasoning': {'type': 'string'}}, 'required': ['source_id', 'keywords', 'reasoning'], 'additionalProperties': False}, 'minItems': 1, 'maxItems': 10}, 'research_strategy': {'type': 'string'}}, 'required': ['selected_sources', 'research_strategy'], 'additionalProperties': False}, 'strict': True}}}
[92m19:48:18 - LiteLLM:DEBUG[0m: litellm_logging.py:921 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'You are a research assistant with access to multiple databases.\n\nAvailable Databases:\n[\n  {\n    "id": "sam",\n    "name": "SAM.gov",\n    "category": "contracts",\n    "description": "U.S. federal government contracting opportunities and solicitations",\n    "requires_api_key": true,\n    "typical_response_time": 2.5\n  },\n  {\n    "id": "dvids",\n    "name": "DVIDS",\n    "category": "media",\n    "description": "U.S. military photos, videos, and news from Department of Defense",\n    "requires_api_key": true,\n    "typical_response_time": 2.0\n  },\n  {\n    "id": "usajobs",\n    "name": "USAJobs",\n    "category": "jobs",\n    "description": "Official U.S. federal government job listings across all agencies",\n    "requires_api_key": true,\n    "typical_response_time": 2.0\n  },\n  {\n    "id": "clearancejobs",\n    "name": "ClearanceJobs",\n    "category": "jobs",\n    "description": "Security clearance job postings requiring TS/SCI, Secret, Top Secret, and other clearances",\n    "requires_api_key": false,\n    "typical_response_time": 5.0\n  },\n  {\n    "id": "fbi_vault",\n    "name": "FBI Vault",\n    "category": "government_fbi",\n    "description": "FBI FOIA document releases and investigation files",\n    "requires_api_key": false,\n    "typical_response_time": 3.0\n  },\n  {\n    "id": "discord",\n    "name": "Discord",\n    "category": "social_general",\n    "description": "Discord community discussions from Bellingcat, Project OWL, and other OSINT servers",\n    "requires_api_key": false,\n    "typical_response_time": 0.5\n  },\n  {\n    "id": "twitter",\n    "name": "Twitter",\n    "category": "social_twitter",\n    "description": "Twitter search for tweets, users, and social media intelligence",\n    "requires_api_key": true,\n    "typical_response_time": 3.0\n  }\n]\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nTask: Select EVERY database that could provide relevant information for this research question.\n\n\nIMPORTANT:\n- Include EVERY database that might have relevant information\n- Only exclude databases that are clearly irrelevant\n- Cast a very wide net - when in doubt, include it\n- Keep keywords simple and focused\n\n\nFor each selected database, provide:\n- source_id: The database ID (must match an id from Available Databases list)\n- keywords: Search keywords (1-3 focused terms, NOT a sentence)\n- reasoning: Why this database is relevant (1 sentence)\n\nReturn JSON array of selected sources.', 'text': {'format': {'type': 'json_schema', 'name': 'source_selection', 'schema': {'type': 'object', 'properties': {'selected_sources': {'type': 'array', 'items': {'type': 'object', 'properties': {'source_id': {'type': 'string'}, 'keywords': {'type': 'string'}, 'reasoning': {'type': 'string'}}, 'required': ['source_id', 'keywords', 'reasoning'], 'additionalProperties': False}, 'minItems': 1, 'maxItems': 10}, 'research_strategy': {'type': 'string'}}, 'required': ['selected_sources', 'research_strategy'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:18,121 - LiteLLM - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'You are a research assistant with access to multiple databases.\n\nAvailable Databases:\n[\n  {\n    "id": "sam",\n    "name": "SAM.gov",\n    "category": "contracts",\n    "description": "U.S. federal government contracting opportunities and solicitations",\n    "requires_api_key": true,\n    "typical_response_time": 2.5\n  },\n  {\n    "id": "dvids",\n    "name": "DVIDS",\n    "category": "media",\n    "description": "U.S. military photos, videos, and news from Department of Defense",\n    "requires_api_key": true,\n    "typical_response_time": 2.0\n  },\n  {\n    "id": "usajobs",\n    "name": "USAJobs",\n    "category": "jobs",\n    "description": "Official U.S. federal government job listings across all agencies",\n    "requires_api_key": true,\n    "typical_response_time": 2.0\n  },\n  {\n    "id": "clearancejobs",\n    "name": "ClearanceJobs",\n    "category": "jobs",\n    "description": "Security clearance job postings requiring TS/SCI, Secret, Top Secret, and other clearances",\n    "requires_api_key": false,\n    "typical_response_time": 5.0\n  },\n  {\n    "id": "fbi_vault",\n    "name": "FBI Vault",\n    "category": "government_fbi",\n    "description": "FBI FOIA document releases and investigation files",\n    "requires_api_key": false,\n    "typical_response_time": 3.0\n  },\n  {\n    "id": "discord",\n    "name": "Discord",\n    "category": "social_general",\n    "description": "Discord community discussions from Bellingcat, Project OWL, and other OSINT servers",\n    "requires_api_key": false,\n    "typical_response_time": 0.5\n  },\n  {\n    "id": "twitter",\n    "name": "Twitter",\n    "category": "social_twitter",\n    "description": "Twitter search for tweets, users, and social media intelligence",\n    "requires_api_key": true,\n    "typical_response_time": 3.0\n  }\n]\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nTask: Select EVERY database that could provide relevant information for this research question.\n\n\nIMPORTANT:\n- Include EVERY database that might have relevant information\n- Only exclude databases that are clearly irrelevant\n- Cast a very wide net - when in doubt, include it\n- Keep keywords simple and focused\n\n\nFor each selected database, provide:\n- source_id: The database ID (must match an id from Available Databases list)\n- keywords: Search keywords (1-3 focused terms, NOT a sentence)\n- reasoning: Why this database is relevant (1 sentence)\n\nReturn JSON array of selected sources.', 'text': {'format': {'type': 'json_schema', 'name': 'source_selection', 'schema': {'type': 'object', 'properties': {'selected_sources': {'type': 'array', 'items': {'type': 'object', 'properties': {'source_id': {'type': 'string'}, 'keywords': {'type': 'string'}, 'reasoning': {'type': 'string'}}, 'required': ['source_id', 'keywords', 'reasoning'], 'additionalProperties': False}, 'minItems': 1, 'maxItems': 10}, 'research_strategy': {'type': 'string'}}, 'required': ['selected_sources', 'research_strategy'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:18,122 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=6000.0 socket_options=None
2025-10-20 19:48:18,241 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b13696d80>
2025-10-20 19:48:18,241 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x735b13061850> server_hostname='api.openai.com' timeout=6000.0
2025-10-20 19:48:18,683 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b13051ee0>
2025-10-20 19:48:18,683 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-10-20 19:48:18,683 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-10-20 19:48:18,683 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-10-20 19:48:18,683 - httpcore.http11 - DEBUG - send_request_body.complete
2025-10-20 19:48:18,684 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-10-20 19:48:41,111 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 21 Oct 2025 02:48:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999088'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'quickgpts'), (b'openai-project', b'proj_tta1tTpO1Yd49KEelsEZTSjW'), (b'x-request-id', b'req_12819be2b2df45b89618fb11fa04345d'), (b'openai-processing-ms', b'20928'), (b'x-envoy-upstream-service-time', b'20935'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=LstUstCsZHRb.RrhwfhnvR3BbrMJ.tdMc52bwR6Yuao-1761014922-1.0.1.1-hFcYqzoBizL6BFHZB9sD1ONQq56GaQyd76kp4hTGhjky6R0HNFWNKQOo5tLXDE7qksrt1UqJGqacRMzaNIJAi.ExvjOhIs.tLyezBMUptXw; path=/; expires=Tue, 21-Oct-25 03:18:42 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=4m0fSXHTgfld.sGb2YPNL7_.OY2W0BKs.4ZfFx5yzO8-1761014922568-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'991d6f7eafe3d9a9-MIA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-20 19:48:41,112 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-10-20 19:48:41,112 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-10-20 19:48:41,112 - httpcore.http11 - DEBUG - response_closed.started
2025-10-20 19:48:41,112 - httpcore.http11 - DEBUG - response_closed.complete
[92m19:48:41 - LiteLLM:INFO[0m: utils.py:1262 - Wrapper: Completed Call, calling success_handler
2025-10-20 19:48:41,113 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:1594 - Logging Details LiteLLM-Success Call: Cache_hit=None
[92m19:48:41 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
2025-10-20 19:48:41,113 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
[92m19:48:41 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
2025-10-20 19:48:41,114 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:41,115 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:41,115 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:41,115 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:41,115 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.0026197499999999997
2025-10-20 19:48:41,115 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.0026197499999999997
2025-10-20 19:48:41,116 - LiteLLM - DEBUG - response_cost: 0.0026197499999999997
2025-10-20 19:48:41,116 - LiteLLM - DEBUG - response_cost: 0.0026197499999999997
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:41,116 - AIResearchTest - INFO - LLM selected 7 sources
2025-10-20 19:48:41,116 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:41,117 - AIResearchTest - INFO - ================================================================================
2025-10-20 19:48:41,117 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:41,117 - AIResearchTest - INFO - Starting search for source: sam
2025-10-20 19:48:41,117 - AIResearchTest - INFO - Research question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc
2025-10-20 19:48:41,117 - AIResearchTest - INFO - Integration: SAM.gov
2025-10-20 19:48:41,117 - AIResearchTest - INFO - API key found: SAM-db0e80...
2025-10-20 19:48:41,117 - AIResearchTest - INFO - Generating query parameters...
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,118 - AIResearchTest - INFO - ================================================================================
2025-10-20 19:48:41,118 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mRequest to litellm:[0m
2025-10-20 19:48:41,118 - AIResearchTest - INFO - Starting search for source: dvids
2025-10-20 19:48:41,118 - LiteLLM - DEBUG - [92mRequest to litellm:[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mlitellm.responses(model='gpt-5-mini', input='User: You are a search query generator for SAM.gov, the U.S. federal government contracting opportunities system.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the SAM.gov API:\n- keywords: Search terms for opportunity titles/descriptions (string, keep focused)\n- procurement_types: Types of procurement (array from: "Solicitation", "Presolicitation", "Combined Synopsis/Solicitation", "Sources Sought")\n- set_aside: Small business set-aside type (string from: null, "SBA" (Total Small Business), "8A", "SDVOSBC" (Service-Disabled Veteran), "WOSB" (Women-Owned), "HZC" (HUBZone), or null for none)\n- naics_codes: Industry classification codes if relevant (array of strings like ["541512", "541519"], or empty array)\n- organization: Specific agency/organization if mentioned (string or null)\n- date_range_days: How many days back to search (integer 1-365, default 60)\n\nGuidelines:\n- keywords: Use industry/procurement-specific terms\n- procurement_types: Include all types unless specifically requested (e.g., "RFPs only" → ["Solicitation"])\n- set_aside: Only ONE allowed per query, use null if not specified\n- naics_codes: Common codes:\n  * 541512 - Computer Systems Design Services\n  * 541519 - Other Computer Related Services\n  * 541611 - Administrative Management Consulting\n  * 541990 - All Other Professional Services\n  * 334111 - Electronic Computer Manufacturing\n  * 518210 - Data Processing Services\n- organization: Only specify if question mentions specific agency (e.g., "DoD", "FBI", "VA")\n- date_range_days: Use 30 for "recent", 60 for default, 90 for "past few months"\n\nIMPORTANT: SAM.gov REQUIRES a date range and it cannot exceed 365 days.\n\nIf this question is not about government contracts or procurement, return relevant: false.\n\nReturn JSON with these exact fields. Use empty arrays for optional list fields and null for optional single fields.\n\nExample 1:\nQuestion: "What cybersecurity contracts are available from DoD?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "cybersecurity",\n  "procurement_types": [],\n  "set_aside": null,\n  "naics_codes": ["541512", "541519"],\n  "organization": "Department of Defense",\n  "date_range_days": 60,\n  "reasoning": "DoD cybersecurity contracting opportunities"\n}\n\nExample 2:\nQuestion: "Recent small business IT solicitations"\nResponse:\n{\n  "relevant": true,\n  "keywords": "IT information technology",\n  "procurement_types": ["Solicitation"],\n  "set_aside": "SBA",\n  "naics_codes": ["541512", "541519"],\n  "organization": null,\n  "date_range_days": 30,\n  "reasoning": "Recent IT solicitations for small businesses"\n}\n\nExample 3:\nQuestion: "What military jobs require security clearances?"\nResponse:\n{\n  "relevant": false,\n  "keywords": "",\n  "procurement_types": [],\n  "set_aside": null,\n  "naics_codes": [],\n  "organization": null,\n  "date_range_days": 60,\n  "reasoning": "Question is about jobs, not contracts"\n}\n', text={'format': {'type': 'json_schema', 'name': 'sam_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for opportunity titles and descriptions'}, 'procurement_types': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of procurement types, empty if not specified'}, 'set_aside': {'type': ['string', 'null'], 'description': 'Set-aside type code or null'}, 'naics_codes': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of NAICS codes, empty if not specified'}, 'organization': {'type': ['string', 'null'], 'description': 'Agency/organization name or null'}, 'date_range_days': {'type': 'integer', 'description': 'Days back to search, 1-365', 'minimum': 1, 'maximum': 365}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'procurement_types', 'set_aside', 'naics_codes', 'organization', 'date_range_days', 'reasoning'], 'additionalProperties': False}, 'strict': True}})[0m
2025-10-20 19:48:41,118 - AIResearchTest - INFO - Research question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc
2025-10-20 19:48:41,118 - LiteLLM - DEBUG - [92mlitellm.responses(model='gpt-5-mini', input='User: You are a search query generator for SAM.gov, the U.S. federal government contracting opportunities system.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the SAM.gov API:\n- keywords: Search terms for opportunity titles/descriptions (string, keep focused)\n- procurement_types: Types of procurement (array from: "Solicitation", "Presolicitation", "Combined Synopsis/Solicitation", "Sources Sought")\n- set_aside: Small business set-aside type (string from: null, "SBA" (Total Small Business), "8A", "SDVOSBC" (Service-Disabled Veteran), "WOSB" (Women-Owned), "HZC" (HUBZone), or null for none)\n- naics_codes: Industry classification codes if relevant (array of strings like ["541512", "541519"], or empty array)\n- organization: Specific agency/organization if mentioned (string or null)\n- date_range_days: How many days back to search (integer 1-365, default 60)\n\nGuidelines:\n- keywords: Use industry/procurement-specific terms\n- procurement_types: Include all types unless specifically requested (e.g., "RFPs only" → ["Solicitation"])\n- set_aside: Only ONE allowed per query, use null if not specified\n- naics_codes: Common codes:\n  * 541512 - Computer Systems Design Services\n  * 541519 - Other Computer Related Services\n  * 541611 - Administrative Management Consulting\n  * 541990 - All Other Professional Services\n  * 334111 - Electronic Computer Manufacturing\n  * 518210 - Data Processing Services\n- organization: Only specify if question mentions specific agency (e.g., "DoD", "FBI", "VA")\n- date_range_days: Use 30 for "recent", 60 for default, 90 for "past few months"\n\nIMPORTANT: SAM.gov REQUIRES a date range and it cannot exceed 365 days.\n\nIf this question is not about government contracts or procurement, return relevant: false.\n\nReturn JSON with these exact fields. Use empty arrays for optional list fields and null for optional single fields.\n\nExample 1:\nQuestion: "What cybersecurity contracts are available from DoD?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "cybersecurity",\n  "procurement_types": [],\n  "set_aside": null,\n  "naics_codes": ["541512", "541519"],\n  "organization": "Department of Defense",\n  "date_range_days": 60,\n  "reasoning": "DoD cybersecurity contracting opportunities"\n}\n\nExample 2:\nQuestion: "Recent small business IT solicitations"\nResponse:\n{\n  "relevant": true,\n  "keywords": "IT information technology",\n  "procurement_types": ["Solicitation"],\n  "set_aside": "SBA",\n  "naics_codes": ["541512", "541519"],\n  "organization": null,\n  "date_range_days": 30,\n  "reasoning": "Recent IT solicitations for small businesses"\n}\n\nExample 3:\nQuestion: "What military jobs require security clearances?"\nResponse:\n{\n  "relevant": false,\n  "keywords": "",\n  "procurement_types": [],\n  "set_aside": null,\n  "naics_codes": [],\n  "organization": null,\n  "date_range_days": 60,\n  "reasoning": "Question is about jobs, not contracts"\n}\n', text={'format': {'type': 'json_schema', 'name': 'sam_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for opportunity titles and descriptions'}, 'procurement_types': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of procurement types, empty if not specified'}, 'set_aside': {'type': ['string', 'null'], 'description': 'Set-aside type code or null'}, 'naics_codes': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of NAICS codes, empty if not specified'}, 'organization': {'type': ['string', 'null'], 'description': 'Agency/organization name or null'}, 'date_range_days': {'type': 'integer', 'description': 'Days back to search, 1-365', 'minimum': 1, 'maximum': 365}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'procurement_types', 'set_aside', 'naics_codes', 'organization', 'date_range_days', 'reasoning'], 'additionalProperties': False}, 'strict': True}})[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,118 - AIResearchTest - INFO - Integration: DVIDS
2025-10-20 19:48:41,119 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {}
2025-10-20 19:48:41,119 - AIResearchTest - INFO - API key found: key-68f319...
2025-10-20 19:48:41,119 - LiteLLM - DEBUG - self.optional_params: {}
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-10-20 19:48:41,119 - AIResearchTest - INFO - Generating query parameters...
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,119 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'sam_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for opportunity titles and descriptions'}, 'procurement_types': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of procurement types, empty if not specified'}, 'set_aside': {'type': ['string', 'null'], 'description': 'Set-aside type code or null'}, 'naics_codes': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of NAICS codes, empty if not specified'}, 'organization': {'type': ['string', 'null'], 'description': 'Agency/organization name or null'}, 'date_range_days': {'type': 'integer', 'description': 'Days back to search, 1-365', 'minimum': 1, 'maximum': 365}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'procurement_types', 'set_aside', 'naics_codes', 'organization', 'date_range_days', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}
2025-10-20 19:48:41,120 - AIResearchTest - INFO - ================================================================================
2025-10-20 19:48:41,120 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mRequest to litellm:[0m
2025-10-20 19:48:41,120 - LiteLLM - DEBUG - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'sam_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for opportunity titles and descriptions'}, 'procurement_types': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of procurement types, empty if not specified'}, 'set_aside': {'type': ['string', 'null'], 'description': 'Set-aside type code or null'}, 'naics_codes': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of NAICS codes, empty if not specified'}, 'organization': {'type': ['string', 'null'], 'description': 'Agency/organization name or null'}, 'date_range_days': {'type': 'integer', 'description': 'Days back to search, 1-365', 'minimum': 1, 'maximum': 365}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'procurement_types', 'set_aside', 'naics_codes', 'organization', 'date_range_days', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}
2025-10-20 19:48:41,120 - AIResearchTest - INFO - Starting search for source: usajobs
2025-10-20 19:48:41,120 - LiteLLM - DEBUG - [92mRequest to litellm:[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mlitellm.responses(model='gpt-5-mini', input='User: You are a search query generator for DVIDS, the U.S. military\'s media distribution service.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the DVIDS API:\n- keywords: Search terms for media titles/descriptions (string, keep concise)\n- media_types: Types of media to search (array from: "image", "video", "news")\n- branches: Military branches (array from: "Army", "Navy", "Air Force", "Marines", "Coast Guard", "Joint")\n- country: Country if specified (string, e.g., "United States", "Germany", "Japan")\n- from_date: Start date if recency mentioned (YYYY-MM-DD format, or null)\n- to_date: End date if specified (YYYY-MM-DD format, or null)\n\nGuidelines:\n- keywords: Use military-specific terms, avoid very long queries\n- media_types: Include all types unless specifically requested (e.g., "photos only" → ["image"])\n- branches: Only specify if the question mentions specific branches\n- dates: Only filter by date if recency is mentioned (e.g., "recent", "2024", "last month")\n- country: Only specify if the question mentions a specific country or location\n\nIf this question is not about military media or content, return relevant: false.\n\nReturn JSON with these exact fields. Use empty arrays for optional list fields and null for optional date fields.\n\nExample 1:\nQuestion: "Show me recent F-35 training photos from the Air Force"\nResponse:\n{\n  "relevant": true,\n  "keywords": "F-35 training",\n  "media_types": ["image"],\n  "branches": ["Air Force"],\n  "country": null,\n  "from_date": "2024-10-01",\n  "to_date": null,\n  "reasoning": "Recent Air Force F-35 training imagery"\n}\n\nExample 2:\nQuestion: "What videos are available about humanitarian operations?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "humanitarian operations",\n  "media_types": ["video"],\n  "branches": [],\n  "country": null,\n  "from_date": null,\n  "to_date": null,\n  "reasoning": "Video content about humanitarian missions"\n}\n\nExample 3:\nQuestion: "What government contracts are available?"\nResponse:\n{\n  "relevant": false,\n  "keywords": "",\n  "media_types": [],\n  "branches": [],\n  "country": null,\n  "from_date": null,\n  "to_date": null,\n  "reasoning": "Question is about contracts, not military media"\n}\n', text={'format': {'type': 'json_schema', 'name': 'dvids_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for media titles and descriptions'}, 'media_types': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of media types, empty if not specified'}, 'branches': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of military branches, empty if not specified'}, 'country': {'type': ['string', 'null'], 'description': 'Country name or null'}, 'from_date': {'type': ['string', 'null'], 'description': 'Start date in YYYY-MM-DD format or null'}, 'to_date': {'type': ['string', 'null'], 'description': 'End date in YYYY-MM-DD format or null'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'media_types', 'branches', 'country', 'from_date', 'to_date', 'reasoning'], 'additionalProperties': False}, 'strict': True}})[0m
2025-10-20 19:48:41,121 - AIResearchTest - INFO - Research question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc
2025-10-20 19:48:41,121 - LiteLLM - DEBUG - [92mlitellm.responses(model='gpt-5-mini', input='User: You are a search query generator for DVIDS, the U.S. military\'s media distribution service.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the DVIDS API:\n- keywords: Search terms for media titles/descriptions (string, keep concise)\n- media_types: Types of media to search (array from: "image", "video", "news")\n- branches: Military branches (array from: "Army", "Navy", "Air Force", "Marines", "Coast Guard", "Joint")\n- country: Country if specified (string, e.g., "United States", "Germany", "Japan")\n- from_date: Start date if recency mentioned (YYYY-MM-DD format, or null)\n- to_date: End date if specified (YYYY-MM-DD format, or null)\n\nGuidelines:\n- keywords: Use military-specific terms, avoid very long queries\n- media_types: Include all types unless specifically requested (e.g., "photos only" → ["image"])\n- branches: Only specify if the question mentions specific branches\n- dates: Only filter by date if recency is mentioned (e.g., "recent", "2024", "last month")\n- country: Only specify if the question mentions a specific country or location\n\nIf this question is not about military media or content, return relevant: false.\n\nReturn JSON with these exact fields. Use empty arrays for optional list fields and null for optional date fields.\n\nExample 1:\nQuestion: "Show me recent F-35 training photos from the Air Force"\nResponse:\n{\n  "relevant": true,\n  "keywords": "F-35 training",\n  "media_types": ["image"],\n  "branches": ["Air Force"],\n  "country": null,\n  "from_date": "2024-10-01",\n  "to_date": null,\n  "reasoning": "Recent Air Force F-35 training imagery"\n}\n\nExample 2:\nQuestion: "What videos are available about humanitarian operations?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "humanitarian operations",\n  "media_types": ["video"],\n  "branches": [],\n  "country": null,\n  "from_date": null,\n  "to_date": null,\n  "reasoning": "Video content about humanitarian missions"\n}\n\nExample 3:\nQuestion: "What government contracts are available?"\nResponse:\n{\n  "relevant": false,\n  "keywords": "",\n  "media_types": [],\n  "branches": [],\n  "country": null,\n  "from_date": null,\n  "to_date": null,\n  "reasoning": "Question is about contracts, not military media"\n}\n', text={'format': {'type': 'json_schema', 'name': 'dvids_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for media titles and descriptions'}, 'media_types': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of media types, empty if not specified'}, 'branches': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of military branches, empty if not specified'}, 'country': {'type': ['string', 'null'], 'description': 'Country name or null'}, 'from_date': {'type': ['string', 'null'], 'description': 'Start date in YYYY-MM-DD format or null'}, 'to_date': {'type': ['string', 'null'], 'description': 'End date in YYYY-MM-DD format or null'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'media_types', 'branches', 'country', 'from_date', 'to_date', 'reasoning'], 'additionalProperties': False}, 'strict': True}})[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,121 - AIResearchTest - INFO - Integration: USAJobs
2025-10-20 19:48:41,121 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {}
2025-10-20 19:48:41,121 - AIResearchTest - INFO - API key found: HjEl/dTPVC...
2025-10-20 19:48:41,121 - LiteLLM - DEBUG - self.optional_params: {}
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-10-20 19:48:41,121 - AIResearchTest - INFO - Generating query parameters...
2025-10-20 19:48:41,122 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,122 - AIResearchTest - INFO - ================================================================================
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'dvids_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for media titles and descriptions'}, 'media_types': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of media types, empty if not specified'}, 'branches': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of military branches, empty if not specified'}, 'country': {'type': ['string', 'null'], 'description': 'Country name or null'}, 'from_date': {'type': ['string', 'null'], 'description': 'Start date in YYYY-MM-DD format or null'}, 'to_date': {'type': ['string', 'null'], 'description': 'End date in YYYY-MM-DD format or null'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'media_types', 'branches', 'country', 'from_date', 'to_date', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}
2025-10-20 19:48:41,122 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mRequest to litellm:[0m
2025-10-20 19:48:41,122 - AIResearchTest - INFO - Starting search for source: clearancejobs
2025-10-20 19:48:41,122 - LiteLLM - DEBUG - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'dvids_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for media titles and descriptions'}, 'media_types': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of media types, empty if not specified'}, 'branches': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of military branches, empty if not specified'}, 'country': {'type': ['string', 'null'], 'description': 'Country name or null'}, 'from_date': {'type': ['string', 'null'], 'description': 'Start date in YYYY-MM-DD format or null'}, 'to_date': {'type': ['string', 'null'], 'description': 'End date in YYYY-MM-DD format or null'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'media_types', 'branches', 'country', 'from_date', 'to_date', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}
2025-10-20 19:48:41,123 - LiteLLM - DEBUG - [92mRequest to litellm:[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mlitellm.responses(model='gpt-5-mini', input='User: You are a search query generator for USAJOBS, the official U.S. federal government job site.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the USAJOBS API:\n- keywords: Search terms for job titles/descriptions (string, keep focused)\n- location: Geographic location if specified (string like "Washington, DC" or "California" or null)\n- organization: Federal agency/organization (string like "Department of Defense", "FBI", or null)\n- pay_grade_low: Minimum GS pay grade if mentioned (integer 1-15, or null)\n- pay_grade_high: Maximum GS pay grade if mentioned (integer 1-15, or null)\n\nGuidelines:\n- keywords: Use job title or skill terms (e.g., "engineer", "analyst", "scientist")\n- location: Format as city-state or just state name, null if not mentioned\n- organization: Use full agency names, null if not specified\n- pay_grade: GS (General Schedule) grades range 1-15, where:\n  * GS-1 to GS-4: Entry-level positions\n  * GS-5 to GS-9: Junior professional positions\n  * GS-10 to GS-12: Mid-level professional positions\n  * GS-13 to GS-15: Senior professional/supervisory positions\n  Only specify if the question explicitly mentions pay grade or seniority level\n\nIf this question is not about federal government jobs or employment, return relevant: false.\n\nReturn JSON with these exact fields. Use null for optional fields.\n\nExample 1:\nQuestion: "What data science jobs are available in the DC area?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "data science",\n  "location": "Washington, DC",\n  "organization": null,\n  "pay_grade_low": null,\n  "pay_grade_high": null,\n  "reasoning": "Federal data science positions in DC area"\n}\n\nExample 2:\nQuestion: "Senior engineer positions at NASA"\nResponse:\n{\n  "relevant": true,\n  "keywords": "engineer",\n  "location": null,\n  "organization": "NASA",\n  "pay_grade_low": 13,\n  "pay_grade_high": 15,\n  "reasoning": "Senior engineering roles at NASA (GS-13 to 15)"\n}\n\nExample 3:\nQuestion: "What cybersecurity jobs with clearances are available?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "cybersecurity security clearance",\n  "location": null,\n  "organization": null,\n  "pay_grade_low": null,\n  "pay_grade_high": null,\n  "reasoning": "Federal cybersecurity positions requiring clearances"\n}\n\nExample 4:\nQuestion: "What government contracts are available?"\nResponse:\n{\n  "relevant": false,\n  "keywords": "",\n  "location": null,\n  "organization": null,\n  "pay_grade_low": null,\n  "pay_grade_high": null,\n  "reasoning": "Question is about contracts, not jobs"\n}\n', text={'format': {'type': 'json_schema', 'name': 'usajobs_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for job titles and descriptions'}, 'location': {'type': ['string', 'null'], 'description': 'Geographic location or null'}, 'organization': {'type': ['string', 'null'], 'description': 'Federal agency/organization name or null'}, 'pay_grade_low': {'type': ['integer', 'null'], 'description': 'Minimum GS pay grade (1-15) or null'}, 'pay_grade_high': {'type': ['integer', 'null'], 'description': 'Maximum GS pay grade (1-15) or null'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'location', 'organization', 'pay_grade_low', 'pay_grade_high', 'reasoning'], 'additionalProperties': False}, 'strict': True}})[0m
2025-10-20 19:48:41,123 - AIResearchTest - INFO - Research question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc
2025-10-20 19:48:41,123 - LiteLLM - DEBUG - [92mlitellm.responses(model='gpt-5-mini', input='User: You are a search query generator for USAJOBS, the official U.S. federal government job site.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the USAJOBS API:\n- keywords: Search terms for job titles/descriptions (string, keep focused)\n- location: Geographic location if specified (string like "Washington, DC" or "California" or null)\n- organization: Federal agency/organization (string like "Department of Defense", "FBI", or null)\n- pay_grade_low: Minimum GS pay grade if mentioned (integer 1-15, or null)\n- pay_grade_high: Maximum GS pay grade if mentioned (integer 1-15, or null)\n\nGuidelines:\n- keywords: Use job title or skill terms (e.g., "engineer", "analyst", "scientist")\n- location: Format as city-state or just state name, null if not mentioned\n- organization: Use full agency names, null if not specified\n- pay_grade: GS (General Schedule) grades range 1-15, where:\n  * GS-1 to GS-4: Entry-level positions\n  * GS-5 to GS-9: Junior professional positions\n  * GS-10 to GS-12: Mid-level professional positions\n  * GS-13 to GS-15: Senior professional/supervisory positions\n  Only specify if the question explicitly mentions pay grade or seniority level\n\nIf this question is not about federal government jobs or employment, return relevant: false.\n\nReturn JSON with these exact fields. Use null for optional fields.\n\nExample 1:\nQuestion: "What data science jobs are available in the DC area?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "data science",\n  "location": "Washington, DC",\n  "organization": null,\n  "pay_grade_low": null,\n  "pay_grade_high": null,\n  "reasoning": "Federal data science positions in DC area"\n}\n\nExample 2:\nQuestion: "Senior engineer positions at NASA"\nResponse:\n{\n  "relevant": true,\n  "keywords": "engineer",\n  "location": null,\n  "organization": "NASA",\n  "pay_grade_low": 13,\n  "pay_grade_high": 15,\n  "reasoning": "Senior engineering roles at NASA (GS-13 to 15)"\n}\n\nExample 3:\nQuestion: "What cybersecurity jobs with clearances are available?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "cybersecurity security clearance",\n  "location": null,\n  "organization": null,\n  "pay_grade_low": null,\n  "pay_grade_high": null,\n  "reasoning": "Federal cybersecurity positions requiring clearances"\n}\n\nExample 4:\nQuestion: "What government contracts are available?"\nResponse:\n{\n  "relevant": false,\n  "keywords": "",\n  "location": null,\n  "organization": null,\n  "pay_grade_low": null,\n  "pay_grade_high": null,\n  "reasoning": "Question is about contracts, not jobs"\n}\n', text={'format': {'type': 'json_schema', 'name': 'usajobs_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for job titles and descriptions'}, 'location': {'type': ['string', 'null'], 'description': 'Geographic location or null'}, 'organization': {'type': ['string', 'null'], 'description': 'Federal agency/organization name or null'}, 'pay_grade_low': {'type': ['integer', 'null'], 'description': 'Minimum GS pay grade (1-15) or null'}, 'pay_grade_high': {'type': ['integer', 'null'], 'description': 'Maximum GS pay grade (1-15) or null'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'location', 'organization', 'pay_grade_low', 'pay_grade_high', 'reasoning'], 'additionalProperties': False}, 'strict': True}})[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,123 - AIResearchTest - INFO - Integration: ClearanceJobs
2025-10-20 19:48:41,123 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {}
2025-10-20 19:48:41,123 - AIResearchTest - INFO - Generating query parameters...
2025-10-20 19:48:41,124 - LiteLLM - DEBUG - self.optional_params: {}
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,124 - AIResearchTest - INFO - ================================================================================
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-10-20 19:48:41,124 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mRequest to litellm:[0m
2025-10-20 19:48:41,124 - AIResearchTest - INFO - Starting search for source: fbi_vault
2025-10-20 19:48:41,124 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'usajobs_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for job titles and descriptions'}, 'location': {'type': ['string', 'null'], 'description': 'Geographic location or null'}, 'organization': {'type': ['string', 'null'], 'description': 'Federal agency/organization name or null'}, 'pay_grade_low': {'type': ['integer', 'null'], 'description': 'Minimum GS pay grade (1-15) or null'}, 'pay_grade_high': {'type': ['integer', 'null'], 'description': 'Maximum GS pay grade (1-15) or null'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'location', 'organization', 'pay_grade_low', 'pay_grade_high', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}
2025-10-20 19:48:41,125 - LiteLLM - DEBUG - [92mRequest to litellm:[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mlitellm.responses(model='gpt-5-mini', input='User: You are a search query generator for ClearanceJobs.com, a job board for security-cleared positions.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters:\n- keywords: Search terms for job titles/descriptions (string, keep focused - 2-3 words max)\n\nNOTE: The search only supports keyword filtering. Clearance levels and recency are shown in results but cannot be filtered.\n\nIf this question is not about security-cleared jobs or employment, return relevant: false.\n\nReturn JSON with these exact fields.', text={'format': {'type': 'json_schema', 'name': 'clearancejobs_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for job titles and descriptions'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'reasoning'], 'additionalProperties': False}, 'strict': True}})[0m
2025-10-20 19:48:41,125 - AIResearchTest - INFO - Research question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc
2025-10-20 19:48:41,125 - LiteLLM - DEBUG - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'usajobs_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for job titles and descriptions'}, 'location': {'type': ['string', 'null'], 'description': 'Geographic location or null'}, 'organization': {'type': ['string', 'null'], 'description': 'Federal agency/organization name or null'}, 'pay_grade_low': {'type': ['integer', 'null'], 'description': 'Minimum GS pay grade (1-15) or null'}, 'pay_grade_high': {'type': ['integer', 'null'], 'description': 'Maximum GS pay grade (1-15) or null'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'location', 'organization', 'pay_grade_low', 'pay_grade_high', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}
2025-10-20 19:48:41,125 - LiteLLM - DEBUG - [92mlitellm.responses(model='gpt-5-mini', input='User: You are a search query generator for ClearanceJobs.com, a job board for security-cleared positions.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters:\n- keywords: Search terms for job titles/descriptions (string, keep focused - 2-3 words max)\n\nNOTE: The search only supports keyword filtering. Clearance levels and recency are shown in results but cannot be filtered.\n\nIf this question is not about security-cleared jobs or employment, return relevant: false.\n\nReturn JSON with these exact fields.', text={'format': {'type': 'json_schema', 'name': 'clearancejobs_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for job titles and descriptions'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'reasoning'], 'additionalProperties': False}, 'strict': True}})[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,125 - AIResearchTest - INFO - Integration: FBI Vault
2025-10-20 19:48:41,126 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {}
2025-10-20 19:48:41,126 - AIResearchTest - INFO - Generating query parameters...
2025-10-20 19:48:41,126 - LiteLLM - DEBUG - self.optional_params: {}
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,127 - AIResearchTest - INFO - ================================================================================
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-10-20 19:48:41,126 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mRequest to litellm:[0m
2025-10-20 19:48:41,127 - AIResearchTest - INFO - Starting search for source: discord
2025-10-20 19:48:41,127 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'clearancejobs_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for job titles and descriptions'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}
2025-10-20 19:48:41,127 - LiteLLM - DEBUG - [92mRequest to litellm:[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mlitellm.responses(model='gpt-5-mini', input='User: You are a search query generator for FBI Vault, the FBI\'s FOIA document library.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for FBI Vault:\n- query: Search terms for documents (string)\n- reasoning: Brief explanation of the search strategy\n\nGuidelines:\n- Be SPECIFIC with multi-word phrases (e.g., "domestic terrorism threat assessment")\n- Focus on investigation names, document types, or specific topics\n- Use FBI terminology when applicable\n- Keep queries focused on topics likely to have FBI documentation\n\nIf this question is not relevant to FBI investigations or documents, return relevant: false.\n\nReturn JSON with these exact fields.\n\nExample 1:\nQuestion: "What documents exist about domestic terrorism threats?"\nResponse:\n{\n  "relevant": true,\n  "query": "domestic terrorism threat assessment",\n  "reasoning": "Searching for FBI threat assessments on domestic terrorism"\n}\n\nExample 2:\nQuestion: "FBI investigation into January 6"\nResponse:\n{\n  "relevant": true,\n  "query": "January 6 Capitol investigation",\n  "reasoning": "Looking for FBI documents related to January 6th investigation"\n}\n\nExample 3:\nQuestion: "How do I apply for a job?"\nResponse:\n{\n  "relevant": false,\n  "query": "",\n  "reasoning": "Question is about employment, not FBI documents"\n}\n', text={'format': {'type': 'json_schema', 'name': 'fbi_vault_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'query': {'type': 'string', 'description': 'Search query for FBI Vault documents'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'query', 'reasoning'], 'additionalProperties': False}, 'strict': True}})[0m
2025-10-20 19:48:41,127 - AIResearchTest - INFO - Research question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc
2025-10-20 19:48:41,127 - LiteLLM - DEBUG - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'clearancejobs_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for job titles and descriptions'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}
2025-10-20 19:48:41,128 - LiteLLM - DEBUG - [92mlitellm.responses(model='gpt-5-mini', input='User: You are a search query generator for FBI Vault, the FBI\'s FOIA document library.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for FBI Vault:\n- query: Search terms for documents (string)\n- reasoning: Brief explanation of the search strategy\n\nGuidelines:\n- Be SPECIFIC with multi-word phrases (e.g., "domestic terrorism threat assessment")\n- Focus on investigation names, document types, or specific topics\n- Use FBI terminology when applicable\n- Keep queries focused on topics likely to have FBI documentation\n\nIf this question is not relevant to FBI investigations or documents, return relevant: false.\n\nReturn JSON with these exact fields.\n\nExample 1:\nQuestion: "What documents exist about domestic terrorism threats?"\nResponse:\n{\n  "relevant": true,\n  "query": "domestic terrorism threat assessment",\n  "reasoning": "Searching for FBI threat assessments on domestic terrorism"\n}\n\nExample 2:\nQuestion: "FBI investigation into January 6"\nResponse:\n{\n  "relevant": true,\n  "query": "January 6 Capitol investigation",\n  "reasoning": "Looking for FBI documents related to January 6th investigation"\n}\n\nExample 3:\nQuestion: "How do I apply for a job?"\nResponse:\n{\n  "relevant": false,\n  "query": "",\n  "reasoning": "Question is about employment, not FBI documents"\n}\n', text={'format': {'type': 'json_schema', 'name': 'fbi_vault_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'query': {'type': 'string', 'description': 'Search query for FBI Vault documents'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'query', 'reasoning'], 'additionalProperties': False}, 'strict': True}})[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,128 - AIResearchTest - INFO - Integration: Discord
2025-10-20 19:48:41,128 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {}
2025-10-20 19:48:41,128 - AIResearchTest - INFO - Generating query parameters...
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,128 - LiteLLM - DEBUG - self.optional_params: {}
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-10-20 19:48:41,128 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mRequest to litellm:[0m
2025-10-20 19:48:41,129 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'fbi_vault_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'query': {'type': 'string', 'description': 'Search query for FBI Vault documents'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'query', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}
2025-10-20 19:48:41,129 - LiteLLM - DEBUG - [92mRequest to litellm:[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mlitellm.acompletion(model='gpt-4o-mini', messages=[{'role': 'user', 'content': 'Extract 2-5 key search terms or phrases from this research question for searching Discord messages.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGuidelines:\n- Preserve multi-word concepts as single terms (e.g., "domestic terrorism" not ["domestic", "terrorism"])\n- Include acronyms if relevant (e.g., "JTTF")\n- Focus on the most specific, distinctive terms\n- Use quotes around multi-word phrases in the output\n\nExamples:\nQuestion: "JTTF domestic terrorism activity"\nTerms: ["JTTF", "domestic terrorism"]\n\nQuestion: "Joint Terrorism Task Force operations"\nTerms: ["Joint Terrorism Task Force", "JTTF", "operations"]\n\nReturn JSON with a "terms" array.'}], response_format={'type': 'json_schema', 'json_schema': {'strict': True, 'name': 'discord_search_terms', 'schema': {'type': 'object', 'properties': {'terms': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Key search terms or phrases'}}, 'required': ['terms'], 'additionalProperties': False}}})[0m
2025-10-20 19:48:41,129 - LiteLLM - DEBUG - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'fbi_vault_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'query': {'type': 'string', 'description': 'Search query for FBI Vault documents'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'query', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}
2025-10-20 19:48:41,129 - LiteLLM - DEBUG - [92mlitellm.acompletion(model='gpt-4o-mini', messages=[{'role': 'user', 'content': 'Extract 2-5 key search terms or phrases from this research question for searching Discord messages.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGuidelines:\n- Preserve multi-word concepts as single terms (e.g., "domestic terrorism" not ["domestic", "terrorism"])\n- Include acronyms if relevant (e.g., "JTTF")\n- Focus on the most specific, distinctive terms\n- Use quotes around multi-word phrases in the output\n\nExamples:\nQuestion: "JTTF domestic terrorism activity"\nTerms: ["JTTF", "domestic terrorism"]\n\nQuestion: "Joint Terrorism Task Force operations"\nTerms: ["Joint Terrorism Task Force", "JTTF", "operations"]\n\nReturn JSON with a "terms" array.'}], response_format={'type': 'json_schema', 'json_schema': {'strict': True, 'name': 'discord_search_terms', 'schema': {'type': 'object', 'properties': {'terms': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Key search terms or phrases'}}, 'required': ['terms'], 'additionalProperties': False}}})[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,129 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {}
2025-10-20 19:48:41,130 - LiteLLM - DEBUG - self.optional_params: {}
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
2025-10-20 19:48:41,130 - LiteLLM - DEBUG - ASYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache'): None
[92m19:48:41 - LiteLLM:DEBUG[0m: caching_handler.py:213 - CACHE RESULT: None
2025-10-20 19:48:41,130 - LiteLLM - DEBUG - CACHE RESULT: None
[92m19:48:41 - LiteLLM:INFO[0m: utils.py:3260 - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
2025-10-20 19:48:41,134 - AIResearchTest - INFO - ================================================================================
2025-10-20 19:48:41,134 - LiteLLM - INFO - 
LiteLLM completion() model= gpt-4o-mini; provider = openai
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:3263 - 
LiteLLM: Params passed to completion() {'model': 'gpt-4o-mini', 'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': {'type': 'json_schema', 'json_schema': {'strict': True, 'name': 'discord_search_terms', 'schema': {'type': 'object', 'properties': {'terms': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Key search terms or phrases'}}, 'required': ['terms'], 'additionalProperties': False}}}, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Extract 2-5 key search terms or phrases from this research question for searching Discord messages.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGuidelines:\n- Preserve multi-word concepts as single terms (e.g., "domestic terrorism" not ["domestic", "terrorism"])\n- Include acronyms if relevant (e.g., "JTTF")\n- Focus on the most specific, distinctive terms\n- Use quotes around multi-word phrases in the output\n\nExamples:\nQuestion: "JTTF domestic terrorism activity"\nTerms: ["JTTF", "domestic terrorism"]\n\nQuestion: "Joint Terrorism Task Force operations"\nTerms: ["Joint Terrorism Task Force", "JTTF", "operations"]\n\nReturn JSON with a "terms" array.'}], 'thinking': None, 'web_search_options': None}
2025-10-20 19:48:41,134 - AIResearchTest - INFO - Starting search for source: twitter
2025-10-20 19:48:41,134 - AIResearchTest - INFO - Research question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc
2025-10-20 19:48:41,134 - AIResearchTest - INFO - Integration: Twitter
2025-10-20 19:48:41,134 - AIResearchTest - INFO - API key found: 7501a19221...
2025-10-20 19:48:41,134 - AIResearchTest - INFO - Generating query parameters...
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,134 - LiteLLM - DEBUG - 
LiteLLM: Params passed to completion() {'model': 'gpt-4o-mini', 'functions': None, 'function_call': None, 'temperature': None, 'top_p': None, 'n': None, 'stream': None, 'stream_options': None, 'stop': None, 'max_tokens': None, 'max_completion_tokens': None, 'modalities': None, 'prediction': None, 'audio': None, 'presence_penalty': None, 'frequency_penalty': None, 'logit_bias': None, 'user': None, 'custom_llm_provider': 'openai', 'response_format': {'type': 'json_schema', 'json_schema': {'strict': True, 'name': 'discord_search_terms', 'schema': {'type': 'object', 'properties': {'terms': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Key search terms or phrases'}}, 'required': ['terms'], 'additionalProperties': False}}}, 'seed': None, 'tools': None, 'tool_choice': None, 'max_retries': None, 'logprobs': None, 'top_logprobs': None, 'extra_headers': None, 'api_version': None, 'parallel_tool_calls': None, 'drop_params': None, 'allowed_openai_params': None, 'reasoning_effort': None, 'additional_drop_params': None, 'messages': [{'role': 'user', 'content': 'Extract 2-5 key search terms or phrases from this research question for searching Discord messages.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGuidelines:\n- Preserve multi-word concepts as single terms (e.g., "domestic terrorism" not ["domestic", "terrorism"])\n- Include acronyms if relevant (e.g., "JTTF")\n- Focus on the most specific, distinctive terms\n- Use quotes around multi-word phrases in the output\n\nExamples:\nQuestion: "JTTF domestic terrorism activity"\nTerms: ["JTTF", "domestic terrorism"]\n\nQuestion: "Joint Terrorism Task Force operations"\nTerms: ["Joint Terrorism Task Force", "JTTF", "operations"]\n\nReturn JSON with a "terms" array.'}], 'thinking': None, 'web_search_options': None}
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:3266 - 
LiteLLM: Non-Default params passed to completion() {'response_format': {'type': 'json_schema', 'json_schema': {'strict': True, 'name': 'discord_search_terms', 'schema': {'type': 'object', 'properties': {'terms': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Key search terms or phrases'}}, 'required': ['terms'], 'additionalProperties': False}}}}
2025-10-20 19:48:41,134 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mRequest to litellm:[0m
2025-10-20 19:48:41,134 - LiteLLM - DEBUG - 
LiteLLM: Non-Default params passed to completion() {'response_format': {'type': 'json_schema', 'json_schema': {'strict': True, 'name': 'discord_search_terms', 'schema': {'type': 'object', 'properties': {'terms': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Key search terms or phrases'}}, 'required': ['terms'], 'additionalProperties': False}}}}
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'strict': True, 'name': 'discord_search_terms', 'schema': {'type': 'object', 'properties': {'terms': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Key search terms or phrases'}}, 'required': ['terms'], 'additionalProperties': False}}}, 'extra_body': {}}
2025-10-20 19:48:41,135 - LiteLLM - DEBUG - [92mRequest to litellm:[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - [92mlitellm.responses(model='gpt-5-mini', input='User: You are a search query generator for Twitter (via RapidAPI twitter-api45).\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the Twitter API:\n- query: Search keywords (use Twitter Boolean operators: OR, AND, NOT, quotes for exact phrases)\n- search_type: Search filter type (MUST be one of: "Latest", "Top", "Media", "People")\n- max_pages: Number of pages to fetch (integer 1-5, each page ~20 results)\n- reasoning: Brief explanation of query strategy\n\nSearch Type Guidelines:\n- "Latest": Most recent tweets (best for time-sensitive research, breaking news)\n- "Top": Most popular/relevant tweets (best for high-engagement content)\n- "Media": Tweets with images/videos (best for visual content)\n- "People": User profiles (best for finding accounts, NOT for tweets)\n\nQuery Syntax Tips:\n- Use OR for alternatives: "JTTF OR counterterrorism"\n- Use AND to require multiple terms: "cybersecurity AND federal"\n- Use quotes for exact phrases: "\\"joint terrorism task force\\""\n- Use NOT to exclude: "python NOT snake"\n- Keep queries focused (Twitter search has limitations)\n\nGuidelines:\n- query: Use Boolean operators for precision\n- search_type: "Latest" for time-sensitive, "Top" for popularity\n- max_pages: 1-2 for broad queries, 3-5 for focused queries\n- reasoning: Explain why these parameters were chosen\n\nIMPORTANT: search_type MUST be exactly one of: "Latest", "Top", "Media", "People"\n\nIf this question is not about social media or Twitter, return relevant: false.\n\nReturn JSON with these exact fields.\n\nExample 1:\nQuestion: "Recent Twitter discussions about JTTF and counterterrorism operations"\nResponse:\n{\n  "relevant": true,\n  "query": "JTTF OR \\"Joint Terrorism Task Force\\" OR counterterrorism",\n  "search_type": "Latest",\n  "max_pages": 3,\n  "reasoning": "Use Latest for recent discussions, OR operator to catch variations, 3 pages for good coverage"\n}\n\nExample 2:\nQuestion: "What are people saying about FBI hiring?"\nResponse:\n{\n  "relevant": true,\n  "query": "FBI AND (hiring OR jobs OR careers OR recruitment)",\n  "search_type": "Top",\n  "max_pages": 2,\n  "reasoning": "Top tweets for high-engagement discussions, AND/OR for relevant combinations"\n}\n\nExample 3:\nQuestion: "Federal contracting opportunities in Virginia"\nResponse:\n{\n  "relevant": false,\n  "query": "",\n  "search_type": "Latest",\n  "max_pages": 1,\n  "reasoning": "Question is about federal contracts, not social media"\n}\n', text={'format': {'type': 'json_schema', 'name': 'twitter_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'query': {'type': 'string', 'description': 'Twitter search query with Boolean operators'}, 'search_type': {'type': 'string', 'enum': ['Latest', 'Top', 'Media', 'People'], 'description': 'Search filter type'}, 'max_pages': {'type': 'integer', 'description': 'Number of pages to fetch (1-5)', 'minimum': 1, 'maximum': 5}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'query', 'search_type', 'max_pages', 'reasoning'], 'additionalProperties': False}, 'strict': True}})[0m
2025-10-20 19:48:41,135 - LiteLLM - DEBUG - Final returned optional params: {'response_format': {'type': 'json_schema', 'json_schema': {'strict': True, 'name': 'discord_search_terms', 'schema': {'type': 'object', 'properties': {'terms': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Key search terms or phrases'}}, 'required': ['terms'], 'additionalProperties': False}}}, 'extra_body': {}}
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {'response_format': {'type': 'json_schema', 'json_schema': {'strict': True, 'name': 'discord_search_terms', 'schema': {'type': 'object', 'properties': {'terms': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Key search terms or phrases'}}, 'required': ['terms'], 'additionalProperties': False}}}, 'extra_body': {}}
2025-10-20 19:48:41,135 - LiteLLM - DEBUG - [92mlitellm.responses(model='gpt-5-mini', input='User: You are a search query generator for Twitter (via RapidAPI twitter-api45).\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the Twitter API:\n- query: Search keywords (use Twitter Boolean operators: OR, AND, NOT, quotes for exact phrases)\n- search_type: Search filter type (MUST be one of: "Latest", "Top", "Media", "People")\n- max_pages: Number of pages to fetch (integer 1-5, each page ~20 results)\n- reasoning: Brief explanation of query strategy\n\nSearch Type Guidelines:\n- "Latest": Most recent tweets (best for time-sensitive research, breaking news)\n- "Top": Most popular/relevant tweets (best for high-engagement content)\n- "Media": Tweets with images/videos (best for visual content)\n- "People": User profiles (best for finding accounts, NOT for tweets)\n\nQuery Syntax Tips:\n- Use OR for alternatives: "JTTF OR counterterrorism"\n- Use AND to require multiple terms: "cybersecurity AND federal"\n- Use quotes for exact phrases: "\\"joint terrorism task force\\""\n- Use NOT to exclude: "python NOT snake"\n- Keep queries focused (Twitter search has limitations)\n\nGuidelines:\n- query: Use Boolean operators for precision\n- search_type: "Latest" for time-sensitive, "Top" for popularity\n- max_pages: 1-2 for broad queries, 3-5 for focused queries\n- reasoning: Explain why these parameters were chosen\n\nIMPORTANT: search_type MUST be exactly one of: "Latest", "Top", "Media", "People"\n\nIf this question is not about social media or Twitter, return relevant: false.\n\nReturn JSON with these exact fields.\n\nExample 1:\nQuestion: "Recent Twitter discussions about JTTF and counterterrorism operations"\nResponse:\n{\n  "relevant": true,\n  "query": "JTTF OR \\"Joint Terrorism Task Force\\" OR counterterrorism",\n  "search_type": "Latest",\n  "max_pages": 3,\n  "reasoning": "Use Latest for recent discussions, OR operator to catch variations, 3 pages for good coverage"\n}\n\nExample 2:\nQuestion: "What are people saying about FBI hiring?"\nResponse:\n{\n  "relevant": true,\n  "query": "FBI AND (hiring OR jobs OR careers OR recruitment)",\n  "search_type": "Top",\n  "max_pages": 2,\n  "reasoning": "Top tweets for high-engagement discussions, AND/OR for relevant combinations"\n}\n\nExample 3:\nQuestion: "Federal contracting opportunities in Virginia"\nResponse:\n{\n  "relevant": false,\n  "query": "",\n  "search_type": "Latest",\n  "max_pages": 1,\n  "reasoning": "Question is about federal contracts, not social media"\n}\n', text={'format': {'type': 'json_schema', 'name': 'twitter_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'query': {'type': 'string', 'description': 'Twitter search query with Boolean operators'}, 'search_type': {'type': 'string', 'enum': ['Latest', 'Top', 'Media', 'People'], 'description': 'Search filter type'}, 'max_pages': {'type': 'integer', 'description': 'Number of pages to fetch (1-5)', 'minimum': 1, 'maximum': 5}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'query', 'search_type', 'max_pages', 'reasoning'], 'additionalProperties': False}, 'strict': True}})[0m
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - 

2025-10-20 19:48:41,135 - LiteLLM - DEBUG - self.optional_params: {'response_format': {'type': 'json_schema', 'json_schema': {'strict': True, 'name': 'discord_search_terms', 'schema': {'type': 'object', 'properties': {'terms': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Key search terms or phrases'}}, 'required': ['terms'], 'additionalProperties': False}}}, 'extra_body': {}}
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-mini', 'combined_model_name': 'openai/gpt-4o-mini', 'stripped_model_name': 'gpt-4o-mini', 'combined_stripped_model_name': 'openai/gpt-4o-mini', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:41,135 - LiteLLM - DEBUG - 

[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {}
2025-10-20 19:48:41,136 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-mini', 'combined_model_name': 'openai/gpt-4o-mini', 'stripped_model_name': 'gpt-4o-mini', 'combined_stripped_model_name': 'openai/gpt-4o-mini', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:41,136 - LiteLLM - DEBUG - self.optional_params: {}
[92m19:48:41 - LiteLLM:DEBUG[0m: utils.py:349 - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
2025-10-20 19:48:41,136 - LiteLLM - DEBUG - SYNC kwargs[caching]: False; litellm.cache: None; kwargs.get('cache')['no-cache']: False
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:475 - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'twitter_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'query': {'type': 'string', 'description': 'Twitter search query with Boolean operators'}, 'search_type': {'type': 'string', 'enum': ['Latest', 'Top', 'Media', 'People'], 'description': 'Search filter type'}, 'max_pages': {'type': 'integer', 'description': 'Number of pages to fetch (1-5)', 'minimum': 1, 'maximum': 5}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'query', 'search_type', 'max_pages', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}
2025-10-20 19:48:41,137 - LiteLLM - DEBUG - self.optional_params: {'text': {'format': {'type': 'json_schema', 'name': 'twitter_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'query': {'type': 'string', 'description': 'Twitter search query with Boolean operators'}, 'search_type': {'type': 'string', 'enum': ['Latest', 'Top', 'Media', 'People'], 'description': 'Search filter type'}, 'max_pages': {'type': 'integer', 'description': 'Number of pages to fetch (1-5)', 'minimum': 1, 'maximum': 5}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'query', 'search_type', 'max_pages', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:921 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'User: You are a search query generator for SAM.gov, the U.S. federal government contracting opportunities system.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the SAM.gov API:\n- keywords: Search terms for opportunity titles/descriptions (string, keep focused)\n- procurement_types: Types of procurement (array from: "Solicitation", "Presolicitation", "Combined Synopsis/Solicitation", "Sources Sought")\n- set_aside: Small business set-aside type (string from: null, "SBA" (Total Small Business), "8A", "SDVOSBC" (Service-Disabled Veteran), "WOSB" (Women-Owned), "HZC" (HUBZone), or null for none)\n- naics_codes: Industry classification codes if relevant (array of strings like ["541512", "541519"], or empty array)\n- organization: Specific agency/organization if mentioned (string or null)\n- date_range_days: How many days back to search (integer 1-365, default 60)\n\nGuidelines:\n- keywords: Use industry/procurement-specific terms\n- procurement_types: Include all types unless specifically requested (e.g., "RFPs only" → ["Solicitation"])\n- set_aside: Only ONE allowed per query, use null if not specified\n- naics_codes: Common codes:\n  * 541512 - Computer Systems Design Services\n  * 541519 - Other Computer Related Services\n  * 541611 - Administrative Management Consulting\n  * 541990 - All Other Professional Services\n  * 334111 - Electronic Computer Manufacturing\n  * 518210 - Data Processing Services\n- organization: Only specify if question mentions specific agency (e.g., "DoD", "FBI", "VA")\n- date_range_days: Use 30 for "recent", 60 for default, 90 for "past few months"\n\nIMPORTANT: SAM.gov REQUIRES a date range and it cannot exceed 365 days.\n\nIf this question is not about government contracts or procurement, return relevant: false.\n\nReturn JSON with these exact fields. Use empty arrays for optional list fields and null for optional single fields.\n\nExample 1:\nQuestion: "What cybersecurity contracts are available from DoD?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "cybersecurity",\n  "procurement_types": [],\n  "set_aside": null,\n  "naics_codes": ["541512", "541519"],\n  "organization": "Department of Defense",\n  "date_range_days": 60,\n  "reasoning": "DoD cybersecurity contracting opportunities"\n}\n\nExample 2:\nQuestion: "Recent small business IT solicitations"\nResponse:\n{\n  "relevant": true,\n  "keywords": "IT information technology",\n  "procurement_types": ["Solicitation"],\n  "set_aside": "SBA",\n  "naics_codes": ["541512", "541519"],\n  "organization": null,\n  "date_range_days": 30,\n  "reasoning": "Recent IT solicitations for small businesses"\n}\n\nExample 3:\nQuestion: "What military jobs require security clearances?"\nResponse:\n{\n  "relevant": false,\n  "keywords": "",\n  "procurement_types": [],\n  "set_aside": null,\n  "naics_codes": [],\n  "organization": null,\n  "date_range_days": 60,\n  "reasoning": "Question is about jobs, not contracts"\n}\n', 'text': {'format': {'type': 'json_schema', 'name': 'sam_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for opportunity titles and descriptions'}, 'procurement_types': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of procurement types, empty if not specified'}, 'set_aside': {'type': ['string', 'null'], 'description': 'Set-aside type code or null'}, 'naics_codes': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of NAICS codes, empty if not specified'}, 'organization': {'type': ['string', 'null'], 'description': 'Agency/organization name or null'}, 'date_range_days': {'type': 'integer', 'description': 'Days back to search, 1-365', 'minimum': 1, 'maximum': 365}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'procurement_types', 'set_aside', 'naics_codes', 'organization', 'date_range_days', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:41,203 - LiteLLM - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'User: You are a search query generator for SAM.gov, the U.S. federal government contracting opportunities system.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the SAM.gov API:\n- keywords: Search terms for opportunity titles/descriptions (string, keep focused)\n- procurement_types: Types of procurement (array from: "Solicitation", "Presolicitation", "Combined Synopsis/Solicitation", "Sources Sought")\n- set_aside: Small business set-aside type (string from: null, "SBA" (Total Small Business), "8A", "SDVOSBC" (Service-Disabled Veteran), "WOSB" (Women-Owned), "HZC" (HUBZone), or null for none)\n- naics_codes: Industry classification codes if relevant (array of strings like ["541512", "541519"], or empty array)\n- organization: Specific agency/organization if mentioned (string or null)\n- date_range_days: How many days back to search (integer 1-365, default 60)\n\nGuidelines:\n- keywords: Use industry/procurement-specific terms\n- procurement_types: Include all types unless specifically requested (e.g., "RFPs only" → ["Solicitation"])\n- set_aside: Only ONE allowed per query, use null if not specified\n- naics_codes: Common codes:\n  * 541512 - Computer Systems Design Services\n  * 541519 - Other Computer Related Services\n  * 541611 - Administrative Management Consulting\n  * 541990 - All Other Professional Services\n  * 334111 - Electronic Computer Manufacturing\n  * 518210 - Data Processing Services\n- organization: Only specify if question mentions specific agency (e.g., "DoD", "FBI", "VA")\n- date_range_days: Use 30 for "recent", 60 for default, 90 for "past few months"\n\nIMPORTANT: SAM.gov REQUIRES a date range and it cannot exceed 365 days.\n\nIf this question is not about government contracts or procurement, return relevant: false.\n\nReturn JSON with these exact fields. Use empty arrays for optional list fields and null for optional single fields.\n\nExample 1:\nQuestion: "What cybersecurity contracts are available from DoD?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "cybersecurity",\n  "procurement_types": [],\n  "set_aside": null,\n  "naics_codes": ["541512", "541519"],\n  "organization": "Department of Defense",\n  "date_range_days": 60,\n  "reasoning": "DoD cybersecurity contracting opportunities"\n}\n\nExample 2:\nQuestion: "Recent small business IT solicitations"\nResponse:\n{\n  "relevant": true,\n  "keywords": "IT information technology",\n  "procurement_types": ["Solicitation"],\n  "set_aside": "SBA",\n  "naics_codes": ["541512", "541519"],\n  "organization": null,\n  "date_range_days": 30,\n  "reasoning": "Recent IT solicitations for small businesses"\n}\n\nExample 3:\nQuestion: "What military jobs require security clearances?"\nResponse:\n{\n  "relevant": false,\n  "keywords": "",\n  "procurement_types": [],\n  "set_aside": null,\n  "naics_codes": [],\n  "organization": null,\n  "date_range_days": 60,\n  "reasoning": "Question is about jobs, not contracts"\n}\n', 'text': {'format': {'type': 'json_schema', 'name': 'sam_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for opportunity titles and descriptions'}, 'procurement_types': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of procurement types, empty if not specified'}, 'set_aside': {'type': ['string', 'null'], 'description': 'Set-aside type code or null'}, 'naics_codes': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of NAICS codes, empty if not specified'}, 'organization': {'type': ['string', 'null'], 'description': 'Agency/organization name or null'}, 'date_range_days': {'type': 'integer', 'description': 'Days back to search, 1-365', 'minimum': 1, 'maximum': 365}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'procurement_types', 'set_aside', 'naics_codes', 'organization', 'date_range_days', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:41,203 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=6000.0 socket_options=None
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:921 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'User: You are a search query generator for DVIDS, the U.S. military\'s media distribution service.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the DVIDS API:\n- keywords: Search terms for media titles/descriptions (string, keep concise)\n- media_types: Types of media to search (array from: "image", "video", "news")\n- branches: Military branches (array from: "Army", "Navy", "Air Force", "Marines", "Coast Guard", "Joint")\n- country: Country if specified (string, e.g., "United States", "Germany", "Japan")\n- from_date: Start date if recency mentioned (YYYY-MM-DD format, or null)\n- to_date: End date if specified (YYYY-MM-DD format, or null)\n\nGuidelines:\n- keywords: Use military-specific terms, avoid very long queries\n- media_types: Include all types unless specifically requested (e.g., "photos only" → ["image"])\n- branches: Only specify if the question mentions specific branches\n- dates: Only filter by date if recency is mentioned (e.g., "recent", "2024", "last month")\n- country: Only specify if the question mentions a specific country or location\n\nIf this question is not about military media or content, return relevant: false.\n\nReturn JSON with these exact fields. Use empty arrays for optional list fields and null for optional date fields.\n\nExample 1:\nQuestion: "Show me recent F-35 training photos from the Air Force"\nResponse:\n{\n  "relevant": true,\n  "keywords": "F-35 training",\n  "media_types": ["image"],\n  "branches": ["Air Force"],\n  "country": null,\n  "from_date": "2024-10-01",\n  "to_date": null,\n  "reasoning": "Recent Air Force F-35 training imagery"\n}\n\nExample 2:\nQuestion: "What videos are available about humanitarian operations?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "humanitarian operations",\n  "media_types": ["video"],\n  "branches": [],\n  "country": null,\n  "from_date": null,\n  "to_date": null,\n  "reasoning": "Video content about humanitarian missions"\n}\n\nExample 3:\nQuestion: "What government contracts are available?"\nResponse:\n{\n  "relevant": false,\n  "keywords": "",\n  "media_types": [],\n  "branches": [],\n  "country": null,\n  "from_date": null,\n  "to_date": null,\n  "reasoning": "Question is about contracts, not military media"\n}\n', 'text': {'format': {'type': 'json_schema', 'name': 'dvids_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for media titles and descriptions'}, 'media_types': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of media types, empty if not specified'}, 'branches': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of military branches, empty if not specified'}, 'country': {'type': ['string', 'null'], 'description': 'Country name or null'}, 'from_date': {'type': ['string', 'null'], 'description': 'Start date in YYYY-MM-DD format or null'}, 'to_date': {'type': ['string', 'null'], 'description': 'End date in YYYY-MM-DD format or null'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'media_types', 'branches', 'country', 'from_date', 'to_date', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:41,220 - LiteLLM - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'User: You are a search query generator for DVIDS, the U.S. military\'s media distribution service.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the DVIDS API:\n- keywords: Search terms for media titles/descriptions (string, keep concise)\n- media_types: Types of media to search (array from: "image", "video", "news")\n- branches: Military branches (array from: "Army", "Navy", "Air Force", "Marines", "Coast Guard", "Joint")\n- country: Country if specified (string, e.g., "United States", "Germany", "Japan")\n- from_date: Start date if recency mentioned (YYYY-MM-DD format, or null)\n- to_date: End date if specified (YYYY-MM-DD format, or null)\n\nGuidelines:\n- keywords: Use military-specific terms, avoid very long queries\n- media_types: Include all types unless specifically requested (e.g., "photos only" → ["image"])\n- branches: Only specify if the question mentions specific branches\n- dates: Only filter by date if recency is mentioned (e.g., "recent", "2024", "last month")\n- country: Only specify if the question mentions a specific country or location\n\nIf this question is not about military media or content, return relevant: false.\n\nReturn JSON with these exact fields. Use empty arrays for optional list fields and null for optional date fields.\n\nExample 1:\nQuestion: "Show me recent F-35 training photos from the Air Force"\nResponse:\n{\n  "relevant": true,\n  "keywords": "F-35 training",\n  "media_types": ["image"],\n  "branches": ["Air Force"],\n  "country": null,\n  "from_date": "2024-10-01",\n  "to_date": null,\n  "reasoning": "Recent Air Force F-35 training imagery"\n}\n\nExample 2:\nQuestion: "What videos are available about humanitarian operations?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "humanitarian operations",\n  "media_types": ["video"],\n  "branches": [],\n  "country": null,\n  "from_date": null,\n  "to_date": null,\n  "reasoning": "Video content about humanitarian missions"\n}\n\nExample 3:\nQuestion: "What government contracts are available?"\nResponse:\n{\n  "relevant": false,\n  "keywords": "",\n  "media_types": [],\n  "branches": [],\n  "country": null,\n  "from_date": null,\n  "to_date": null,\n  "reasoning": "Question is about contracts, not military media"\n}\n', 'text': {'format': {'type': 'json_schema', 'name': 'dvids_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for media titles and descriptions'}, 'media_types': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of media types, empty if not specified'}, 'branches': {'type': 'array', 'items': {'type': 'string'}, 'description': 'List of military branches, empty if not specified'}, 'country': {'type': ['string', 'null'], 'description': 'Country name or null'}, 'from_date': {'type': ['string', 'null'], 'description': 'Start date in YYYY-MM-DD format or null'}, 'to_date': {'type': ['string', 'null'], 'description': 'End date in YYYY-MM-DD format or null'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'media_types', 'branches', 'country', 'from_date', 'to_date', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:41,220 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=6000.0 socket_options=None
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:921 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'User: You are a search query generator for USAJOBS, the official U.S. federal government job site.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the USAJOBS API:\n- keywords: Search terms for job titles/descriptions (string, keep focused)\n- location: Geographic location if specified (string like "Washington, DC" or "California" or null)\n- organization: Federal agency/organization (string like "Department of Defense", "FBI", or null)\n- pay_grade_low: Minimum GS pay grade if mentioned (integer 1-15, or null)\n- pay_grade_high: Maximum GS pay grade if mentioned (integer 1-15, or null)\n\nGuidelines:\n- keywords: Use job title or skill terms (e.g., "engineer", "analyst", "scientist")\n- location: Format as city-state or just state name, null if not mentioned\n- organization: Use full agency names, null if not specified\n- pay_grade: GS (General Schedule) grades range 1-15, where:\n  * GS-1 to GS-4: Entry-level positions\n  * GS-5 to GS-9: Junior professional positions\n  * GS-10 to GS-12: Mid-level professional positions\n  * GS-13 to GS-15: Senior professional/supervisory positions\n  Only specify if the question explicitly mentions pay grade or seniority level\n\nIf this question is not about federal government jobs or employment, return relevant: false.\n\nReturn JSON with these exact fields. Use null for optional fields.\n\nExample 1:\nQuestion: "What data science jobs are available in the DC area?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "data science",\n  "location": "Washington, DC",\n  "organization": null,\n  "pay_grade_low": null,\n  "pay_grade_high": null,\n  "reasoning": "Federal data science positions in DC area"\n}\n\nExample 2:\nQuestion: "Senior engineer positions at NASA"\nResponse:\n{\n  "relevant": true,\n  "keywords": "engineer",\n  "location": null,\n  "organization": "NASA",\n  "pay_grade_low": 13,\n  "pay_grade_high": 15,\n  "reasoning": "Senior engineering roles at NASA (GS-13 to 15)"\n}\n\nExample 3:\nQuestion: "What cybersecurity jobs with clearances are available?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "cybersecurity security clearance",\n  "location": null,\n  "organization": null,\n  "pay_grade_low": null,\n  "pay_grade_high": null,\n  "reasoning": "Federal cybersecurity positions requiring clearances"\n}\n\nExample 4:\nQuestion: "What government contracts are available?"\nResponse:\n{\n  "relevant": false,\n  "keywords": "",\n  "location": null,\n  "organization": null,\n  "pay_grade_low": null,\n  "pay_grade_high": null,\n  "reasoning": "Question is about contracts, not jobs"\n}\n', 'text': {'format': {'type': 'json_schema', 'name': 'usajobs_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for job titles and descriptions'}, 'location': {'type': ['string', 'null'], 'description': 'Geographic location or null'}, 'organization': {'type': ['string', 'null'], 'description': 'Federal agency/organization name or null'}, 'pay_grade_low': {'type': ['integer', 'null'], 'description': 'Minimum GS pay grade (1-15) or null'}, 'pay_grade_high': {'type': ['integer', 'null'], 'description': 'Maximum GS pay grade (1-15) or null'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'location', 'organization', 'pay_grade_low', 'pay_grade_high', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:41,225 - LiteLLM - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'User: You are a search query generator for USAJOBS, the official U.S. federal government job site.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the USAJOBS API:\n- keywords: Search terms for job titles/descriptions (string, keep focused)\n- location: Geographic location if specified (string like "Washington, DC" or "California" or null)\n- organization: Federal agency/organization (string like "Department of Defense", "FBI", or null)\n- pay_grade_low: Minimum GS pay grade if mentioned (integer 1-15, or null)\n- pay_grade_high: Maximum GS pay grade if mentioned (integer 1-15, or null)\n\nGuidelines:\n- keywords: Use job title or skill terms (e.g., "engineer", "analyst", "scientist")\n- location: Format as city-state or just state name, null if not mentioned\n- organization: Use full agency names, null if not specified\n- pay_grade: GS (General Schedule) grades range 1-15, where:\n  * GS-1 to GS-4: Entry-level positions\n  * GS-5 to GS-9: Junior professional positions\n  * GS-10 to GS-12: Mid-level professional positions\n  * GS-13 to GS-15: Senior professional/supervisory positions\n  Only specify if the question explicitly mentions pay grade or seniority level\n\nIf this question is not about federal government jobs or employment, return relevant: false.\n\nReturn JSON with these exact fields. Use null for optional fields.\n\nExample 1:\nQuestion: "What data science jobs are available in the DC area?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "data science",\n  "location": "Washington, DC",\n  "organization": null,\n  "pay_grade_low": null,\n  "pay_grade_high": null,\n  "reasoning": "Federal data science positions in DC area"\n}\n\nExample 2:\nQuestion: "Senior engineer positions at NASA"\nResponse:\n{\n  "relevant": true,\n  "keywords": "engineer",\n  "location": null,\n  "organization": "NASA",\n  "pay_grade_low": 13,\n  "pay_grade_high": 15,\n  "reasoning": "Senior engineering roles at NASA (GS-13 to 15)"\n}\n\nExample 3:\nQuestion: "What cybersecurity jobs with clearances are available?"\nResponse:\n{\n  "relevant": true,\n  "keywords": "cybersecurity security clearance",\n  "location": null,\n  "organization": null,\n  "pay_grade_low": null,\n  "pay_grade_high": null,\n  "reasoning": "Federal cybersecurity positions requiring clearances"\n}\n\nExample 4:\nQuestion: "What government contracts are available?"\nResponse:\n{\n  "relevant": false,\n  "keywords": "",\n  "location": null,\n  "organization": null,\n  "pay_grade_low": null,\n  "pay_grade_high": null,\n  "reasoning": "Question is about contracts, not jobs"\n}\n', 'text': {'format': {'type': 'json_schema', 'name': 'usajobs_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for job titles and descriptions'}, 'location': {'type': ['string', 'null'], 'description': 'Geographic location or null'}, 'organization': {'type': ['string', 'null'], 'description': 'Federal agency/organization name or null'}, 'pay_grade_low': {'type': ['integer', 'null'], 'description': 'Minimum GS pay grade (1-15) or null'}, 'pay_grade_high': {'type': ['integer', 'null'], 'description': 'Maximum GS pay grade (1-15) or null'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'location', 'organization', 'pay_grade_low', 'pay_grade_high', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:41,225 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=6000.0 socket_options=None
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:921 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'User: You are a search query generator for FBI Vault, the FBI\'s FOIA document library.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for FBI Vault:\n- query: Search terms for documents (string)\n- reasoning: Brief explanation of the search strategy\n\nGuidelines:\n- Be SPECIFIC with multi-word phrases (e.g., "domestic terrorism threat assessment")\n- Focus on investigation names, document types, or specific topics\n- Use FBI terminology when applicable\n- Keep queries focused on topics likely to have FBI documentation\n\nIf this question is not relevant to FBI investigations or documents, return relevant: false.\n\nReturn JSON with these exact fields.\n\nExample 1:\nQuestion: "What documents exist about domestic terrorism threats?"\nResponse:\n{\n  "relevant": true,\n  "query": "domestic terrorism threat assessment",\n  "reasoning": "Searching for FBI threat assessments on domestic terrorism"\n}\n\nExample 2:\nQuestion: "FBI investigation into January 6"\nResponse:\n{\n  "relevant": true,\n  "query": "January 6 Capitol investigation",\n  "reasoning": "Looking for FBI documents related to January 6th investigation"\n}\n\nExample 3:\nQuestion: "How do I apply for a job?"\nResponse:\n{\n  "relevant": false,\n  "query": "",\n  "reasoning": "Question is about employment, not FBI documents"\n}\n', 'text': {'format': {'type': 'json_schema', 'name': 'fbi_vault_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'query': {'type': 'string', 'description': 'Search query for FBI Vault documents'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'query', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:41,230 - LiteLLM - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'User: You are a search query generator for FBI Vault, the FBI\'s FOIA document library.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for FBI Vault:\n- query: Search terms for documents (string)\n- reasoning: Brief explanation of the search strategy\n\nGuidelines:\n- Be SPECIFIC with multi-word phrases (e.g., "domestic terrorism threat assessment")\n- Focus on investigation names, document types, or specific topics\n- Use FBI terminology when applicable\n- Keep queries focused on topics likely to have FBI documentation\n\nIf this question is not relevant to FBI investigations or documents, return relevant: false.\n\nReturn JSON with these exact fields.\n\nExample 1:\nQuestion: "What documents exist about domestic terrorism threats?"\nResponse:\n{\n  "relevant": true,\n  "query": "domestic terrorism threat assessment",\n  "reasoning": "Searching for FBI threat assessments on domestic terrorism"\n}\n\nExample 2:\nQuestion: "FBI investigation into January 6"\nResponse:\n{\n  "relevant": true,\n  "query": "January 6 Capitol investigation",\n  "reasoning": "Looking for FBI documents related to January 6th investigation"\n}\n\nExample 3:\nQuestion: "How do I apply for a job?"\nResponse:\n{\n  "relevant": false,\n  "query": "",\n  "reasoning": "Question is about employment, not FBI documents"\n}\n', 'text': {'format': {'type': 'json_schema', 'name': 'fbi_vault_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'query': {'type': 'string', 'description': 'Search query for FBI Vault documents'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'query', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:41,230 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=6000.0 socket_options=None
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:921 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'User: You are a search query generator for ClearanceJobs.com, a job board for security-cleared positions.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters:\n- keywords: Search terms for job titles/descriptions (string, keep focused - 2-3 words max)\n\nNOTE: The search only supports keyword filtering. Clearance levels and recency are shown in results but cannot be filtered.\n\nIf this question is not about security-cleared jobs or employment, return relevant: false.\n\nReturn JSON with these exact fields.', 'text': {'format': {'type': 'json_schema', 'name': 'clearancejobs_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for job titles and descriptions'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:41,231 - LiteLLM - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'User: You are a search query generator for ClearanceJobs.com, a job board for security-cleared positions.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters:\n- keywords: Search terms for job titles/descriptions (string, keep focused - 2-3 words max)\n\nNOTE: The search only supports keyword filtering. Clearance levels and recency are shown in results but cannot be filtered.\n\nIf this question is not about security-cleared jobs or employment, return relevant: false.\n\nReturn JSON with these exact fields.', 'text': {'format': {'type': 'json_schema', 'name': 'clearancejobs_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'keywords': {'type': 'string', 'description': 'Search keywords for job titles and descriptions'}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'keywords', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:41,231 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=6000.0 socket_options=None
[92m19:48:41 - LiteLLM:DEBUG[0m: http_handler.py:579 - Using AiohttpTransport...
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:921 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'User: You are a search query generator for Twitter (via RapidAPI twitter-api45).\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the Twitter API:\n- query: Search keywords (use Twitter Boolean operators: OR, AND, NOT, quotes for exact phrases)\n- search_type: Search filter type (MUST be one of: "Latest", "Top", "Media", "People")\n- max_pages: Number of pages to fetch (integer 1-5, each page ~20 results)\n- reasoning: Brief explanation of query strategy\n\nSearch Type Guidelines:\n- "Latest": Most recent tweets (best for time-sensitive research, breaking news)\n- "Top": Most popular/relevant tweets (best for high-engagement content)\n- "Media": Tweets with images/videos (best for visual content)\n- "People": User profiles (best for finding accounts, NOT for tweets)\n\nQuery Syntax Tips:\n- Use OR for alternatives: "JTTF OR counterterrorism"\n- Use AND to require multiple terms: "cybersecurity AND federal"\n- Use quotes for exact phrases: "\\"joint terrorism task force\\""\n- Use NOT to exclude: "python NOT snake"\n- Keep queries focused (Twitter search has limitations)\n\nGuidelines:\n- query: Use Boolean operators for precision\n- search_type: "Latest" for time-sensitive, "Top" for popularity\n- max_pages: 1-2 for broad queries, 3-5 for focused queries\n- reasoning: Explain why these parameters were chosen\n\nIMPORTANT: search_type MUST be exactly one of: "Latest", "Top", "Media", "People"\n\nIf this question is not about social media or Twitter, return relevant: false.\n\nReturn JSON with these exact fields.\n\nExample 1:\nQuestion: "Recent Twitter discussions about JTTF and counterterrorism operations"\nResponse:\n{\n  "relevant": true,\n  "query": "JTTF OR \\"Joint Terrorism Task Force\\" OR counterterrorism",\n  "search_type": "Latest",\n  "max_pages": 3,\n  "reasoning": "Use Latest for recent discussions, OR operator to catch variations, 3 pages for good coverage"\n}\n\nExample 2:\nQuestion: "What are people saying about FBI hiring?"\nResponse:\n{\n  "relevant": true,\n  "query": "FBI AND (hiring OR jobs OR careers OR recruitment)",\n  "search_type": "Top",\n  "max_pages": 2,\n  "reasoning": "Top tweets for high-engagement discussions, AND/OR for relevant combinations"\n}\n\nExample 3:\nQuestion: "Federal contracting opportunities in Virginia"\nResponse:\n{\n  "relevant": false,\n  "query": "",\n  "search_type": "Latest",\n  "max_pages": 1,\n  "reasoning": "Question is about federal contracts, not social media"\n}\n', 'text': {'format': {'type': 'json_schema', 'name': 'twitter_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'query': {'type': 'string', 'description': 'Twitter search query with Boolean operators'}, 'search_type': {'type': 'string', 'enum': ['Latest', 'Top', 'Media', 'People'], 'description': 'Search filter type'}, 'max_pages': {'type': 'integer', 'description': 'Number of pages to fetch (1-5)', 'minimum': 1, 'maximum': 5}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'query', 'search_type', 'max_pages', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:41,235 - LiteLLM - DEBUG - Using AiohttpTransport...
[92m19:48:41 - LiteLLM:DEBUG[0m: http_handler.py:636 - Creating AiohttpTransport...
2025-10-20 19:48:41,235 - LiteLLM - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/responses \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-5-mini', 'input': 'User: You are a search query generator for Twitter (via RapidAPI twitter-api45).\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGenerate search parameters for the Twitter API:\n- query: Search keywords (use Twitter Boolean operators: OR, AND, NOT, quotes for exact phrases)\n- search_type: Search filter type (MUST be one of: "Latest", "Top", "Media", "People")\n- max_pages: Number of pages to fetch (integer 1-5, each page ~20 results)\n- reasoning: Brief explanation of query strategy\n\nSearch Type Guidelines:\n- "Latest": Most recent tweets (best for time-sensitive research, breaking news)\n- "Top": Most popular/relevant tweets (best for high-engagement content)\n- "Media": Tweets with images/videos (best for visual content)\n- "People": User profiles (best for finding accounts, NOT for tweets)\n\nQuery Syntax Tips:\n- Use OR for alternatives: "JTTF OR counterterrorism"\n- Use AND to require multiple terms: "cybersecurity AND federal"\n- Use quotes for exact phrases: "\\"joint terrorism task force\\""\n- Use NOT to exclude: "python NOT snake"\n- Keep queries focused (Twitter search has limitations)\n\nGuidelines:\n- query: Use Boolean operators for precision\n- search_type: "Latest" for time-sensitive, "Top" for popularity\n- max_pages: 1-2 for broad queries, 3-5 for focused queries\n- reasoning: Explain why these parameters were chosen\n\nIMPORTANT: search_type MUST be exactly one of: "Latest", "Top", "Media", "People"\n\nIf this question is not about social media or Twitter, return relevant: false.\n\nReturn JSON with these exact fields.\n\nExample 1:\nQuestion: "Recent Twitter discussions about JTTF and counterterrorism operations"\nResponse:\n{\n  "relevant": true,\n  "query": "JTTF OR \\"Joint Terrorism Task Force\\" OR counterterrorism",\n  "search_type": "Latest",\n  "max_pages": 3,\n  "reasoning": "Use Latest for recent discussions, OR operator to catch variations, 3 pages for good coverage"\n}\n\nExample 2:\nQuestion: "What are people saying about FBI hiring?"\nResponse:\n{\n  "relevant": true,\n  "query": "FBI AND (hiring OR jobs OR careers OR recruitment)",\n  "search_type": "Top",\n  "max_pages": 2,\n  "reasoning": "Top tweets for high-engagement discussions, AND/OR for relevant combinations"\n}\n\nExample 3:\nQuestion: "Federal contracting opportunities in Virginia"\nResponse:\n{\n  "relevant": false,\n  "query": "",\n  "search_type": "Latest",\n  "max_pages": 1,\n  "reasoning": "Question is about federal contracts, not social media"\n}\n', 'text': {'format': {'type': 'json_schema', 'name': 'twitter_query', 'schema': {'type': 'object', 'properties': {'relevant': {'type': 'boolean', 'description': 'Whether this database is relevant to the question'}, 'query': {'type': 'string', 'description': 'Twitter search query with Boolean operators'}, 'search_type': {'type': 'string', 'enum': ['Latest', 'Top', 'Media', 'People'], 'description': 'Search filter type'}, 'max_pages': {'type': 'integer', 'description': 'Number of pages to fetch (1-5)', 'minimum': 1, 'maximum': 5}, 'reasoning': {'type': 'string', 'description': 'Brief explanation of the query strategy'}}, 'required': ['relevant', 'query', 'search_type', 'max_pages', 'reasoning'], 'additionalProperties': False}, 'strict': True}}}'
[0m

2025-10-20 19:48:41,236 - LiteLLM - DEBUG - Creating AiohttpTransport...
[92m19:48:41 - LiteLLM:DEBUG[0m: litellm_logging.py:921 - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/ \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-4o-mini', 'messages': [{'role': 'user', 'content': 'Extract 2-5 key search terms or phrases from this research question for searching Discord messages.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGuidelines:\n- Preserve multi-word concepts as single terms (e.g., "domestic terrorism" not ["domestic", "terrorism"])\n- Include acronyms if relevant (e.g., "JTTF")\n- Focus on the most specific, distinctive terms\n- Use quotes around multi-word phrases in the output\n\nExamples:\nQuestion: "JTTF domestic terrorism activity"\nTerms: ["JTTF", "domestic terrorism"]\n\nQuestion: "Joint Terrorism Task Force operations"\nTerms: ["Joint Terrorism Task Force", "JTTF", "operations"]\n\nReturn JSON with a "terms" array.'}], 'response_format': {'type': 'json_schema', 'json_schema': {'strict': True, 'name': 'discord_search_terms', 'schema': {'type': 'object', 'properties': {'terms': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Key search terms or phrases'}}, 'required': ['terms'], 'additionalProperties': False}}}, 'extra_body': {}}'
[0m

2025-10-20 19:48:41,236 - httpcore.connection - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=6000.0 socket_options=None
2025-10-20 19:48:41,236 - LiteLLM - DEBUG - [92m

POST Request Sent from LiteLLM:
curl -X POST \
https://api.openai.com/v1/ \
-H 'Authorization: Be****QA' \
-d '{'model': 'gpt-4o-mini', 'messages': [{'role': 'user', 'content': 'Extract 2-5 key search terms or phrases from this research question for searching Discord messages.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGuidelines:\n- Preserve multi-word concepts as single terms (e.g., "domestic terrorism" not ["domestic", "terrorism"])\n- Include acronyms if relevant (e.g., "JTTF")\n- Focus on the most specific, distinctive terms\n- Use quotes around multi-word phrases in the output\n\nExamples:\nQuestion: "JTTF domestic terrorism activity"\nTerms: ["JTTF", "domestic terrorism"]\n\nQuestion: "Joint Terrorism Task Force operations"\nTerms: ["Joint Terrorism Task Force", "JTTF", "operations"]\n\nReturn JSON with a "terms" array.'}], 'response_format': {'type': 'json_schema', 'json_schema': {'strict': True, 'name': 'discord_search_terms', 'schema': {'type': 'object', 'properties': {'terms': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Key search terms or phrases'}}, 'required': ['terms'], 'additionalProperties': False}}}, 'extra_body': {}}'
[0m

2025-10-20 19:48:41,379 - openai._base_client - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'timeout': 600.0, 'files': None, 'idempotency_key': 'stainless-python-retry-fb973bbf-0523-4836-af7d-5e6d7ecbe10e', 'json_data': {'messages': [{'role': 'user', 'content': 'Extract 2-5 key search terms or phrases from this research question for searching Discord messages.\n\nResearch Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc\n\nGuidelines:\n- Preserve multi-word concepts as single terms (e.g., "domestic terrorism" not ["domestic", "terrorism"])\n- Include acronyms if relevant (e.g., "JTTF")\n- Focus on the most specific, distinctive terms\n- Use quotes around multi-word phrases in the output\n\nExamples:\nQuestion: "JTTF domestic terrorism activity"\nTerms: ["JTTF", "domestic terrorism"]\n\nQuestion: "Joint Terrorism Task Force operations"\nTerms: ["Joint Terrorism Task Force", "JTTF", "operations"]\n\nReturn JSON with a "terms" array.'}], 'model': 'gpt-4o-mini', 'response_format': {'type': 'json_schema', 'json_schema': {'strict': True, 'name': 'discord_search_terms', 'schema': {'type': 'object', 'properties': {'terms': {'type': 'array', 'items': {'type': 'string'}, 'description': 'Key search terms or phrases'}}, 'required': ['terms'], 'additionalProperties': False}}}}, 'extra_json': {}}
2025-10-20 19:48:41,379 - openai._base_client - DEBUG - Sending HTTP Request: POST https://api.openai.com/v1/chat/completions
2025-10-20 19:48:46,331 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b130a5a90>
2025-10-20 19:48:46,331 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x735b1307ecd0> server_hostname='api.openai.com' timeout=6000.0
2025-10-20 19:48:46,362 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b130a7230>
2025-10-20 19:48:46,362 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b130c57f0>
2025-10-20 19:48:46,362 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b130a6690>
2025-10-20 19:48:46,362 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x735b130948d0> server_hostname='api.openai.com' timeout=6000.0
2025-10-20 19:48:46,362 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x735b130b5cd0> server_hostname='api.openai.com' timeout=6000.0
2025-10-20 19:48:46,362 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x735b1307fbd0> server_hostname='api.openai.com' timeout=6000.0
2025-10-20 19:48:46,368 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b130c4b00>
2025-10-20 19:48:46,368 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x735b13095550> server_hostname='api.openai.com' timeout=6000.0
2025-10-20 19:48:46,369 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b130c4b30>
2025-10-20 19:48:46,370 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-10-20 19:48:46,370 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-10-20 19:48:46,370 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-10-20 19:48:46,370 - httpcore.http11 - DEBUG - send_request_body.complete
2025-10-20 19:48:46,370 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-10-20 19:48:46,376 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b130a7e60>
2025-10-20 19:48:46,377 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x735b130961d0> server_hostname='api.openai.com' timeout=6000.0
2025-10-20 19:48:46,391 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b130c57c0>
2025-10-20 19:48:46,392 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-10-20 19:48:46,392 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-10-20 19:48:46,392 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-10-20 19:48:46,392 - httpcore.http11 - DEBUG - send_request_body.complete
2025-10-20 19:48:46,392 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-10-20 19:48:46,424 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b130a7d70>
2025-10-20 19:48:46,424 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-10-20 19:48:46,425 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-10-20 19:48:46,425 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-10-20 19:48:46,425 - httpcore.http11 - DEBUG - send_request_body.complete
2025-10-20 19:48:46,425 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-10-20 19:48:46,452 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b130c5700>
2025-10-20 19:48:46,453 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-10-20 19:48:46,453 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-10-20 19:48:46,453 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-10-20 19:48:46,453 - httpcore.http11 - DEBUG - send_request_body.complete
2025-10-20 19:48:46,453 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-10-20 19:48:46,695 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b130a7140>
2025-10-20 19:48:46,695 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-10-20 19:48:46,695 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-10-20 19:48:46,695 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-10-20 19:48:46,695 - httpcore.http11 - DEBUG - send_request_body.complete
2025-10-20 19:48:46,695 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-10-20 19:48:46,729 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x735b130c4a10>
2025-10-20 19:48:46,729 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-10-20 19:48:46,729 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-10-20 19:48:46,729 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-10-20 19:48:46,729 - httpcore.http11 - DEBUG - send_request_body.complete
2025-10-20 19:48:46,729 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-10-20 19:48:47,510 - openai._base_client - DEBUG - HTTP Response: POST https://api.openai.com/v1/chat/completions "200 OK" Headers([('date', 'Tue, 21 Oct 2025 02:48:49 GMT'), ('content-type', 'application/json'), ('transfer-encoding', 'chunked'), ('connection', 'keep-alive'), ('access-control-expose-headers', 'X-Request-ID'), ('openai-organization', 'quickgpts'), ('openai-processing-ms', '596'), ('openai-project', 'proj_tta1tTpO1Yd49KEelsEZTSjW'), ('openai-version', '2020-10-01'), ('x-envoy-upstream-service-time', '644'), ('x-ratelimit-limit-requests', '10000'), ('x-ratelimit-limit-tokens', '10000000'), ('x-ratelimit-remaining-requests', '9999'), ('x-ratelimit-remaining-tokens', '9999815'), ('x-ratelimit-reset-requests', '6ms'), ('x-ratelimit-reset-tokens', '1ms'), ('x-request-id', 'req_3635dfce534546cb8d2d1097c6e90bfc'), ('x-openai-proxy-wasm', 'v0.1'), ('cf-cache-status', 'DYNAMIC'), ('set-cookie', '__cf_bm=buosILa1iWlJiZRs9F2FQCIM6LYZ98NG44Uh9anGKwU-1761014929-1.0.1.1-VSeeQESjbHYZzaJSTw9O9jCjvBW2UvEIfiSkcAKyuEh2mK19noNCRP3dzheDIEChFQuwSYvv6Os_pMSLzOdPoNjVyk_VKMqdaVIaQzIDOpQ; path=/; expires=Tue, 21-Oct-25 03:18:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('strict-transport-security', 'max-age=31536000; includeSubDomains; preload'), ('x-content-type-options', 'nosniff'), ('set-cookie', '_cfuvid=80Aa4UNAW6YEy6L63hYBCwZsXFkKNvAk0bEMrcHVQIA-1761014929625-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), ('server', 'cloudflare'), ('cf-ray', '991d7029ebb1c962-MIA'), ('content-encoding', 'gzip'), ('alt-svc', 'h3=":443"; ma=86400')])
2025-10-20 19:48:47,510 - openai._base_client - DEBUG - request_id: req_3635dfce534546cb8d2d1097c6e90bfc
[92m19:48:47 - LiteLLM:DEBUG[0m: utils.py:349 - RAW RESPONSE:
{"id": "chatcmpl-CSwiXnEBx5jdDSFOmJRRuZPsREyEX", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "{\"terms\":[\"domestic counterterrorism\",\"JTTF\",\"recent activity\",\"conversation\",\"domestic terrorism\"]}", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}}], "created": 1761014929, "model": "gpt-4o-mini-2024-07-18", "object": "chat.completion", "service_tier": "default", "system_fingerprint": "fp_560af6e559", "usage": {"completion_tokens": 23, "prompt_tokens": 222, "total_tokens": 245, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}}


2025-10-20 19:48:47,515 - LiteLLM - DEBUG - RAW RESPONSE:
{"id": "chatcmpl-CSwiXnEBx5jdDSFOmJRRuZPsREyEX", "choices": [{"finish_reason": "stop", "index": 0, "logprobs": null, "message": {"content": "{\"terms\":[\"domestic counterterrorism\",\"JTTF\",\"recent activity\",\"conversation\",\"domestic terrorism\"]}", "refusal": null, "role": "assistant", "annotations": [], "audio": null, "function_call": null, "tool_calls": null}}], "created": 1761014929, "model": "gpt-4o-mini-2024-07-18", "object": "chat.completion", "service_tier": "default", "system_fingerprint": "fp_560af6e559", "usage": {"completion_tokens": 23, "prompt_tokens": 222, "total_tokens": 245, "completion_tokens_details": {"accepted_prediction_tokens": 0, "audio_tokens": 0, "reasoning_tokens": 0, "rejected_prediction_tokens": 0}, "prompt_tokens_details": {"audio_tokens": 0, "cached_tokens": 0}}}


[92m19:48:47 - LiteLLM:DEBUG[0m: litellm_logging.py:2824 - Filtered callbacks: []
2025-10-20 19:48:47,516 - LiteLLM - DEBUG - Filtered callbacks: []
[92m19:48:47 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18
2025-10-20 19:48:47,516 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-4o-mini-2024-07-18
[92m19:48:47 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-mini-2024-07-18', 'combined_model_name': 'openai/gpt-4o-mini-2024-07-18', 'stripped_model_name': 'gpt-4o-mini-2024-07-18', 'combined_stripped_model_name': 'openai/gpt-4o-mini-2024-07-18', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:47,517 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-mini-2024-07-18', 'combined_model_name': 'openai/gpt-4o-mini-2024-07-18', 'stripped_model_name': 'gpt-4o-mini-2024-07-18', 'combined_stripped_model_name': 'openai/gpt-4o-mini-2024-07-18', 'custom_llm_provider': 'openai'}
[92m19:48:47 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-4o-mini-2024-07-18', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 7.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 7.5e-08, 'output_cost_per_token_batches': 3e-07, 'output_cost_per_token': 6e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': {'search_context_size_high': 0.03, 'search_context_size_low': 0.025, 'search_context_size_medium': 0.0275}, 'tpm': None, 'rpm': None}
2025-10-20 19:48:47,517 - LiteLLM - DEBUG - model_info: {'key': 'gpt-4o-mini-2024-07-18', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 7.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 7.5e-08, 'output_cost_per_token_batches': 3e-07, 'output_cost_per_token': 6e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': {'search_context_size_high': 0.03, 'search_context_size_low': 0.025, 'search_context_size_medium': 0.0275}, 'tpm': None, 'rpm': None}
[92m19:48:47 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 4.709999999999999e-05
2025-10-20 19:48:47,517 - LiteLLM - DEBUG - response_cost: 4.709999999999999e-05
[92m19:48:47 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: gpt-4o-mini-2024-07-18
2025-10-20 19:48:47,517 - LiteLLM - DEBUG - selected model name for cost calculation: gpt-4o-mini-2024-07-18
[92m19:48:47 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-mini-2024-07-18', 'combined_model_name': 'openai/gpt-4o-mini-2024-07-18', 'stripped_model_name': 'gpt-4o-mini-2024-07-18', 'combined_stripped_model_name': 'openai/gpt-4o-mini-2024-07-18', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:47,517 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-mini-2024-07-18', 'combined_model_name': 'openai/gpt-4o-mini-2024-07-18', 'stripped_model_name': 'gpt-4o-mini-2024-07-18', 'combined_stripped_model_name': 'openai/gpt-4o-mini-2024-07-18', 'custom_llm_provider': 'openai'}
[92m19:48:47 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-4o-mini-2024-07-18', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 7.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 7.5e-08, 'output_cost_per_token_batches': 3e-07, 'output_cost_per_token': 6e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': {'search_context_size_high': 0.03, 'search_context_size_low': 0.025, 'search_context_size_medium': 0.0275}, 'tpm': None, 'rpm': None}
2025-10-20 19:48:47,517 - LiteLLM - DEBUG - model_info: {'key': 'gpt-4o-mini-2024-07-18', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 7.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 7.5e-08, 'output_cost_per_token_batches': 3e-07, 'output_cost_per_token': 6e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': {'search_context_size_high': 0.03, 'search_context_size_low': 0.025, 'search_context_size_medium': 0.0275}, 'tpm': None, 'rpm': None}
2025-10-20 19:48:47,518 - AIResearchTest - INFO - Generated query parameters:
2025-10-20 19:48:47,518 - AIResearchTest - INFO - {
  "keywords": [
    "domestic counterterrorism",
    "jttf",
    "recent activity",
    "conversation",
    "domestic terrorism"
  ],
  "servers": null,
  "date_range": null
}
2025-10-20 19:48:47,518 - AIResearchTest - INFO - Executing search...
2025-10-20 19:48:50,662 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 21 Oct 2025 02:48:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9998962'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'quickgpts'), (b'openai-project', b'proj_tta1tTpO1Yd49KEelsEZTSjW'), (b'x-request-id', b'req_09b3bbc6872d4c89bc3737647e40b84e'), (b'openai-processing-ms', b'4215'), (b'x-envoy-upstream-service-time', b'4220'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=QqCEcanWadmfDVARJe9Pr9gwHcj2AVMchIt8GCeLF5w-1761014933-1.0.1.1-nUpSdahIH4Ap9xQkB7.yo4EfgCsMdvcJltKjnPJBYGc9o7cHjup.DjDZh9xVS7GRI1JKMfgpZcuVBstOj04fO6iq60MUYBWxDGPDcq0m9Gc; path=/; expires=Tue, 21-Oct-25 03:18:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=PvYKNukcupdrUX.ZzKHAqBo5xkt.cZy5CkK9BdIFY2s-1761014933068-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'991d7028eec46dda-MIA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-20 19:48:50,662 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-10-20 19:48:50,662 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-10-20 19:48:50,662 - httpcore.http11 - DEBUG - response_closed.started
2025-10-20 19:48:50,662 - httpcore.http11 - DEBUG - response_closed.complete
2025-10-20 19:48:50,664 - httpcore.connection - DEBUG - close.started
2025-10-20 19:48:50,664 - httpcore.connection - DEBUG - close.complete
[92m19:48:50 - LiteLLM:INFO[0m: utils.py:1262 - Wrapper: Completed Call, calling success_handler
2025-10-20 19:48:50,664 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
[92m19:48:50 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:48:50 - LiteLLM:DEBUG[0m: litellm_logging.py:1594 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-10-20 19:48:50,664 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:48:50 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:50,664 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
[92m19:48:50 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
2025-10-20 19:48:50,665 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:48:50 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:50,665 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:48:50 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:50,665 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:48:50 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.00074525
2025-10-20 19:48:50,666 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:48:50 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:50,666 - LiteLLM - DEBUG - response_cost: 0.00074525
2025-10-20 19:48:50,666 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:48:50 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.00074525
2025-10-20 19:48:50,666 - LiteLLM - DEBUG - response_cost: 0.00074525
[92m19:48:50 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:50,666 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:48:50 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:50,667 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:53,025 - AIResearchTest - INFO - Search completed:
2025-10-20 19:48:53,025 - AIResearchTest - INFO -   Success: True
2025-10-20 19:48:53,025 - AIResearchTest - INFO -   Total: 0
2025-10-20 19:48:53,025 - AIResearchTest - INFO -   Returned: 0
2025-10-20 19:48:53,025 - AIResearchTest - INFO -   Time: 11898ms
[92m19:48:53 - LiteLLM:DEBUG[0m: utils.py:349 - Async Wrapper: Completed Call, calling async_success_handler: <bound method Logging.async_success_handler of <litellm.litellm_core_utils.litellm_logging.Logging object at 0x735b1329faa0>>
2025-10-20 19:48:53,025 - LiteLLM - DEBUG - Async Wrapper: Completed Call, calling async_success_handler: <bound method Logging.async_success_handler of <litellm.litellm_core_utils.litellm_logging.Logging object at 0x735b1329faa0>>
[92m19:48:53 - LiteLLM:DEBUG[0m: litellm_logging.py:2824 - Filtered callbacks: []
2025-10-20 19:48:53,025 - LiteLLM - DEBUG - Filtered callbacks: []
[92m19:48:53 - LiteLLM:DEBUG[0m: utils.py:349 - Logging Details LiteLLM-Async Success Call, cache_hit=None
2025-10-20 19:48:53,025 - LiteLLM - DEBUG - Logging Details LiteLLM-Async Success Call, cache_hit=None
[92m19:48:53 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-mini-2024-07-18', 'combined_model_name': 'openai/gpt-4o-mini-2024-07-18', 'stripped_model_name': 'gpt-4o-mini-2024-07-18', 'combined_stripped_model_name': 'openai/gpt-4o-mini-2024-07-18', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:53,026 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-mini-2024-07-18', 'combined_model_name': 'openai/gpt-4o-mini-2024-07-18', 'stripped_model_name': 'gpt-4o-mini-2024-07-18', 'combined_stripped_model_name': 'openai/gpt-4o-mini-2024-07-18', 'custom_llm_provider': 'openai'}
[92m19:48:53 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-4o-mini-2024-07-18', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 7.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 7.5e-08, 'output_cost_per_token_batches': 3e-07, 'output_cost_per_token': 6e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': {'search_context_size_high': 0.03, 'search_context_size_low': 0.025, 'search_context_size_medium': 0.0275}, 'tpm': None, 'rpm': None}
2025-10-20 19:48:53,026 - LiteLLM - DEBUG - model_info: {'key': 'gpt-4o-mini-2024-07-18', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 7.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 7.5e-08, 'output_cost_per_token_batches': 3e-07, 'output_cost_per_token': 6e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': {'search_context_size_high': 0.03, 'search_context_size_low': 0.025, 'search_context_size_medium': 0.0275}, 'tpm': None, 'rpm': None}
[92m19:48:53 - LiteLLM:DEBUG[0m: utils.py:349 - Async success callbacks: Got a complete streaming response
2025-10-20 19:48:53,026 - LiteLLM - DEBUG - Async success callbacks: Got a complete streaming response
[92m19:48:53 - LiteLLM:DEBUG[0m: litellm_logging.py:2163 - Model=gpt-4o-mini; cost=4.709999999999999e-05
2025-10-20 19:48:53,026 - LiteLLM - DEBUG - Model=gpt-4o-mini; cost=4.709999999999999e-05
[92m19:48:53 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-mini-2024-07-18', 'combined_model_name': 'openai/gpt-4o-mini-2024-07-18', 'stripped_model_name': 'gpt-4o-mini-2024-07-18', 'combined_stripped_model_name': 'openai/gpt-4o-mini-2024-07-18', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:53,027 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-4o-mini-2024-07-18', 'combined_model_name': 'openai/gpt-4o-mini-2024-07-18', 'stripped_model_name': 'gpt-4o-mini-2024-07-18', 'combined_stripped_model_name': 'openai/gpt-4o-mini-2024-07-18', 'custom_llm_provider': 'openai'}
[92m19:48:53 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-4o-mini-2024-07-18', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 7.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 7.5e-08, 'output_cost_per_token_batches': 3e-07, 'output_cost_per_token': 6e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': {'search_context_size_high': 0.03, 'search_context_size_low': 0.025, 'search_context_size_medium': 0.0275}, 'tpm': None, 'rpm': None}
2025-10-20 19:48:53,027 - LiteLLM - DEBUG - model_info: {'key': 'gpt-4o-mini-2024-07-18', 'max_tokens': 16384, 'max_input_tokens': 128000, 'max_output_tokens': 16384, 'input_cost_per_token': 1.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 7.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': 7.5e-08, 'output_cost_per_token_batches': 3e-07, 'output_cost_per_token': 6e-07, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': None, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': None, 'supports_computer_use': None, 'search_context_cost_per_query': {'search_context_size_high': 0.03, 'search_context_size_low': 0.025, 'search_context_size_medium': 0.0275}, 'tpm': None, 'rpm': None}
[92m19:48:53 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: None
2025-10-20 19:48:53,027 - LiteLLM - DEBUG - selected model name for cost calculation: None
[92m19:48:53 - LiteLLM:DEBUG[0m: cost_calculator.py:960 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=None - Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b1061f980>, model=None
2025-10-20 19:48:53,027 - LiteLLM - DEBUG - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=None - Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b1061f980>, model=None
2025-10-20 19:48:53,027 - root - DEBUG - Cost tracking failed: Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b1061f980>, model=None
2025-10-20 19:48:53,027 - AIResearchTest - WARNING - Query generation returned None (source deemed not relevant)
2025-10-20 19:48:59,153 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 21 Oct 2025 02:48:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999059'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'quickgpts'), (b'openai-project', b'proj_tta1tTpO1Yd49KEelsEZTSjW'), (b'x-request-id', b'req_71a5a8a334594c5fa3d404122dca15fc'), (b'openai-processing-ms', b'10678'), (b'x-envoy-upstream-service-time', b'10683'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=CgsPQ.eY.7blSlLRQI8Zjbi8fnomzqCFOvfl53X_8.w-1761014939-1.0.1.1-KyKrEIU6iMvea.A5ssao7IAwDWSV3vFzsBhf52bsgCLswDdSZupltu0vY7OlhsWHxHOx1YPTWdR5dyPjgVzPUIFGlwqZhhJj1O7.NnOR1r4; path=/; expires=Tue, 21-Oct-25 03:18:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=YQ9ST2InW0pVp1OFCzIiJRidgYLCbhsdva6YSrCB9iA-1761014939293-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'991d70274d37d965-MIA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-20 19:48:59,153 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-10-20 19:48:59,157 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-10-20 19:48:59,157 - httpcore.http11 - DEBUG - response_closed.started
2025-10-20 19:48:59,158 - httpcore.http11 - DEBUG - response_closed.complete
[92m19:48:59 - LiteLLM:INFO[0m: utils.py:1262 - Wrapper: Completed Call, calling success_handler
2025-10-20 19:48:59,158 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
[92m19:48:59 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:48:59 - LiteLLM:DEBUG[0m: litellm_logging.py:1594 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-10-20 19:48:59,158 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:48:59 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:59,158 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
[92m19:48:59 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
2025-10-20 19:48:59,159 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:48:59 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:59,159 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:48:59 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:59,159 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:48:59 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.0013889999999999998
2025-10-20 19:48:59,160 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:48:59 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:59,160 - LiteLLM - DEBUG - response_cost: 0.0013889999999999998
2025-10-20 19:48:59,160 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:48:59 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: None
[92m19:48:59 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.0013889999999999998
2025-10-20 19:48:59,160 - LiteLLM - DEBUG - selected model name for cost calculation: None
[92m19:48:59 - LiteLLM:DEBUG[0m: cost_calculator.py:960 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=None - Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b104ae0f0>, model=None
2025-10-20 19:48:59,160 - LiteLLM - DEBUG - response_cost: 0.0013889999999999998
[92m19:48:59 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:59,161 - LiteLLM - DEBUG - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=None - Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b104ae0f0>, model=None
2025-10-20 19:48:59,161 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:48:59 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:59,161 - root - DEBUG - Cost tracking failed: Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b104ae0f0>, model=None
2025-10-20 19:48:59,161 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:59,162 - AIResearchTest - INFO - Generated query parameters:
2025-10-20 19:48:59,162 - AIResearchTest - INFO - {
  "query": "JTTF OR \"Joint Terrorism Task Force\" OR counterterrorism OR \"domestic terrorism\" OR \"domestic counterterrorism\" OR \"terrorism task force\" OR \"fusion center\" OR FBI OR DHS OR \"law enforcement\" OR #JTTF OR #Counterterrorism",
  "search_type": "Latest",
  "max_pages": 4,
  "reasoning": "Use Latest for time-sensitive monitoring of recent conversations. The query uses OR to capture acronyms, full phrase variants, agency names, related programs (fusion centers) and common hashtags to maximize recall. Four pages provide broad recent coverage while remaining focused."
}
2025-10-20 19:48:59,162 - AIResearchTest - INFO - Executing search...
2025-10-20 19:48:59,163 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): twitter-api45.p.rapidapi.com:443
2025-10-20 19:48:59,622 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 21 Oct 2025 02:48:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999024'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'quickgpts'), (b'openai-project', b'proj_tta1tTpO1Yd49KEelsEZTSjW'), (b'x-request-id', b'req_994211fdd5f645d08d85ad322c8aae02'), (b'openai-processing-ms', b'11228'), (b'x-envoy-upstream-service-time', b'11233'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=aiO8qUdgSEhXUmil4lXWm9gko3E1pBMDhSpqXI9BTJk-1761014939-1.0.1.1-.WwjZvFWsDXIFFHWQ61AmHFgRDwjjJDD318OZy2vZ0_Fq0ZT0kDNMMF3TuiiWR4CVxR3oFJ5az4ftDhhsAgZ.lTtR1b5qMcWNBkMtoGIREQ; path=/; expires=Tue, 21-Oct-25 03:18:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=Woxk42miAgI.qeamR1Ja5Q7Xo79Z7rEdd59hYSK01.k-1761014939794-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'991d7026e9750870-MIA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-20 19:48:59,622 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-10-20 19:48:59,623 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-10-20 19:48:59,623 - httpcore.http11 - DEBUG - response_closed.started
2025-10-20 19:48:59,623 - httpcore.http11 - DEBUG - response_closed.complete
2025-10-20 19:48:59,623 - httpcore.connection - DEBUG - close.started
2025-10-20 19:48:59,623 - httpcore.connection - DEBUG - close.complete
[92m19:48:59 - LiteLLM:INFO[0m: utils.py:1262 - Wrapper: Completed Call, calling success_handler
2025-10-20 19:48:59,623 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
[92m19:48:59 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:48:59 - LiteLLM:DEBUG[0m: litellm_logging.py:1594 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-10-20 19:48:59,624 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:48:59 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:59,624 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
[92m19:48:59 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
2025-10-20 19:48:59,624 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:48:59 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:59,624 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:48:59 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:59,624 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:48:59 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.00171175
2025-10-20 19:48:59,625 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:48:59 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:59,625 - LiteLLM - DEBUG - response_cost: 0.00171175
2025-10-20 19:48:59,625 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:48:59 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: None
[92m19:48:59 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.00171175
2025-10-20 19:48:59,625 - LiteLLM - DEBUG - selected model name for cost calculation: None
[92m19:48:59 - LiteLLM:DEBUG[0m: cost_calculator.py:960 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=None - Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b136caff0>, model=None
2025-10-20 19:48:59,625 - LiteLLM - DEBUG - response_cost: 0.00171175
[92m19:48:59 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:48:59,626 - LiteLLM - DEBUG - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=None - Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b136caff0>, model=None
2025-10-20 19:48:59,626 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:48:59 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:59,626 - root - DEBUG - Cost tracking failed: Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b136caff0>, model=None
2025-10-20 19:48:59,626 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:48:59,626 - AIResearchTest - INFO - Generated query parameters:
2025-10-20 19:48:59,627 - AIResearchTest - INFO - {
  "keywords": "domestic counterterrorism JTTF",
  "media_types": [
    "image",
    "video",
    "news"
  ],
  "branches": [],
  "country": "United States",
  "from_date": "2024-10-01",
  "to_date": null
}
2025-10-20 19:48:59,627 - AIResearchTest - INFO - Executing search...
2025-10-20 19:48:59,627 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.dvidshub.net:443
2025-10-20 19:49:00,387 - urllib3.connectionpool - DEBUG - https://api.dvidshub.net:443 "GET /search?api_key=key-68f319e8dc377&page=1&max_results=10&q=domestic+counterterrorism+JTTF&type%5B%5D=image&type%5B%5D=video&type%5B%5D=news&country=United+States&from_publishdate=2024-10-01T00%3A00%3A00Z HTTP/1.1" 200 68
2025-10-20 19:49:00,389 - AIResearchTest - INFO - Search completed:
2025-10-20 19:49:00,389 - AIResearchTest - INFO -   Success: True
2025-10-20 19:49:00,389 - AIResearchTest - INFO -   Total: 0
2025-10-20 19:49:00,389 - AIResearchTest - INFO -   Returned: 0
2025-10-20 19:49:00,389 - AIResearchTest - INFO -   Time: 19271ms
2025-10-20 19:49:00,912 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 21 Oct 2025 02:49:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999587'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'2ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'quickgpts'), (b'openai-project', b'proj_tta1tTpO1Yd49KEelsEZTSjW'), (b'x-request-id', b'req_dd002699cc5b4c6387fb9a9ae1d38903'), (b'openai-processing-ms', b'12318'), (b'x-envoy-upstream-service-time', b'12320'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=G8YUPIlohTGRf5agQ8ugF5bComAafmM5MqzgfnXWH6Q-1761014941-1.0.1.1-L4uMCpcrBSnr_stpq5QWfHbcSnbSTZXVXWSK8vOzRmgKbNJmH2W1G3QgvWy2o_c.bj3HUfLzaXx8bCsdZSAeytypsJejfBbHebNxK.SyveU; path=/; expires=Tue, 21-Oct-25 03:19:01 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=6xXItNCetkLRfjoRrUxQRCW4IqmSV1C7NcfkLmxdDxQ-1761014941204-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'991d70292a0ea55a-MIA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-20 19:49:00,912 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-10-20 19:49:00,913 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-10-20 19:49:00,913 - httpcore.http11 - DEBUG - response_closed.started
2025-10-20 19:49:00,913 - httpcore.http11 - DEBUG - response_closed.complete
2025-10-20 19:49:00,913 - httpcore.connection - DEBUG - close.started
2025-10-20 19:49:00,913 - httpcore.connection - DEBUG - close.complete
[92m19:49:00 - LiteLLM:INFO[0m: utils.py:1262 - Wrapper: Completed Call, calling success_handler
2025-10-20 19:49:00,913 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
[92m19:49:00 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:49:00 - LiteLLM:DEBUG[0m: litellm_logging.py:1594 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-10-20 19:49:00,914 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:49:00 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:49:00,914 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
[92m19:49:00 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
2025-10-20 19:49:00,914 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:49:00 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:49:00,914 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:49:00 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:49:00,914 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:49:00 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.001351
2025-10-20 19:49:00,915 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:49:00 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:49:00,915 - LiteLLM - DEBUG - response_cost: 0.001351
2025-10-20 19:49:00,915 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:49:00 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.001351
[92m19:49:00 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: None
2025-10-20 19:49:00,915 - LiteLLM - DEBUG - response_cost: 0.001351
[92m19:49:00 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:49:00,916 - LiteLLM - DEBUG - selected model name for cost calculation: None
[92m19:49:00 - LiteLLM:DEBUG[0m: cost_calculator.py:960 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=None - Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b13051d90>, model=None
2025-10-20 19:49:00,916 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:49:00 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:49:00,916 - LiteLLM - DEBUG - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=None - Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b13051d90>, model=None
2025-10-20 19:49:00,916 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:49:00,916 - root - DEBUG - Cost tracking failed: Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b13051d90>, model=None
2025-10-20 19:49:00,917 - AIResearchTest - WARNING - Query generation returned None (source deemed not relevant)
2025-10-20 19:49:01,368 - urllib3.connectionpool - DEBUG - https://twitter-api45.p.rapidapi.com:443 "GET /search.php?query=JTTF+OR+%22Joint+Terrorism+Task+Force%22+OR+counterterrorism+OR+%22domestic+terrorism%22+OR+%22domestic+counterterrorism%22+OR+%22terrorism+task+force%22+OR+%22fusion+center%22+OR+FBI+OR+DHS+OR+%22law+enforcement%22+OR+%23JTTF+OR+%23Counterterrorism&search_type=Latest HTTP/1.1" 200 None
2025-10-20 19:49:01,870 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): twitter-api45.p.rapidapi.com:443
2025-10-20 19:49:04,936 - urllib3.connectionpool - DEBUG - https://twitter-api45.p.rapidapi.com:443 "GET /search.php?query=JTTF+OR+%22Joint+Terrorism+Task+Force%22+OR+counterterrorism+OR+%22domestic+terrorism%22+OR+%22domestic+counterterrorism%22+OR+%22terrorism+task+force%22+OR+%22fusion+center%22+OR+FBI+OR+DHS+OR+%22law+enforcement%22+OR+%23JTTF+OR+%23Counterterrorism&search_type=Latest&cursor=DAADDAABCgABG3wHmmNacMsKAAIbfAdmZ1qxggAIAAIAAAACCAADAAAAAAgABAAAAAAKAAUbfAegZUAnEAoABht8B6BlP9jwAAA HTTP/1.1" 200 None
2025-10-20 19:49:05,438 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): twitter-api45.p.rapidapi.com:443
2025-10-20 19:49:08,504 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 21 Oct 2025 02:49:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9998853'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'quickgpts'), (b'openai-project', b'proj_tta1tTpO1Yd49KEelsEZTSjW'), (b'x-request-id', b'req_0911a84a3acf4204bbb639ef4a5e81f4'), (b'openai-processing-ms', b'20950'), (b'x-envoy-upstream-service-time', b'20953'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=9nHvdT1H3jCCcpqIWulqF4vshiLyngQ4eANjrlUcGvc-1761014949-1.0.1.1-1adGgAQWKw8NLKhG8z9n2S5JqmZjwvc77nfEvdZZQpu1vRzdvQvaxj5K3RnpdN6HKGg1Ff57gLF631vNBmhLQ4QPR_0hZtjRfjOF8d64.wk; path=/; expires=Tue, 21-Oct-25 03:19:09 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=6yMvr0RcwW7O7X3m3za3sVzp2_HuGfMXxBk9Ft_viOs-1761014949520-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'991d7026be1f67db-MIA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-20 19:49:08,505 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-10-20 19:49:08,505 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-10-20 19:49:08,505 - httpcore.http11 - DEBUG - response_closed.started
2025-10-20 19:49:08,505 - httpcore.http11 - DEBUG - response_closed.complete
2025-10-20 19:49:08,505 - httpcore.connection - DEBUG - close.started
2025-10-20 19:49:08,506 - httpcore.connection - DEBUG - close.complete
[92m19:49:08 - LiteLLM:INFO[0m: utils.py:1262 - Wrapper: Completed Call, calling success_handler
2025-10-20 19:49:08,506 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
[92m19:49:08 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:49:08 - LiteLLM:DEBUG[0m: litellm_logging.py:1594 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-10-20 19:49:08,506 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:49:08 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:49:08,506 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
[92m19:49:08 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
2025-10-20 19:49:08,506 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:49:08 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:49:08,507 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:49:08 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:49:08,507 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:49:08 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.0019905
2025-10-20 19:49:08,507 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:49:08 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:49:08,507 - LiteLLM - DEBUG - response_cost: 0.0019905
2025-10-20 19:49:08,508 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:49:08 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: None
[92m19:49:08 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.0019905
2025-10-20 19:49:08,508 - LiteLLM - DEBUG - selected model name for cost calculation: None
[92m19:49:08 - LiteLLM:DEBUG[0m: cost_calculator.py:960 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=None - Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b130a51c0>, model=None
2025-10-20 19:49:08,508 - LiteLLM - DEBUG - response_cost: 0.0019905
[92m19:49:08 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:49:08,508 - LiteLLM - DEBUG - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=None - Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b130a51c0>, model=None
2025-10-20 19:49:08,509 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:49:08 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:49:08,509 - root - DEBUG - Cost tracking failed: Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b130a51c0>, model=None
2025-10-20 19:49:08,509 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:49:08,509 - AIResearchTest - INFO - Generated query parameters:
2025-10-20 19:49:08,509 - AIResearchTest - INFO - {
  "keywords": "domestic counterterrorism JTTF \"Joint Terrorism Task Force\" counterterrorism intelligence \"counter violent extremism\" CVE threat assessment training information sharing fusion center",
  "procurement_types": [
    "Solicitation",
    "Presolicitation",
    "Combined Synopsis/Solicitation",
    "Sources Sought"
  ],
  "set_aside": null,
  "naics_codes": [
    "541611",
    "541512",
    "541519",
    "541990",
    "518210"
  ],
  "organization": "Federal Bureau of Investigation",
  "date_range_days": 30
}
2025-10-20 19:49:08,509 - AIResearchTest - INFO - Executing search...
2025-10-20 19:49:08,510 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): api.sam.gov:443
2025-10-20 19:49:08,673 - urllib3.connectionpool - DEBUG - https://twitter-api45.p.rapidapi.com:443 "GET /search.php?query=JTTF+OR+%22Joint+Terrorism+Task+Force%22+OR+counterterrorism+OR+%22domestic+terrorism%22+OR+%22domestic+counterterrorism%22+OR+%22terrorism+task+force%22+OR+%22fusion+center%22+OR+FBI+OR+DHS+OR+%22law+enforcement%22+OR+%23JTTF+OR+%23Counterterrorism&search_type=Latest&cursor=DAADDAABCgABG3wHmmNacMsKAAIbfAdBYVsxtgAIAAIAAAACCAADAAAAAAgABAAAAAEKAAUbfAegZUAnEAoABht8B6BlP7HgAAA HTTP/1.1" 200 None
2025-10-20 19:49:09,176 - urllib3.connectionpool - DEBUG - Starting new HTTPS connection (1): twitter-api45.p.rapidapi.com:443
2025-10-20 19:49:12,290 - urllib3.connectionpool - DEBUG - https://twitter-api45.p.rapidapi.com:443 "GET /search.php?query=JTTF+OR+%22Joint+Terrorism+Task+Force%22+OR+counterterrorism+OR+%22domestic+terrorism%22+OR+%22domestic+counterterrorism%22+OR+%22terrorism+task+force%22+OR+%22fusion+center%22+OR+FBI+OR+DHS+OR+%22law+enforcement%22+OR+%23JTTF+OR+%23Counterterrorism&search_type=Latest&cursor=DAADDAABCgABG3wHmmNacMsKAAIbfAcbFRpxQQAIAAIAAAACCAADAAAAAAgABAAAAAIKAAUbfAegZUAnEAoABht8B6BlP4rQAAA HTTP/1.1" 200 None
2025-10-20 19:49:12,368 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 21 Oct 2025 02:49:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'x-ratelimit-limit-requests', b'10000'), (b'x-ratelimit-limit-tokens', b'10000000'), (b'x-ratelimit-remaining-requests', b'9999'), (b'x-ratelimit-remaining-tokens', b'9999405'), (b'x-ratelimit-reset-requests', b'6ms'), (b'x-ratelimit-reset-tokens', b'3ms'), (b'openai-version', b'2020-10-01'), (b'openai-organization', b'quickgpts'), (b'openai-project', b'proj_tta1tTpO1Yd49KEelsEZTSjW'), (b'x-request-id', b'req_e77365b346b54acdb8816bd907e817c0'), (b'openai-processing-ms', b'25265'), (b'x-envoy-upstream-service-time', b'25270'), (b'cf-cache-status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=cjfSvANn._yKqU59c2_JLos_LUsuqvceKalqb_8tpL8-1761014953-1.0.1.1-oBO4Mt.Bue7EvI1wUrV7k6EfjPv1jIN9H0dme1o7xhRivMABHZE8FJHwo5L_tc8xng_O45S8913JBPK1cP6ngv5jusoXbIAUoKp8ik.RFno; path=/; expires=Tue, 21-Oct-25 03:19:13 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Strict-Transport-Security', b'max-age=31536000; includeSubDomains; preload'), (b'X-Content-Type-Options', b'nosniff'), (b'Set-Cookie', b'_cfuvid=qwJoM1m0iMfy8HYxMvkXiPpaLVQ4JY3bLpeXkcMCT5U-1761014953823-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'991d70270b52b112-MIA'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])
2025-10-20 19:49:12,369 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-10-20 19:49:12,369 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-10-20 19:49:12,369 - httpcore.http11 - DEBUG - response_closed.started
2025-10-20 19:49:12,369 - httpcore.http11 - DEBUG - response_closed.complete
2025-10-20 19:49:12,370 - httpcore.connection - DEBUG - close.started
2025-10-20 19:49:12,370 - httpcore.connection - DEBUG - close.complete
[92m19:49:12 - LiteLLM:INFO[0m: utils.py:1262 - Wrapper: Completed Call, calling success_handler
2025-10-20 19:49:12,370 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler
[92m19:49:12 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:49:12 - LiteLLM:DEBUG[0m: litellm_logging.py:1594 - Logging Details LiteLLM-Success Call: Cache_hit=None
2025-10-20 19:49:12,370 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:49:12 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:49:12,370 - LiteLLM - DEBUG - Logging Details LiteLLM-Success Call: Cache_hit=None
[92m19:49:12 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
2025-10-20 19:49:12,371 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:49:12 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:49:12,371 - LiteLLM - DEBUG - selected model name for cost calculation: openai/gpt-5-mini-2025-08-07
[92m19:49:12 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:49:12,371 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:49:12 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.0031704999999999997
2025-10-20 19:49:12,371 - LiteLLM - DEBUG - response_cost: 0.0031704999999999997
2025-10-20 19:49:12,371 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:49:12 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:49:12,372 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
[92m19:49:12 - LiteLLM:DEBUG[0m: litellm_logging.py:1223 - response_cost: 0.0031704999999999997
2025-10-20 19:49:12,372 - LiteLLM - DEBUG - response_cost: 0.0031704999999999997
[92m19:49:12 - LiteLLM:DEBUG[0m: utils.py:4622 - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
2025-10-20 19:49:12,372 - LiteLLM - DEBUG - checking potential_model_names in litellm.model_cost: {'split_model': 'gpt-5-mini-2025-08-07', 'combined_model_name': 'openai/gpt-5-mini-2025-08-07', 'stripped_model_name': 'gpt-5-mini-2025-08-07', 'combined_stripped_model_name': 'openai/gpt-5-mini-2025-08-07', 'custom_llm_provider': 'openai'}
[92m19:49:12 - LiteLLM:DEBUG[0m: utils.py:4927 - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:49:12,372 - LiteLLM - DEBUG - model_info: {'key': 'gpt-5-mini-2025-08-07', 'max_tokens': 128000, 'max_input_tokens': 272000, 'max_output_tokens': 128000, 'input_cost_per_token': 2.5e-07, 'cache_creation_input_token_cost': None, 'cache_read_input_token_cost': 2.5e-08, 'input_cost_per_character': None, 'input_cost_per_token_above_128k_tokens': None, 'input_cost_per_token_above_200k_tokens': None, 'input_cost_per_query': None, 'input_cost_per_second': None, 'input_cost_per_audio_token': None, 'input_cost_per_token_batches': None, 'output_cost_per_token_batches': None, 'output_cost_per_token': 2e-06, 'output_cost_per_audio_token': None, 'output_cost_per_character': None, 'output_cost_per_reasoning_token': None, 'output_cost_per_token_above_128k_tokens': None, 'output_cost_per_character_above_128k_tokens': None, 'output_cost_per_token_above_200k_tokens': None, 'output_cost_per_second': None, 'output_cost_per_image': None, 'output_vector_size': None, 'citation_cost_per_token': None, 'litellm_provider': 'openai', 'mode': 'chat', 'supports_system_messages': True, 'supports_response_schema': True, 'supports_vision': True, 'supports_function_calling': True, 'supports_tool_choice': True, 'supports_assistant_prefill': None, 'supports_prompt_caching': True, 'supports_audio_input': None, 'supports_audio_output': None, 'supports_pdf_input': True, 'supports_embedding_image_input': None, 'supports_native_streaming': True, 'supports_web_search': None, 'supports_url_context': None, 'supports_reasoning': True, 'supports_computer_use': None, 'search_context_cost_per_query': None, 'tpm': None, 'rpm': None}
2025-10-20 19:49:22,899 - urllib3.connectionpool - DEBUG - https://api.sam.gov:443 "GET /opportunities/v2/search?api_key=SAM-db0e8074-ef7f-41b2-8456-b0f79a0a2112&postedFrom=09%2F20%2F2025&postedTo=10%2F20%2F2025&limit=10&offset=0&keywords=domestic+counterterrorism+JTTF+%22Joint+Terrorism+Task+Force%22+counterterrorism+intelligence+%22counter+violent+extremism%22+CVE+threat+assessment+training+information+sharing+fusion+center&ptype=o%2Cp%2Ck%2Cr&ncode=541611%2C541512%2C541519%2C541990%2C518210&organizationName=Federal+Bureau+of+Investigation HTTP/1.1" 200 None
2025-10-20 19:49:22,900 - AIResearchTest - INFO - Search completed:
2025-10-20 19:49:22,900 - AIResearchTest - INFO -   Success: True
2025-10-20 19:49:22,900 - AIResearchTest - INFO -   Total: 0
2025-10-20 19:49:22,900 - AIResearchTest - INFO -   Returned: 0
2025-10-20 19:49:22,900 - AIResearchTest - INFO -   Time: 41783ms
2025-10-20 19:49:22,900 - AIResearchTest - INFO - Search completed:
2025-10-20 19:49:22,900 - AIResearchTest - INFO -   Success: True
2025-10-20 19:49:22,900 - AIResearchTest - INFO -   Total: 68
2025-10-20 19:49:22,901 - AIResearchTest - INFO -   Returned: 10
2025-10-20 19:49:22,901 - AIResearchTest - INFO -   Time: 41767ms
[92m19:49:22 - LiteLLM:DEBUG[0m: cost_calculator.py:675 - selected model name for cost calculation: None
2025-10-20 19:49:22,901 - LiteLLM - DEBUG - selected model name for cost calculation: None
[92m19:49:22 - LiteLLM:DEBUG[0m: cost_calculator.py:960 - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=None - Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b10449400>, model=None
2025-10-20 19:49:22,901 - LiteLLM - DEBUG - litellm.cost_calculator.py::completion_cost() - Error calculating cost for model=None - Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b10449400>, model=None
2025-10-20 19:49:22,901 - root - DEBUG - Cost tracking failed: Model is None and does not exist in passed completion_response. Passed completion_response=<llm_utils.UnifiedLLM._single_completion.<locals>.ResponseWrapper object at 0x735b10449400>, model=None
2025-10-20 19:49:22,901 - AIResearchTest - INFO - Generated query parameters:
2025-10-20 19:49:22,901 - AIResearchTest - INFO - {
  "query": "\"domestic counterterrorism\" OR \"domestic terrorism\" OR \"Joint Terrorism Task Force\" OR \"JTTF\" OR \"Domestic Terrorism Branch\" OR \"Counterterrorism Division\" OR \"National Joint Terrorism Task Force\" OR \"JTTF meeting\" OR \"JTTF call\" OR \"JTTF communication\" OR \"domestic terrorism threat assessment\" OR \"domestic terrorism investigation\" OR \"terrorism threat bulletin\" OR \"intelligence bulletin\" OR \"operational update\" OR \"situation report\" OR \"after-action report\" OR \"field office domestic terrorism\" OR \"counterterrorism task force\" OR \"domestic terrorism advisory\" OR \"Domestic Terrorism Operations Unit\" OR 2023 OR 2024 OR 2025"
}
2025-10-20 19:49:22,901 - AIResearchTest - INFO - Executing search...
2025-10-20 19:49:22,902 - AIResearchTest - INFO - Search completed:
2025-10-20 19:49:22,902 - AIResearchTest - INFO -   Success: False
2025-10-20 19:49:22,902 - AIResearchTest - INFO -   Total: 0
2025-10-20 19:49:22,902 - AIResearchTest - INFO -   Returned: 0
2025-10-20 19:49:22,902 - AIResearchTest - INFO -   Time: 41778ms
2025-10-20 19:49:22,902 - AIResearchTest - ERROR -   Error: Cloudflare bypass failed: No module named 'seleniumbase'
================================================================================
AI RESEARCH - COMPREHENSIVE SEARCH TEST
================================================================================

Research Question: i am looking for all recent activity and conversation related to domestic counterterrorism and JTTF etc

[STEP 1] Generating search strategy...

✅ Strategy: Cast a wide net across official government sources (contracts, FOIA, job postings), media outlets, a...

✅ Selected 7 sources:
   - sam: counterterrorism, JTTF
   - dvids: counterterrorism, training
   - usajobs: JTTF, counterterrorism
   - clearancejobs: counterterrorism, JTTF
   - fbi_vault: JTTF, investigations
   - discord: domestic terrorism, JTTF
   - twitter: JTTF, domestic terrorism

[STEP 2] Executing searches...
Warning: Could not parse data/exports/Project Owl: The OSINT Community - Europe, Russia, and Caucasus - ⛳🏆-eurrrrrrrrrobog [746747727160803418] (2025-09-07 to 2025-09-14).json: Expecting ',' delimiter: line 298005 column 6 (char 8716157)
Warning: Could not parse data/exports/Project Owl: The OSINT Community - Middle East - syria [609160545714831372] (2025-08-17 to 2025-08-24).json: Expecting ',' delimiter: line 8008 column 6 (char 265862)
Warning: Could not parse data/exports/Project Owl: The OSINT Community - Europe, Russia, and Caucasus - ⛳🏆-eurrrrrrrrrobog [746747727160803418] (2025-08-31 to 2025-09-07).json: Expecting ',' delimiter: line 934769 column 12 (char 27265597)
Warning: Could not parse data/exports/Project Owl: The OSINT Community - Americas - 🐸-the-swamp [1418332901220679720] (2025-10-05 to 2025-10-12).json: Expecting ',' delimiter: line 307827 column 6 (char 9291979)
Warning: Could not parse data/exports/Project Owl: The OSINT Community - PO Community - 🏈-sporrts [741739377989779507] (2025-09-21 to 2025-09-28).json: Expecting ',' delimiter: line 266765 column 6 (char 7690159)
Warning: Could not parse data/exports/Project Owl: The OSINT Community - Americas - 🐸-the-swamp [1418332901220679720] (2025-09-28 to 2025-10-05).json: Expecting ',' delimiter: line 30157 column 12 (char 920116)
Warning: Could not parse data/exports/Project Owl: The OSINT Community - Americas - north-america [715937915112521770] (2025-09-28 to 2025-10-05).json: Expecting ',' delimiter: line 259490 column 12 (char 7865521)
Warning: Could not parse data/exports/Project Owl: The OSINT Community - Americas - 🐸-the-swamp [1418332901220679720] (2025-10-12 to 2025-10-19).json: Expecting ',' delimiter: line 265672 column 6 (char 7939300)
Warning: Could not parse data/exports/Bellingcat - ・━━ Server info - announcements [709768274031935560].json: Expecting ',' delimiter: line 77762 column 6 (char 3071942)

Executing Step: Call search.php (Reason: Use Latest for time-sensitive monitoring of recent conversations. The query uses OR to capture acronyms, full phrase variants, agency names, related programs (fusion centers) and common hashtags to maximize recall. Four pages provide broad recent coverage while remaining focused.)
  Requesting URL: https://twitter-api45.p.rapidapi.com/search.php
  With Params: {'query': 'JTTF OR "Joint Terrorism Task Force" OR counterterrorism OR "domestic terrorism" OR "domestic counterterrorism" OR "terrorism task force" OR "fusion center" OR FBI OR DHS OR "law enforcement" OR #JTTF OR #Counterterrorism', 'search_type': 'Latest'}
  Fetching page 1...
  Extracted list data from key: 'timeline'
  Fetching page 2 with cursor DAADDAABCg...
  Extracted list data from key: 'timeline'
  Fetching page 3 with cursor DAADDAABCg...
  Extracted list data from key: 'timeline'
  Fetching page 4 with cursor DAADDAABCg...
  Extracted list data from key: 'timeline'
  Finished fetching for search.php. Total pages: 4. Has next cursor: True
  Successfully processed request for search.php.

================================================================================
[STEP 3] RESULTS SUMMARY
================================================================================

✅ SAM.gov: 0 results (41783ms)
   Params: {
           "keywords": "domestic counterterrorism JTTF \"Joint Terrorism Task Force\" counterterrorism intelligence \"counter violent extremism\" CVE threat assessment training information sharing f...

✅ DVIDS: 0 results (19271ms)
   Params: {
           "keywords": "domestic counterterrorism JTTF",
           "media_types": [
                      "image",
                      "video",
                      "news"
           ],
        ...

❌ USAJobs: 0 results (0ms)
   Error: Query generation returned no parameters (source deemed not relevant)...

❌ ClearanceJobs: 0 results (0ms)
   Error: Query generation returned no parameters (source deemed not relevant)...

❌ FBI Vault: 0 results (41778ms)
   Error: Cloudflare bypass failed: No module named 'seleniumbase'...
   Params: {
           "query": "\"domestic counterterrorism\" OR \"domestic terrorism\" OR \"Joint Terrorism Task Force\" OR \"JTTF\" OR \"Domestic Terrorism Branch\" OR \"Counterterrorism Division\" OR \"Nati...

✅ Discord: 0 results (11898ms)
   Params: {
           "keywords": [
                      "domestic counterterrorism",
                      "jttf",
                      "recent activity",
                      "conversation",
             ...

✅ Twitter: 68 results (41767ms)
   Params: {
           "query": "JTTF OR \"Joint Terrorism Task Force\" OR counterterrorism OR \"domestic terrorism\" OR \"domestic counterterrorism\" OR \"terrorism task force\" OR \"fusion center\" OR FBI OR ...

================================================================================
✅ TEST COMPLETE - Check ai_research_test.log for full details
================================================================================
2025-10-20 19:49:22,904 - asyncio - DEBUG - Using selector: EpollSelector
2025-10-20 19:49:22,998 - httpcore.connection - DEBUG - close.started
2025-10-20 19:49:22,999 - httpcore.connection - DEBUG - close.complete
2025-10-20 19:49:22,999 - httpcore.connection - DEBUG - close.started
2025-10-20 19:49:22,999 - httpcore.connection - DEBUG - close.complete
